{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fec8cafd",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#라이브러리-호출\" data-toc-modified-id=\"라이브러리-호출-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>라이브러리 호출</a></span></li><li><span><a href=\"#parser-정의\" data-toc-modified-id=\"parser-정의-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>parser 정의</a></span></li><li><span><a href=\"#data.py-정의\" data-toc-modified-id=\"data.py-정의-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>data.py 정의</a></span><ul class=\"toc-item\"><li><span><a href=\"#seed-넘버-정의\" data-toc-modified-id=\"seed-넘버-정의-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>seed 넘버 정의</a></span></li><li><span><a href=\"#데이터-불러와보기\" data-toc-modified-id=\"데이터-불러와보기-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>데이터 불러와보기</a></span><ul class=\"toc-item\"><li><span><a href=\"#_batchfy-연습\" data-toc-modified-id=\"_batchfy-연습-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>_batchfy 연습</a></span></li></ul></li></ul></li><li><span><a href=\"#layers.py\" data-toc-modified-id=\"layers.py-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>layers.py</a></span></li><li><span><a href=\"#models.py\" data-toc-modified-id=\"models.py-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>models.py</a></span></li><li><span><a href=\"#evaluate\" data-toc-modified-id=\"evaluate-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>evaluate</a></span></li><li><span><a href=\"#train\" data-toc-modified-id=\"train-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>train</a></span></li><li><span><a href=\"#모델-학습을-위한-설정\" data-toc-modified-id=\"모델-학습을-위한-설정-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>모델 학습을 위한 설정</a></span></li><li><span><a href=\"#학습-및-결과\" data-toc-modified-id=\"학습-및-결과-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>학습 및 결과</a></span></li><li><span><a href=\"#데이터-차원-수-확인\" data-toc-modified-id=\"데이터-차원-수-확인-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>데이터 차원 수 확인</a></span><ul class=\"toc-item\"><li><span><a href=\"#get_batches-풀어보기\" data-toc-modified-id=\"get_batches-풀어보기-10.1\"><span class=\"toc-item-num\">10.1&nbsp;&nbsp;</span>get_batches 풀어보기</a></span><ul class=\"toc-item\"><li><span><a href=\"#get_batches-하나씩-자세하게-풀기\" data-toc-modified-id=\"get_batches-하나씩-자세하게-풀기-10.1.1\"><span class=\"toc-item-num\">10.1.1&nbsp;&nbsp;</span>get_batches 하나씩 자세하게 풀기</a></span></li></ul></li><li><span><a href=\"#intra-series-embedding-module에-input되는-값-확인\" data-toc-modified-id=\"intra-series-embedding-module에-input되는-값-확인-10.2\"><span class=\"toc-item-num\">10.2&nbsp;&nbsp;</span>intra series embedding module에 input되는 값 확인</a></span><ul class=\"toc-item\"><li><span><a href=\"#원본\" data-toc-modified-id=\"원본-10.2.1\"><span class=\"toc-item-num\">10.2.1&nbsp;&nbsp;</span>원본</a></span></li><li><span><a href=\"#permute-이후\" data-toc-modified-id=\"permute-이후-10.2.2\"><span class=\"toc-item-num\">10.2.2&nbsp;&nbsp;</span>permute 이후</a></span></li><li><span><a href=\"#permute().view()-이후\" data-toc-modified-id=\"permute().view()-이후-10.2.3\"><span class=\"toc-item-num\">10.2.3&nbsp;&nbsp;</span>permute().view() 이후</a></span></li><li><span><a href=\"#LSTM-적용해보기\" data-toc-modified-id=\"LSTM-적용해보기-10.2.4\"><span class=\"toc-item-num\">10.2.4&nbsp;&nbsp;</span>LSTM 적용해보기</a></span></li></ul></li><li><span><a href=\"#inter-series-embedding-module에-input-되는-값\" data-toc-modified-id=\"inter-series-embedding-module에-input-되는-값-10.3\"><span class=\"toc-item-num\">10.3&nbsp;&nbsp;</span>inter series embedding module에 input 되는 값</a></span><ul class=\"toc-item\"><li><span><a href=\"#원본\" data-toc-modified-id=\"원본-10.3.1\"><span class=\"toc-item-num\">10.3.1&nbsp;&nbsp;</span>원본</a></span></li><li><span><a href=\"#self.rac()에-원본-X-input\" data-toc-modified-id=\"self.rac()에-원본-X-input-10.3.2\"><span class=\"toc-item-num\">10.3.2&nbsp;&nbsp;</span>self.rac()에 원본 X input</a></span></li><li><span><a href=\"#self.rac-입력-초기\" data-toc-modified-id=\"self.rac-입력-초기-10.3.3\"><span class=\"toc-item-num\">10.3.3&nbsp;&nbsp;</span>self.rac 입력 초기</a></span></li><li><span><a href=\"#self.conv_-(ConvBranch)-입력\" data-toc-modified-id=\"self.conv_-(ConvBranch)-입력-10.3.4\"><span class=\"toc-item-num\">10.3.4&nbsp;&nbsp;</span>self.conv_ (ConvBranch) 입력</a></span><ul class=\"toc-item\"><li><span><a href=\"#nn.Conv2d()-적용\" data-toc-modified-id=\"nn.Conv2d()-적용-10.3.4.1\"><span class=\"toc-item-num\">10.3.4.1&nbsp;&nbsp;</span>nn.Conv2d() 적용</a></span></li><li><span><a href=\"#Max-pooling-적용\" data-toc-modified-id=\"Max-pooling-적용-10.3.4.2\"><span class=\"toc-item-num\">10.3.4.2&nbsp;&nbsp;</span>Max pooling 적용</a></span></li><li><span><a href=\"#view()-적용\" data-toc-modified-id=\"view()-적용-10.3.4.3\"><span class=\"toc-item-num\">10.3.4.3&nbsp;&nbsp;</span>view() 적용</a></span></li><li><span><a href=\"#Local-pattern-concat\" data-toc-modified-id=\"Local-pattern-concat-10.3.4.4\"><span class=\"toc-item-num\">10.3.4.4&nbsp;&nbsp;</span>Local pattern concat</a></span><ul class=\"toc-item\"><li><span><a href=\"#periodic과-global-적용\" data-toc-modified-id=\"periodic과-global-적용-10.3.4.4.1\"><span class=\"toc-item-num\">10.3.4.4.1&nbsp;&nbsp;</span>periodic과 global 적용</a></span></li></ul></li><li><span><a href=\"#local과-periodic과-global-concat\" data-toc-modified-id=\"local과-periodic과-global-concat-10.3.4.5\"><span class=\"toc-item-num\">10.3.4.5&nbsp;&nbsp;</span>local과 periodic과 global concat</a></span></li></ul></li><li><span><a href=\"#attention-적용\" data-toc-modified-id=\"attention-적용-10.3.5\"><span class=\"toc-item-num\">10.3.5&nbsp;&nbsp;</span>attention 적용</a></span></li></ul></li><li><span><a href=\"#parametric-matrix-fusion\" data-toc-modified-id=\"parametric-matrix-fusion-10.4\"><span class=\"toc-item-num\">10.4&nbsp;&nbsp;</span>parametric matrix fusion</a></span></li><li><span><a href=\"#final-output\" data-toc-modified-id=\"final-output-10.5\"><span class=\"toc-item-num\">10.5&nbsp;&nbsp;</span>final output</a></span></li><li><span><a href=\"#AR-module\" data-toc-modified-id=\"AR-module-10.6\"><span class=\"toc-item-num\">10.6&nbsp;&nbsp;</span>AR module</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b502722a",
   "metadata": {},
   "source": [
    "# 라이브러리 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4c69e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import unicode_literals\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os, itertools, random, argparse, time, datetime\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score,explained_variance_score\n",
    "from math import sqrt\n",
    "\n",
    "import scipy.sparse as sp\n",
    "from scipy.stats.stats import pearsonr\n",
    "# from models import *\n",
    "# from data import *\n",
    "\n",
    "import shutil\n",
    "import logging\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2f9c11",
   "metadata": {},
   "source": [
    "# parser 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7be86012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Parameters--------\n",
      "Namespace(batch=128, check_point=1, cuda=False, dataset='japan', dropout=0.2, epochs=1500, eval='', gpu=0, hidA=64, hidP=1, hidR=64, horizon=0, hw=20, k=16, lamda=0.01, lr=0.001, model='model', mylog=True, n_layer=1, patience=200, pcc='', save_dir='save', seed=42, shuffle=False, test=0.3, train=0.5, val=0.2, weight_decay=0.0005, window=20)\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "# Training settings\n",
    "ap = argparse.ArgumentParser()\n",
    "# setting parameters\n",
    "ap.add_argument('--dataset', type=str, default='japan', help=\"Dataset string\")\n",
    "# ap.add_argument('--sim_mat', type=str, default='japan-adj', help=\"adjacency matrix filename (*-adj.txt)\")\n",
    "ap.add_argument('--seed', type=int, default=42, help='random seed')\n",
    "ap.add_argument('--epochs', type=int, default=1500, help='number of epochs to train')\n",
    "ap.add_argument('--lr', type=float, default=1e-3, help='initial learning rate')\n",
    "ap.add_argument('--weight_decay', type=float, default=5e-4, help='weight decay (L2 loss on parameters).')\n",
    "ap.add_argument('--batch', type=int, default=128, help=\"batch size = 128\")\n",
    "ap.add_argument('--check_point', type=int, default=1, help=\"check point\")\n",
    "ap.add_argument('--shuffle', action='store_true', default=False, help=\"not used, default false\")\n",
    "ap.add_argument('--train', type=float, default=.5, help=\"Training ratio (0, 1)\")\n",
    "ap.add_argument('--val', type=float, default=.2, help=\"Validation ratio (0, 1)\")\n",
    "ap.add_argument('--test', type=float, default=.3, help=\"Testing ratio (0, 1)\")\n",
    "ap.add_argument('--mylog', action='store_false', default=True,  help='save tensorboad log')\n",
    "ap.add_argument('--cuda', action='store_true', default=False,  help='')\n",
    "ap.add_argument('--save_dir', type=str,  default='save',help='dir path to save the final model')\n",
    "ap.add_argument('--gpu', type=int, default=0,  help='choose gpu 0-10')\n",
    "ap.add_argument('--lamda', type=float, default=0.01,  help='regularize params similarities of states')\n",
    "ap.add_argument('--patience', type=int, default=200, help='patience default 200')\n",
    "ap.add_argument('--pcc', type=str, default='',  help='have pcc?')\n",
    "ap.add_argument('--eval', type=str, default='', help='evaluation test file')\n",
    "ap.add_argument('--window', type=int, default=20, help='')\n",
    "ap.add_argument('--horizon', type=int, default=0, help='leadtime default 5')\n",
    "# model parameters\n",
    "ap.add_argument('--model', default='model')\n",
    "ap.add_argument('--n_layer', type=int, default=1, help=\"number of layers (default 1)\")\n",
    "ap.add_argument('--k', type=int, default=16,  help='the number of kernels')\n",
    "ap.add_argument('--hidR', type=int, default=64,  help='the hidden dim of LSTM to extract intra-series embedding')\n",
    "ap.add_argument('--hidA', type=int, default=64,  help='the hidden dim of attention layer')\n",
    "ap.add_argument('--hidP', type=int, default=1,  help='the output hidden dim of adaptive pooling')\n",
    "ap.add_argument('--hw', type=int, default=20,  help='the look-back window size of AR component')\n",
    "ap.add_argument('--dropout', type=float, default=0.2, help='dropout rate usually 0.2-0.5.')\n",
    "\n",
    "args = ap.parse_args(args=[])\n",
    "print('--------Parameters--------')\n",
    "print(args)\n",
    "print('--------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d85bbd",
   "metadata": {},
   "source": [
    "# data.py 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81cabba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad9e88d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataBasicLoader(object):\n",
    "    def __init__(self, args):\n",
    "        self.cuda = args.cuda\n",
    "        self.P = args.window # window size (20)\n",
    "        self.h = args.horizon # forecast length (1)\n",
    "        self.d = 0\n",
    "        self.add_his_day = False\n",
    "        self.rawdat = np.loadtxt(open(\"data/{}.txt\".format(args.dataset)), delimiter=',') # 데이터 불러오기\n",
    "        print('################ self.rawdat.shape ################')\n",
    "        print('rawdat.shape', self.rawdat.shape)\n",
    "        print()\n",
    "\n",
    "        if (len(self.rawdat.shape)==1):\n",
    "            self.rawdat = self.rawdat.reshape((self.rawdat.shape[0], 1))\n",
    "        \n",
    "        self.dat = np.zeros(self.rawdat.shape)\n",
    "        self.n, self.m = self.dat.shape # n_sample : 관측치 개수, m_group : 변수 개수\n",
    "        print('################ self.dat.shape ################')\n",
    "        print('관측치 수 :', self.n, '변수 개수 :', self.m)\n",
    "        print()\n",
    "        \n",
    "        self.scale = np.ones(self.m)\n",
    "        # args.train은 train data의 비율이 들어있음\n",
    "        self._pre_train(int(args.train * self.n), int((args.train + args.val) * self.n), self.n)\n",
    "        # self.train (train 데이터 비율) * self.n (관측치 수)\n",
    "        self._split(int(args.train * self.n), int((args.train + args.val) * self.n), self.n)\n",
    "        print('################ [train, valid, test] shape ################')\n",
    "        print('size of train/val/test sets', len(self.train[0]), len(self.val[0]), len(self.test[0]))\n",
    "        print()\n",
    "        \n",
    "    def _pre_train(self, train, valid, test):\n",
    "        self.train_set = train_set = range(self.P+self.h-1, train) # (window_size)+(horizon-1)\n",
    "        self.valid_set = valid_set = range(train, valid)\n",
    "        self.test_set = test_set = range(valid, self.n)\n",
    "        self.tmp_train = self._batchify(train_set, self.h, useraw = True)\n",
    "        # trainset에 대한 첫 번째 window와 이후 window들에 대한 정답을 concat함\n",
    "            # (20, 47)과 (154, 47) concat -> (174, 47)\n",
    "        train_mx = torch.cat((self.tmp_train[0][0], self.tmp_train[1]), 0).numpy() # (batch_size, n_features) : 174, 47\n",
    "        self.max = np.max(train_mx, 0)\n",
    "        self.min = np.min(train_mx, 0)\n",
    "        self.peak_hold = np.mean(train_mx, 0)\n",
    "        # train set의 min과 max 정보로 전체 데이터 scaling\n",
    "        self.dat = (self.rawdat - self.min) / (self.max - self.min + 1e-12)\n",
    "        print('################ _pre_train ################')\n",
    "        print(f'self.tmp_train X: {self.tmp_train[0].shape}')\n",
    "        print(f'self.tmp_train Y: {self.tmp_train[1].shape}')\n",
    "        print(f'train_mx (trainset의 shape) : {train_mx.shape}')\n",
    "        print('self.train_set :', range(self.P+self.h-1, train))\n",
    "        print('self.valid_set :', range(train, valid))\n",
    "        print('self.test_set :', range(valid, self.n))\n",
    "        print(f'_pre_train (정규화된 데이터 dat의 shape) : {self.dat.shape}')\n",
    "        print()\n",
    "        \n",
    "    def _split(self, train, valid, test):\n",
    "        self.train = self._batchify(self.train_set, self.h) # torch.Size([179, 20, 47]) torch.Size([179, 47])\n",
    "        self.val = self._batchify(self.valid_set, self.h)\n",
    "        self.test = self._batchify(self.test_set, self.h)\n",
    "        if (train==valid):\n",
    "            self.val = self.test\n",
    "            \n",
    "    \"\"\"최종적인 batch 형태 [batch_size, window_size, n_features]로 만들어주는 게 아님\n",
    "    각 batch 별로 window size만큼의 데이터가 들어갈 수 있게 해주는 것\"\"\"\n",
    "    def _batchify(self, idx_set, horizon, useraw=False): # test set의 경우 self.h가 변해도 Y값은 변하지 않는다. horizon이 커질 경우 model에 input하는 값을 더 과거로 한다.\n",
    "        n = len(idx_set) # idx_set은 dataset을 의미\n",
    "        Y = torch.zeros((n, self.m))\n",
    "        X = torch.zeros((n, self.P, self.m))\n",
    "        \n",
    "        for i in range(n):\n",
    "            end = idx_set[i] - self.h + 1\n",
    "            start = end - self.P # end 시점에서 window size만큼 제외\n",
    "            ## normalization을 하지 않는 것\n",
    "            if useraw: \n",
    "                X[i,:self.P,:] = torch.from_numpy(self.rawdat[start:end, :])\n",
    "                Y[i,:] = torch.from_numpy(self.rawdat[idx_set[i], :])\n",
    "            ## trainset의 min max 정보를 활용하여 scaling한 뒤 자른 것\n",
    "            else:\n",
    "                his_window = self.dat[start:end, :]\n",
    "                X[i, :self.P, :] = torch.from_numpy(his_window) # size (window, m)\n",
    "                Y[i, :] = torch.from_numpy(self.dat[idx_set[i], :])\n",
    "        return [X, Y]\n",
    "        \n",
    "    def get_batches(self, data, batch_size, shuffle=True):\n",
    "        inputs = data[0]\n",
    "        targets = data[1]\n",
    "        length = len(inputs)\n",
    "        if shuffle:\n",
    "            index = torch.randperm(length)\n",
    "        else:\n",
    "            index = torch.LongTensor(range(length))\n",
    "        start_idx = 0\n",
    "        while (start_idx < length):\n",
    "            end_idx = min(length, start_idx + batch_size)\n",
    "            excerpt = index[start_idx:end_idx]\n",
    "            X = inputs[excerpt,:]\n",
    "            Y = targets[excerpt,:]\n",
    "            if (self.cuda):\n",
    "                X = X.cuda()\n",
    "                Y = Y.cuda()\n",
    "            model_inputs = Variable(X)\n",
    "\n",
    "            data = [model_inputs, Variable(Y)]\n",
    "            yield data\n",
    "            start_idx += batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac103aad",
   "metadata": {},
   "source": [
    "## seed 넘버 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6700b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x16fbb78ab90>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6b2f73",
   "metadata": {},
   "source": [
    "## 데이터 불러와보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41ea3277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################ self.rawdat.shape ################\n",
      "rawdat.shape (348, 47)\n",
      "\n",
      "################ self.dat.shape ################\n",
      "관측치 수 : 348 변수 개수 : 47\n",
      "\n",
      "################ _pre_train ################\n",
      "self.tmp_train X: torch.Size([155, 20, 47])\n",
      "self.tmp_train Y: torch.Size([155, 47])\n",
      "train_mx (trainset의 shape) : (175, 47)\n",
      "self.train_set : range(19, 174)\n",
      "self.valid_set : range(174, 243)\n",
      "self.test_set : range(243, 348)\n",
      "_pre_train (정규화된 데이터 dat의 shape) : (348, 47)\n",
      "\n",
      "################ [train, valid, test] shape ################\n",
      "size of train/val/test sets 155 69 105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataBasicLoader(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464104aa",
   "metadata": {},
   "source": [
    "### _batchfy 연습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "533b2823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 348\n",
    "m = 47\n",
    "P = 20\n",
    "h = 3\n",
    "\n",
    "train = int(args.train*n)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "40ab1495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(22, 174)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdat = np.loadtxt(open(\"data/{}.txt\".format(args.dataset)), delimiter=',') # 데이터 불러오기\n",
    "train_set = range(P+h-1, train)\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "58aed876",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([152, 20, 47])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_train = _batchify(train_set, h, useraw = True)\n",
    "tmp_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e819240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.3000e+01, 1.8700e+02, 7.4900e+02,  ..., 1.2000e+02, 7.4000e+01,\n",
       "         7.9000e+01],\n",
       "        [1.7600e+02, 5.3700e+02, 4.2500e+03,  ..., 7.2500e+02, 1.8500e+02,\n",
       "         2.8000e+02],\n",
       "        [5.1800e+02, 7.9500e+02, 7.8060e+03,  ..., 1.7170e+03, 4.5700e+02,\n",
       "         5.7600e+02],\n",
       "        ...,\n",
       "        [3.0000e+00, 0.0000e+00, 3.6000e+01,  ..., 9.0000e+00, 6.0000e+00,\n",
       "         4.0000e+00],\n",
       "        [3.0000e+00, 2.0000e+00, 5.5000e+01,  ..., 9.0000e+00, 2.0000e+00,\n",
       "         1.0000e+00],\n",
       "        [1.0000e+00, 7.0000e+00, 2.7000e+01,  ..., 1.0000e+01, 8.0000e+00,\n",
       "         2.0000e+00]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "47f5ca4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0.,   0.,   7.,  ...,  14.,   0.,   0.],\n",
       "         [  1.,   0.,  21.,  ...,  16.,   2.,   0.],\n",
       "         [  1.,   0.,   2.,  ...,  42.,   0.,   0.],\n",
       "         ...,\n",
       "         [  7.,  11.,  89.,  ...,   2.,   7.,   3.],\n",
       "         [  2.,  40., 138.,  ...,   2.,  13.,  12.],\n",
       "         [  5., 123., 238.,  ...,   7.,  22.,  17.]],\n",
       "\n",
       "        [[  1.,   0.,  21.,  ...,  16.,   2.,   0.],\n",
       "         [  1.,   0.,   2.,  ...,  42.,   0.,   0.],\n",
       "         [  0.,   0.,   4.,  ...,  75.,   0.,   0.],\n",
       "         ...,\n",
       "         [  2.,  40., 138.,  ...,   2.,  13.,  12.],\n",
       "         [  5., 123., 238.,  ...,   7.,  22.,  17.],\n",
       "         [ 20., 180., 490.,  ...,  19.,  51.,  30.]],\n",
       "\n",
       "        [[  1.,   0.,   2.,  ...,  42.,   0.,   0.],\n",
       "         [  0.,   0.,   4.,  ...,  75.,   0.,   0.],\n",
       "         [  0.,   0.,  13.,  ..., 100.,   0.,   2.],\n",
       "         ...,\n",
       "         [  5., 123., 238.,  ...,   7.,  22.,  17.],\n",
       "         [ 20., 180., 490.,  ...,  19.,  51.,  30.],\n",
       "         [ 31., 177., 854.,  ...,  29.,  68.,  39.]],\n",
       "\n",
       "        [[  0.,   0.,   4.,  ...,  75.,   0.,   0.],\n",
       "         [  0.,   0.,  13.,  ..., 100.,   0.,   2.],\n",
       "         [  0.,   0.,  15.,  ..., 130.,   0.,   0.],\n",
       "         ...,\n",
       "         [ 20., 180., 490.,  ...,  19.,  51.,  30.],\n",
       "         [ 31., 177., 854.,  ...,  29.,  68.,  39.],\n",
       "         [ 83., 187., 749.,  ..., 120.,  74.,  79.]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_train[0][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dfe646b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## tmp_train : torch.Size([154, 20, 47]) torch.Size([154, 47])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([174, 47])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('## tmp_train :',tmp_train[0].shape, tmp_train[1].shape)\n",
    "train_mx = torch.cat((tmp_train[0][0], tmp_train[1]), 0)\n",
    "train_mx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "23feff3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  7., ..., 14.,  0.,  0.],\n",
       "       [ 1.,  0., 21., ..., 16.,  2.,  0.],\n",
       "       [ 1.,  0.,  2., ..., 42.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 3.,  0., 36., ...,  9.,  6.,  4.],\n",
       "       [ 3.,  2., 55., ...,  9.,  2.,  1.],\n",
       "       [ 1.,  7., 27., ..., 10.,  8.,  2.]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa35c2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"최종적인 batch 형태 [batch_size, window_size, n_features]로 만들어주는 게 아님\n",
    "각 batch 별로 window size만큼의 데이터가 들어갈 수 있게 해주는 것\"\"\"\n",
    "def _batchify(idx_set, horizon, useraw=False):\n",
    "    n = len(idx_set) # idx_set은 dataset을 의미\n",
    "    Y = torch.zeros((n, m))\n",
    "    X = torch.zeros((n, P, m))\n",
    "\n",
    "    for i in range(n):\n",
    "        end = idx_set[i] - h + 1\n",
    "        start = end - P # end 시점에서 window size만큼 제외\n",
    "        # useraw가 True이면 window size만큼 잘린채로 X와 Y가 들어간다.\n",
    "            # ex) window_size = 20\n",
    "            # \n",
    "        if useraw: # for normalization\n",
    "            X[i,:P,:] = torch.from_numpy(rawdat[start:end, :])\n",
    "            Y[i,:] = torch.from_numpy(rawdat[idx_set[i], :])\n",
    "        else:\n",
    "            his_window = dat[start:end, :]\n",
    "            X[i, :P, :] = torch.from_numpy(his_window) # size (window, m)\n",
    "            Y[i, :] = torch.from_numpy(dat[idx_set[i], :])\n",
    "    return [X, Y]\n",
    "\n",
    "tmp_train = _batchify(train_set, h, useraw = True)\n",
    "train_mx = torch.cat((tmp_train[0][0], tmp_train[1]), 0).numpy()\n",
    "max_ = np.max(train_mx, 0)\n",
    "min_ = np.min(train_mx, 0)\n",
    "peak_hold = np.mean(train_mx, 0)\n",
    "dat = (rawdat - min_) / (max_ - min_ + 1e-12)\n",
    "\n",
    "tmp_train = _batchify(train_set, h, useraw = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3076aa",
   "metadata": {},
   "source": [
    "# layers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "268f9e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from utils import *\n",
    "from torch.autograd import Variable\n",
    "import sys\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78ea60c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotAtt(nn.Module):\n",
    "    def __init__(self, attn_dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(attn_dropout)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "    def forward(self, q,k,v):\n",
    "        attn = torch.bmm(q,k.transpose(1,2))\n",
    "        attn = self.dropout(attn)\n",
    "        attn = self.softmax(attn)\n",
    "        output = torch.bmm(attn, v)\n",
    "        return output\n",
    "    \n",
    "class ConvBranch(nn.Module):\n",
    "    def __init__(self, m, in_channels, out_channels, kernel_size, dilation_factor, hidP = 1, isPool=True):\n",
    "        super().__init__()\n",
    "        self.m = m\n",
    "        self.isPool = isPool\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=(kernel_size, 1), dilation = (dilation_factor, 1), bias=False)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        if self.isPool:\n",
    "            self.pooling = nn.AdaptiveMaxPool2d((hidP, m))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = F.relu(self.conv(x))\n",
    "        x = self.batchnorm(x)\n",
    "        if self.isPool:\n",
    "            x = self.pooling(x)\n",
    "        x = x.view(batch_size, -1, self.m)\n",
    "        return x\n",
    "        \n",
    "class RegionAwareConv(nn.Module):\n",
    "    def __init__(self, P, m, k, hidP, dilation_factor=2):\n",
    "        super(RegionAwareConv, self).__init__()\n",
    "        self.P = P\n",
    "        self.m = m\n",
    "        self.k = k\n",
    "        self.hidP = hidP\n",
    "        # local convolution의 경우 dilation은 1로 설정\n",
    "            # conv_l1과 conv_l2는 kernel_size가 다름\n",
    "        self.conv_l1 = ConvBranch(m = self.m, in_channels=1, out_channels=self.k, kernel_size=3, dilation_factor=1, hidP = self.hidP)\n",
    "        self.conv_l2 = ConvBranch(m = self.m, in_channels=1, out_channels=self.k, kernel_size=5, dilation_factor=1, hidP = self.hidP)\n",
    "        # periodic convolution의 경우 dilation은 2로 설정\n",
    "        self.conv_p1 = ConvBranch(m = self.m, in_channels=1, out_channels=self.k, kernel_size=3, dilation_factor=dilation_factor, hidP=self.hidP)\n",
    "        self.conv_p2 = ConvBranch(m = self.m, in_channels=1, out_channels=self.k, kernel_size=5, dilation_factor=dilation_factor, hidP=self.hidP)\n",
    "        # global_pattern의 경우 전체 window가 input됨 -> kernel_size가 self.P\n",
    "        self.conv_g = ConvBranch(m=self.m, in_channels=1, out_channels=self.k, kernel_size=self.P, dilation_factor=1, hidP=None, isPool=False)\n",
    "        self.activate = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, self.P, self.m)\n",
    "        batch_size = x.shape[0]\n",
    "        # local pattern\n",
    "        x_l1 = self.conv_l1(x)\n",
    "        x_l2 = self.conv_l2(x)\n",
    "        x_local = torch.cat([x_l1, x_l2], dim=1)\n",
    "        # periodic pattern\n",
    "        x_p1 = self.conv_p1(x)\n",
    "        x_p2 = self.conv_p2(x)\n",
    "        x_period = torch.cat([x_l1, x_l2], dim=1)\n",
    "        # global\n",
    "        x_global = self.conv_g(x)\n",
    "        # concat and activate\n",
    "        x = torch.cat([x_local, x_period, x_global], dim=1).permute(0, 2, 1) # 3가지 pattern을 concat함\n",
    "        x = self.activate(x) # nn.tanh()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e264ac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(args.gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f9da10",
   "metadata": {},
   "source": [
    "# models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd94bb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import unicode_literals\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from utils import *\n",
    "from torch.autograd import Variable\n",
    "import sys\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30b256fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, args, data):\n",
    "        super().__init__()\n",
    "        self.m = data.m # 변수 개수\n",
    "        self.w = args.window # window_size\n",
    "        self.h = args.horizon # forecasting length\n",
    "        self.k = args.k\n",
    "        self.hw = args.hw # AR 모듈(Linear layer)의 input size\n",
    "        self.hidA = args.hidA # attention Q, K, V의 linear layer의 hidden size\n",
    "        self.hidR = args.hidR # intra series내의 LSTM의 hidden size\n",
    "        self.hidP = args.hidP # RegionAwareConv의 pooling size\n",
    "        self.num_layers = args.n_layer # LSTM의 num_layer\n",
    "        self.dp = args.dropout\n",
    "        self.dropout = nn.Dropout(p=self.dp)\n",
    "        self.activate = nn.LeakyReLU()\n",
    "        self.highway = nn.Linear(self.hw, 1) # AR 모듈\n",
    "        self.output = nn.Linear(self.hidA+self.hidR, 1) # parametric matrix fusion을 위한 layer -> inter와 intra의 결과를 concat하여 input으로 받음\n",
    "        self.regionconvhid = self.k * 4*self.hidP + self.k # RegionAwareConv가 Q, K, V에 입력될 때 사용되는 input size값\n",
    "        \n",
    "        self.lstm = nn.LSTM(1, self.hidR, bidirectional=False, batch_first=True, num_layers=self.num_layers)\n",
    "        self.rac = RegionAwareConv(P=self.w, m=self.m, k=self.k, hidP=self.hidP)\n",
    "        self.q_linear = nn.Linear(self.regionconvhid, self.hidA, bias = True)\n",
    "        self.k_linear = nn.Linear(self.regionconvhid, self.hidA, bias = True)\n",
    "        self.v_linear = nn.Linear(self.regionconvhid, self.hidA, bias = True)\n",
    "        self.attn_layer = DotAtt()\n",
    "        self.inter = nn.Parameter(torch.FloatTensor(self.m, self.hidA), requires_grad=True)\n",
    "        self.intra = nn.Parameter(torch.FloatTensor(self.m, self.hidR), requires_grad=True)\n",
    "        nn.init.orthogonal_(self.lstm.weight_ih_l0)\n",
    "        nn.init.orthogonal_(self.lstm.weight_hh_l0)\n",
    "        self.init_weights() # weight 초기화 -> xavier_uniform_ 사용\n",
    "        \n",
    "    def init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.data.ndimension() >= 2:\n",
    "                nn.init.xavier_uniform_(p.data)\n",
    "            else:\n",
    "                stdv = 1. / math.sqrt(p.size(0))\n",
    "                p.data.uniform_(-stdv, stdv)\n",
    "    \n",
    "    def forward(self, x, feat=None):\n",
    "        \n",
    "        # Inter-Region embedding\n",
    "        rac = self.rac(x) # RegionAwareConv\n",
    "        q = self.q_linear(rac) # rac의 결과가 attention에 입력\n",
    "        k = self.k_linear(rac)\n",
    "        v = self.v_linear(rac)\n",
    "        q = nn.Dropout(p=0.2)(q)\n",
    "        k = nn.Dropout(p=0.2)(k)\n",
    "        v = nn.Dropout(p=0.2)(v)\n",
    "        inter_ = self.attn_layer(q, k, v) # i\n",
    "        \n",
    "        # Intra-Region embedding\n",
    "        r = x.permute(0, 2, 1).contiguous().view(-1, x.size(1), 1) # LSTM에 입력될 수 있게 변형\n",
    "        r_out, hc = self.lstm(r, None)\n",
    "        last_hid = self.dropout(r_out[:, -1, :])\n",
    "        intra_ = last_hid.view(-1, self.m, self.hidR) # t\n",
    "        \n",
    "        # parametric-matrix fusion\n",
    "        inter_ = torch.mul(self.inter, inter_)\n",
    "        intra_ = torch.mul(self.intra, intra_)\n",
    "        \n",
    "        res = torch.cat([intra_, inter_], dim=2) # inter와 intra를 concat\n",
    "        res = self.output(res)\n",
    "        res = res.squeeze(2)\n",
    "        \n",
    "        # highway\n",
    "        if self.hw > 0:\n",
    "            z = x[:, -self.hw:, :]\n",
    "            z = z.permute(0, 2, 1).contiguous().view(-1, self.hw)\n",
    "            z = self.highway(z)\n",
    "            z = z.view(-1, self.m)\n",
    "            res = res+z\n",
    "            \n",
    "        return res, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e22b106a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################ self.rawdat.shape ################\n",
      "rawdat.shape (348, 47)\n",
      "\n",
      "################ self.dat.shape ################\n",
      "관측치 수 : 348 변수 개수 : 47\n",
      "\n",
      "################ _pre_train ################\n",
      "self.tmp_train X: torch.Size([150, 20, 47])\n",
      "self.tmp_train Y: torch.Size([150, 47])\n",
      "train_mx (trainset의 shape) : (170, 47)\n",
      "self.train_set : range(24, 174)\n",
      "self.valid_set : range(174, 243)\n",
      "self.test_set : range(243, 348)\n",
      "_pre_train (정규화된 데이터 dat의 shape) : (348, 47)\n",
      "\n",
      "################ [train, valid, test] shape ################\n",
      "size of train/val/test sets 150 69 105\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (activate): LeakyReLU(negative_slope=0.01)\n",
       "  (highway): Linear(in_features=20, out_features=1, bias=True)\n",
       "  (output): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (lstm): LSTM(1, 64, batch_first=True)\n",
       "  (rac): RegionAwareConv(\n",
       "    (conv_l1): ConvBranch(\n",
       "      (conv): Conv2d(1, 16, kernel_size=(3, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pooling): AdaptiveMaxPool2d(output_size=(1, 47))\n",
       "    )\n",
       "    (conv_l2): ConvBranch(\n",
       "      (conv): Conv2d(1, 16, kernel_size=(5, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pooling): AdaptiveMaxPool2d(output_size=(1, 47))\n",
       "    )\n",
       "    (conv_p1): ConvBranch(\n",
       "      (conv): Conv2d(1, 16, kernel_size=(3, 1), stride=(1, 1), dilation=(2, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pooling): AdaptiveMaxPool2d(output_size=(1, 47))\n",
       "    )\n",
       "    (conv_p2): ConvBranch(\n",
       "      (conv): Conv2d(1, 16, kernel_size=(5, 1), stride=(1, 1), dilation=(2, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pooling): AdaptiveMaxPool2d(output_size=(1, 47))\n",
       "    )\n",
       "    (conv_g): ConvBranch(\n",
       "      (conv): Conv2d(1, 16, kernel_size=(20, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (activate): Tanh()\n",
       "  )\n",
       "  (q_linear): Linear(in_features=80, out_features=64, bias=True)\n",
       "  (k_linear): Linear(in_features=80, out_features=64, bias=True)\n",
       "  (v_linear): Linear(in_features=80, out_features=64, bias=True)\n",
       "  (attn_layer): DotAtt(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (softmax): Softmax(dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = DataBasicLoader(args)\n",
    "model = Model(args, data_loader)  \n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f2d521",
   "metadata": {},
   "source": [
    "# evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3973629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_loader, data, tag='val', history_average=False):\n",
    "    model.eval()\n",
    "    total = 0.\n",
    "    n_samples = 0.\n",
    "    total_loss = 0.\n",
    "    y_true, y_pred = [], []\n",
    "    batch_size = args.batch\n",
    "    y_pred_mx = []\n",
    "    y_true_mx = []\n",
    "    for inputs in data_loader.get_batches(data, batch_size, False):\n",
    "        X, Y = inputs[0], inputs[1]\n",
    "        output,_  = model(X)\n",
    "        loss_train = F.mse_loss(output, Y) # mse_loss\n",
    "        total_loss += loss_train.item()\n",
    "        n_samples += (output.size(0) * data_loader.m);\n",
    "\n",
    "        y_true_mx.append(Y.data.cpu())\n",
    "        y_pred_mx.append(output.data.cpu())\n",
    "\n",
    "    y_pred_mx = torch.cat(y_pred_mx)\n",
    "    y_true_mx = torch.cat(y_true_mx) # [n_samples, 47] \n",
    "    y_true_states = y_true_mx.numpy() * (data_loader.max - data_loader.min ) * 1.0 + data_loader.min  \n",
    "    y_pred_states = y_pred_mx.numpy() * (data_loader.max - data_loader.min ) * 1.0 + data_loader.min  #(#n_samples, 47)\n",
    "    rmse_states = np.mean(np.sqrt(mean_squared_error(y_true_states, y_pred_states, multioutput='raw_values'))) # mean of 47\n",
    "    raw_mae = mean_absolute_error(y_true_states, y_pred_states, multioutput='raw_values')\n",
    "    std_mae = np.std(raw_mae) # Standard deviation of MAEs for all states/places \n",
    "    r2_states = np.mean(r2_score(y_true_states, y_pred_states, multioutput='raw_values'))\n",
    "\n",
    "    # convert y_true & y_pred to real data\n",
    "    y_true = np.reshape(y_true_states,(-1))\n",
    "    y_pred = np.reshape(y_pred_states,(-1))\n",
    "\n",
    "    rmse = sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_pred - y_true) / (y_true + 0.00001)))\n",
    "    mape /= 10000000\n",
    "    r2 = r2_score(y_true, y_pred,multioutput='uniform_average') #variance_weighted \n",
    "    global y_true_t\n",
    "    global y_pred_t\n",
    "    y_true_t = y_true_states\n",
    "    y_pred_t = y_pred_states\n",
    "    return float(total_loss / n_samples), mae,std_mae, rmse, rmse_states, mape, r2, r2_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f8ac69",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74ce8b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import unicode_literals\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os, itertools, random, argparse, time, datetime\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score,explained_variance_score\n",
    "from math import sqrt\n",
    "\n",
    "import scipy.sparse as sp\n",
    "from scipy.stats.stats import pearsonr\n",
    "from models_mine import *\n",
    "from data_mine import *\n",
    "\n",
    "import shutil\n",
    "import logging\n",
    "import glob\n",
    "import time\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b95a674",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "args.cuda = args.cuda and torch.cuda.is_available() \n",
    "args.cuda = args.gpu is not None\n",
    "if args.cuda:\n",
    "    torch.cuda.set_device(args.gpu)\n",
    "\n",
    "time_token = str(time.time()).split('.')[0] # tensorboard model\n",
    "log_token = '%s.d-%s.w-%s.h' % (args.dataset, args.window, args.horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5071a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_loader, data):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    n_samples = 0.\n",
    "    batch_size = args.batch\n",
    "\n",
    "    for inputs in data_loader.get_batches(data, batch_size, False):\n",
    "        X, Y = inputs[0], inputs[1]\n",
    "        optimizer.zero_grad()\n",
    "        output,_  = model(X) \n",
    "        if Y.size(0) == 1:\n",
    "            Y = Y.view(-1)\n",
    "        loss_train = F.mse_loss(output, Y) # mse_loss\n",
    "        total_loss += loss_train.item()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        n_samples += (output.size(0) * data_loader.m)\n",
    "    return float(total_loss / n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8886f27a",
   "metadata": {},
   "source": [
    "# 모델 학습을 위한 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0eee2d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "args.cuda = args.cuda and torch.cuda.is_available() \n",
    "# args.cuda = args.gpu is not None\n",
    "if args.cuda:\n",
    "    torch.cuda.set_device(args.gpu)\n",
    "    # logger.info('cuda %s', args.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96c22407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################ self.rawdat.shape ################\n",
      "rawdat.shape (348, 47)\n",
      "\n",
      "################ self.dat.shape ################\n",
      "관측치 수 : 348 변수 개수 : 47\n",
      "\n",
      "################ _pre_train ################\n",
      "self.tmp_train X: torch.Size([150, 20, 47])\n",
      "self.tmp_train Y: torch.Size([150, 47])\n",
      "train_mx (trainset의 shape) : (170, 47)\n",
      "self.train_set : range(24, 174)\n",
      "self.valid_set : range(174, 243)\n",
      "self.test_set : range(243, 348)\n",
      "_pre_train (정규화된 데이터 dat의 shape) : (348, 47)\n",
      "\n",
      "################ [train, valid, test] shape ################\n",
      "size of train/val/test sets 150 69 105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataBasicLoader(args)\n",
    "model = Model(args, data_loader)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "147c265e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (activate): LeakyReLU(negative_slope=0.01)\n",
       "  (highway): Linear(in_features=20, out_features=1, bias=True)\n",
       "  (output): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (lstm): LSTM(1, 64, batch_first=True)\n",
       "  (rac): RegionAwareConv(\n",
       "    (conv_l1): ConvBranch(\n",
       "      (conv): Conv2d(1, 16, kernel_size=(3, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pooling): AdaptiveMaxPool2d(output_size=(1, 47))\n",
       "    )\n",
       "    (conv_l2): ConvBranch(\n",
       "      (conv): Conv2d(1, 16, kernel_size=(5, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pooling): AdaptiveMaxPool2d(output_size=(1, 47))\n",
       "    )\n",
       "    (conv_p1): ConvBranch(\n",
       "      (conv): Conv2d(1, 16, kernel_size=(3, 1), stride=(1, 1), dilation=(2, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pooling): AdaptiveMaxPool2d(output_size=(1, 47))\n",
       "    )\n",
       "    (conv_p2): ConvBranch(\n",
       "      (conv): Conv2d(1, 16, kernel_size=(5, 1), stride=(1, 1), dilation=(2, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pooling): AdaptiveMaxPool2d(output_size=(1, 47))\n",
       "    )\n",
       "    (conv_g): ConvBranch(\n",
       "      (conv): Conv2d(1, 16, kernel_size=(20, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (activate): Tanh()\n",
       "  )\n",
       "  (q_linear): Linear(in_features=80, out_features=64, bias=True)\n",
       "  (k_linear): Linear(in_features=80, out_features=64, bias=True)\n",
       "  (v_linear): Linear(in_features=80, out_features=64, bias=True)\n",
       "  (attn_layer): DotAtt(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (softmax): Softmax(dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8139e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#params: 39606\n"
     ]
    }
   ],
   "source": [
    "if args.cuda:\n",
    "    model.cuda()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=args.lr, weight_decay=args.weight_decay)\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('#params:',pytorch_total_params)\n",
    "\n",
    "time_token = str(time.time()).split('.')[0] # tensorboard model\n",
    "log_token = '%s.d-%s.w-%s.h' % (args.dataset, args.window, args.horizon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f485951a",
   "metadata": {},
   "source": [
    "# 학습 및 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "58aa3f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training\n",
      "Epoch   1|time: 0.29s|train_loss 0.00004003|val_loss 0.00003830\n",
      "Best validation epoch: 1 Mon Aug 15 22:17:51 2022\n",
      "TEST MAE 1709.9204 std 1366.5934 RMSE 2697.3624 RMSEs 2086.2476 MAPE 1.4461 R2 -0.7279 R2s -1.0891\n",
      "Epoch   2|time: 0.04s|train_loss 0.00003838|val_loss 0.00003744\n",
      "Best validation epoch: 2 Mon Aug 15 22:17:51 2022\n",
      "TEST MAE 1694.1718 std 1356.7866 RMSE 2670.4477 RMSEs 2063.4138 MAPE 1.4126 R2 -0.6936 R2s -1.0380\n",
      "Epoch   3|time: 0.04s|train_loss 0.00003684|val_loss 0.00003663\n",
      "Best validation epoch: 3 Mon Aug 15 22:17:51 2022\n",
      "TEST MAE 1678.2847 std 1346.1921 RMSE 2644.2672 RMSEs 2041.2377 MAPE 1.3781 R2 -0.6605 R2s -0.9888\n",
      "Epoch   4|time: 0.03s|train_loss 0.00003536|val_loss 0.00003586\n",
      "Best validation epoch: 4 Mon Aug 15 22:17:51 2022\n",
      "TEST MAE 1662.3519 std 1335.8485 RMSE 2619.5493 RMSEs 2020.0001 MAPE 1.3441 R2 -0.6296 R2s -0.9421\n",
      "Epoch   5|time: 0.03s|train_loss 0.00003387|val_loss 0.00003511\n",
      "Best validation epoch: 5 Mon Aug 15 22:17:51 2022\n",
      "TEST MAE 1645.0227 std 1324.2823 RMSE 2594.6219 RMSEs 1998.6575 MAPE 1.3102 R2 -0.5987 R2s -0.8961\n",
      "Epoch   6|time: 0.03s|train_loss 0.00003244|val_loss 0.00003439\n",
      "Best validation epoch: 6 Mon Aug 15 22:17:51 2022\n",
      "TEST MAE 1626.9789 std 1311.4703 RMSE 2569.7873 RMSEs 1977.6011 MAPE 1.2741 R2 -0.5683 R2s -0.8513\n",
      "Epoch   7|time: 0.03s|train_loss 0.00003102|val_loss 0.00003371\n",
      "Best validation epoch: 7 Mon Aug 15 22:17:52 2022\n",
      "TEST MAE 1607.9445 std 1298.2271 RMSE 2546.0903 RMSEs 1957.1016 MAPE 1.2384 R2 -0.5395 R2s -0.8077\n",
      "Epoch   8|time: 0.03s|train_loss 0.00002958|val_loss 0.00003304\n",
      "Best validation epoch: 8 Mon Aug 15 22:17:52 2022\n",
      "TEST MAE 1588.5706 std 1284.4822 RMSE 2523.1780 RMSEs 1937.3212 MAPE 1.2018 R2 -0.5119 R2s -0.7660\n",
      "Epoch   9|time: 0.03s|train_loss 0.00002818|val_loss 0.00003240\n",
      "Best validation epoch: 9 Mon Aug 15 22:17:52 2022\n",
      "TEST MAE 1567.9836 std 1270.2205 RMSE 2501.1283 RMSEs 1917.9742 MAPE 1.1649 R2 -0.4856 R2s -0.7253\n",
      "Epoch  10|time: 0.03s|train_loss 0.00002675|val_loss 0.00003184\n",
      "Best validation epoch: 10 Mon Aug 15 22:17:52 2022\n",
      "TEST MAE 1547.2229 std 1255.9127 RMSE 2480.1921 RMSEs 1899.4149 MAPE 1.1260 R2 -0.4608 R2s -0.6862\n",
      "Epoch  11|time: 0.03s|train_loss 0.00002531|val_loss 0.00003130\n",
      "Best validation epoch: 11 Mon Aug 15 22:17:52 2022\n",
      "TEST MAE 1524.8124 std 1239.7448 RMSE 2458.9418 RMSEs 1881.0348 MAPE 1.0869 R2 -0.4359 R2s -0.6486\n",
      "Epoch  12|time: 0.03s|train_loss 0.00002392|val_loss 0.00003080\n",
      "Best validation epoch: 12 Mon Aug 15 22:17:52 2022\n",
      "TEST MAE 1504.0151 std 1225.2235 RMSE 2441.9316 RMSEs 1865.5280 MAPE 1.0461 R2 -0.4161 R2s -0.6155\n",
      "Epoch  13|time: 0.03s|train_loss 0.00002254|val_loss 0.00003037\n",
      "Best validation epoch: 13 Mon Aug 15 22:17:52 2022\n",
      "TEST MAE 1481.0385 std 1208.5931 RMSE 2423.9508 RMSEs 1849.4498 MAPE 1.0041 R2 -0.3953 R2s -0.5823\n",
      "Epoch  14|time: 0.03s|train_loss 0.00002122|val_loss 0.00003001\n",
      "Best validation epoch: 14 Mon Aug 15 22:17:52 2022\n",
      "TEST MAE 1457.8942 std 1192.9156 RMSE 2408.6348 RMSEs 1835.1954 MAPE 0.9600 R2 -0.3778 R2s -0.5521\n",
      "Epoch  15|time: 0.03s|train_loss 0.00001993|val_loss 0.00002974\n",
      "Best validation epoch: 15 Mon Aug 15 22:17:52 2022\n",
      "TEST MAE 1433.9210 std 1175.1995 RMSE 2393.7483 RMSEs 1822.0637 MAPE 0.9172 R2 -0.3608 R2s -0.5254\n",
      "Epoch  16|time: 0.03s|train_loss 0.00001866|val_loss 0.00002955\n",
      "Best validation epoch: 16 Mon Aug 15 22:17:52 2022\n",
      "TEST MAE 1411.0468 std 1158.6820 RMSE 2383.4553 RMSEs 1812.3468 MAPE 0.8714 R2 -0.3491 R2s -0.5047\n",
      "Epoch  17|time: 0.03s|train_loss 0.00001754|val_loss 0.00002940\n",
      "Best validation epoch: 17 Mon Aug 15 22:17:52 2022\n",
      "TEST MAE 1387.1847 std 1141.5905 RMSE 2373.4611 RMSEs 1803.0686 MAPE 0.8275 R2 -0.3378 R2s -0.4850\n",
      "Epoch  18|time: 0.03s|train_loss 0.00001641|val_loss 0.00002938\n",
      "Best validation epoch: 18 Mon Aug 15 22:17:52 2022\n",
      "TEST MAE 1363.9622 std 1124.4357 RMSE 2367.1129 RMSEs 1796.5851 MAPE 0.7808 R2 -0.3307 R2s -0.4705\n",
      "Epoch  19|time: 0.03s|train_loss 0.00001549|val_loss 0.00002950\n",
      "Epoch  20|time: 0.03s|train_loss 0.00001460|val_loss 0.00002952\n",
      "Epoch  21|time: 0.03s|train_loss 0.00001390|val_loss 0.00002966\n",
      "Epoch  22|time: 0.03s|train_loss 0.00001317|val_loss 0.00002977\n",
      "Epoch  23|time: 0.03s|train_loss 0.00001263|val_loss 0.00002975\n",
      "Epoch  24|time: 0.03s|train_loss 0.00001210|val_loss 0.00002976\n",
      "Epoch  25|time: 0.03s|train_loss 0.00001166|val_loss 0.00002967\n",
      "Epoch  26|time: 0.03s|train_loss 0.00001123|val_loss 0.00002945\n",
      "Epoch  27|time: 0.03s|train_loss 0.00001079|val_loss 0.00002907\n",
      "Best validation epoch: 27 Mon Aug 15 22:17:52 2022\n",
      "TEST MAE 1154.0033 std 965.4697 RMSE 2296.9810 RMSEs 1737.7701 MAPE 0.4535 R2 -0.2530 R2s -0.3671\n",
      "Epoch  28|time: 0.03s|train_loss 0.00001045|val_loss 0.00002878\n",
      "Best validation epoch: 28 Mon Aug 15 22:17:52 2022\n",
      "TEST MAE 1132.5864 std 947.7286 RMSE 2279.8408 RMSEs 1723.6707 MAPE 0.4342 R2 -0.2344 R2s -0.3439\n",
      "Epoch  29|time: 0.03s|train_loss 0.00001019|val_loss 0.00002834\n",
      "Best validation epoch: 29 Mon Aug 15 22:17:52 2022\n",
      "TEST MAE 1111.2784 std 932.1061 RMSE 2261.4215 RMSEs 1708.7538 MAPE 0.4166 R2 -0.2145 R2s -0.3200\n",
      "Epoch  30|time: 0.03s|train_loss 0.00000985|val_loss 0.00002777\n",
      "Best validation epoch: 30 Mon Aug 15 22:17:52 2022\n",
      "TEST MAE 1091.6472 std 917.6031 RMSE 2242.9624 RMSEs 1693.6479 MAPE 0.4004 R2 -0.1947 R2s -0.2952\n",
      "Epoch  31|time: 0.03s|train_loss 0.00000955|val_loss 0.00002729\n",
      "Best validation epoch: 31 Mon Aug 15 22:17:52 2022\n",
      "TEST MAE 1068.0439 std 897.9681 RMSE 2217.4085 RMSEs 1673.6373 MAPE 0.3807 R2 -0.1677 R2s -0.2644\n",
      "Epoch  32|time: 0.03s|train_loss 0.00000928|val_loss 0.00002687\n",
      "Best validation epoch: 32 Mon Aug 15 22:17:53 2022\n",
      "TEST MAE 1053.0203 std 889.4129 RMSE 2204.4974 RMSEs 1661.9225 MAPE 0.3679 R2 -0.1541 R2s -0.2445\n",
      "Epoch  33|time: 0.03s|train_loss 0.00000911|val_loss 0.00002637\n",
      "Best validation epoch: 33 Mon Aug 15 22:17:53 2022\n",
      "TEST MAE 1033.8650 std 872.2623 RMSE 2180.4178 RMSEs 1644.0590 MAPE 0.3538 R2 -0.1290 R2s -0.2188\n",
      "Epoch  34|time: 0.03s|train_loss 0.00000887|val_loss 0.00002592\n",
      "Best validation epoch: 34 Mon Aug 15 22:17:53 2022\n",
      "TEST MAE 1018.7643 std 863.2917 RMSE 2165.2992 RMSEs 1630.6945 MAPE 0.3414 R2 -0.1134 R2s -0.1966\n",
      "Epoch  35|time: 0.03s|train_loss 0.00000868|val_loss 0.00002548\n",
      "Best validation epoch: 35 Mon Aug 15 22:17:53 2022\n",
      "TEST MAE 1006.9885 std 852.9733 RMSE 2150.6824 RMSEs 1620.0222 MAPE 0.3285 R2 -0.0985 R2s -0.1814\n",
      "Epoch  36|time: 0.03s|train_loss 0.00000853|val_loss 0.00002515\n",
      "Best validation epoch: 36 Mon Aug 15 22:17:53 2022\n",
      "TEST MAE 993.1139 std 843.3318 RMSE 2137.9025 RMSEs 1608.4001 MAPE 0.3170 R2 -0.0854 R2s -0.1620\n",
      "Epoch  37|time: 0.03s|train_loss 0.00000832|val_loss 0.00002481\n",
      "Best validation epoch: 37 Mon Aug 15 22:17:53 2022\n",
      "TEST MAE 984.4825 std 834.9602 RMSE 2124.4548 RMSEs 1599.2472 MAPE 0.3035 R2 -0.0718 R2s -0.1502\n",
      "Epoch  38|time: 0.03s|train_loss 0.00000821|val_loss 0.00002450\n",
      "Best validation epoch: 38 Mon Aug 15 22:17:53 2022\n",
      "TEST MAE 972.1859 std 825.8783 RMSE 2112.5399 RMSEs 1589.6149 MAPE 0.2894 R2 -0.0598 R2s -0.1349\n",
      "Epoch  39|time: 0.03s|train_loss 0.00000808|val_loss 0.00002432\n",
      "Best validation epoch: 39 Mon Aug 15 22:17:53 2022\n",
      "TEST MAE 964.6682 std 819.9968 RMSE 2098.3594 RMSEs 1578.9270 MAPE 0.2784 R2 -0.0457 R2s -0.1196\n",
      "Epoch  40|time: 0.03s|train_loss 0.00000793|val_loss 0.00002410\n",
      "Best validation epoch: 40 Mon Aug 15 22:17:53 2022\n",
      "TEST MAE 956.7321 std 812.0360 RMSE 2090.7454 RMSEs 1572.6653 MAPE 0.2685 R2 -0.0381 R2s -0.1103\n",
      "Epoch  41|time: 0.03s|train_loss 0.00000780|val_loss 0.00002372\n",
      "Best validation epoch: 41 Mon Aug 15 22:17:53 2022\n",
      "TEST MAE 949.0961 std 804.9399 RMSE 2082.7581 RMSEs 1566.9517 MAPE 0.2603 R2 -0.0302 R2s -0.1018\n",
      "Epoch  42|time: 0.03s|train_loss 0.00000772|val_loss 0.00002355\n",
      "Best validation epoch: 42 Mon Aug 15 22:17:53 2022\n",
      "TEST MAE 944.6920 std 803.3868 RMSE 2079.2847 RMSEs 1562.7678 MAPE 0.2474 R2 -0.0267 R2s -0.0938\n",
      "Epoch  43|time: 0.03s|train_loss 0.00000761|val_loss 0.00002316\n",
      "Best validation epoch: 43 Mon Aug 15 22:17:53 2022\n",
      "TEST MAE 939.0164 std 795.4620 RMSE 2064.2777 RMSEs 1553.2720 MAPE 0.2421 R2 -0.0120 R2s -0.0827\n",
      "Epoch  44|time: 0.03s|train_loss 0.00000747|val_loss 0.00002280\n",
      "Best validation epoch: 44 Mon Aug 15 22:17:53 2022\n",
      "TEST MAE 934.8485 std 795.7299 RMSE 2059.7034 RMSEs 1547.3612 MAPE 0.2346 R2 -0.0075 R2s -0.0716\n",
      "Epoch  45|time: 0.03s|train_loss 0.00000738|val_loss 0.00002251\n",
      "Best validation epoch: 45 Mon Aug 15 22:17:53 2022\n",
      "TEST MAE 927.2293 std 789.4618 RMSE 2050.1057 RMSEs 1539.0037 MAPE 0.2321 R2 0.0019 R2s -0.0587\n",
      "Epoch  46|time: 0.03s|train_loss 0.00000734|val_loss 0.00002212\n",
      "Best validation epoch: 46 Mon Aug 15 22:17:53 2022\n",
      "TEST MAE 919.4819 std 785.7701 RMSE 2038.5069 RMSEs 1529.6028 MAPE 0.2243 R2 0.0131 R2s -0.0439\n",
      "Epoch  47|time: 0.03s|train_loss 0.00000719|val_loss 0.00002167\n",
      "Best validation epoch: 47 Mon Aug 15 22:17:53 2022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST MAE 919.9358 std 785.4816 RMSE 2032.2738 RMSEs 1524.8093 MAPE 0.2220 R2 0.0192 R2s -0.0376\n",
      "Epoch  48|time: 0.03s|train_loss 0.00000711|val_loss 0.00002139\n",
      "Best validation epoch: 48 Mon Aug 15 22:17:53 2022\n",
      "TEST MAE 913.2902 std 784.4142 RMSE 2019.9594 RMSEs 1513.9259 MAPE 0.2225 R2 0.0310 R2s -0.0202\n",
      "Epoch  49|time: 0.03s|train_loss 0.00000706|val_loss 0.00002101\n",
      "Best validation epoch: 49 Mon Aug 15 22:17:53 2022\n",
      "TEST MAE 902.0150 std 772.7444 RMSE 2008.4297 RMSEs 1504.2494 MAPE 0.2176 R2 0.0420 R2s -0.0055\n",
      "Epoch  50|time: 0.04s|train_loss 0.00000700|val_loss 0.00002065\n",
      "Best validation epoch: 50 Mon Aug 15 22:17:53 2022\n",
      "TEST MAE 894.2877 std 769.1714 RMSE 1993.0713 RMSEs 1491.7063 MAPE 0.2152 R2 0.0566 R2s 0.0124\n",
      "Epoch  51|time: 0.03s|train_loss 0.00000692|val_loss 0.00002025\n",
      "Best validation epoch: 51 Mon Aug 15 22:17:53 2022\n",
      "TEST MAE 887.7853 std 764.6428 RMSE 1984.9998 RMSEs 1485.3855 MAPE 0.2072 R2 0.0643 R2s 0.0213\n",
      "Epoch  52|time: 0.03s|train_loss 0.00000685|val_loss 0.00001995\n",
      "Best validation epoch: 52 Mon Aug 15 22:17:53 2022\n",
      "TEST MAE 890.9876 std 771.3774 RMSE 1979.9294 RMSEs 1479.8837 MAPE 0.2108 R2 0.0690 R2s 0.0310\n",
      "Epoch  53|time: 0.03s|train_loss 0.00000681|val_loss 0.00001963\n",
      "Best validation epoch: 53 Mon Aug 15 22:17:54 2022\n",
      "TEST MAE 887.9208 std 765.6599 RMSE 1969.0536 RMSEs 1471.5483 MAPE 0.2126 R2 0.0792 R2s 0.0429\n",
      "Epoch  54|time: 0.03s|train_loss 0.00000669|val_loss 0.00001926\n",
      "Best validation epoch: 54 Mon Aug 15 22:17:54 2022\n",
      "TEST MAE 876.0634 std 757.7146 RMSE 1954.7619 RMSEs 1459.6305 MAPE 0.2057 R2 0.0926 R2s 0.0600\n",
      "Epoch  55|time: 0.03s|train_loss 0.00000659|val_loss 0.00001905\n",
      "Best validation epoch: 55 Mon Aug 15 22:17:54 2022\n",
      "TEST MAE 878.1819 std 764.1108 RMSE 1949.4810 RMSEs 1454.3429 MAPE 0.2038 R2 0.0975 R2s 0.0687\n",
      "Epoch  56|time: 0.03s|train_loss 0.00000652|val_loss 0.00001877\n",
      "Best validation epoch: 56 Mon Aug 15 22:17:54 2022\n",
      "TEST MAE 873.8560 std 760.5217 RMSE 1936.8904 RMSEs 1444.8783 MAPE 0.2134 R2 0.1091 R2s 0.0815\n",
      "Epoch  57|time: 0.03s|train_loss 0.00000646|val_loss 0.00001841\n",
      "Best validation epoch: 57 Mon Aug 15 22:17:54 2022\n",
      "TEST MAE 862.1794 std 745.6124 RMSE 1918.7521 RMSEs 1430.7000 MAPE 0.2033 R2 0.1257 R2s 0.1000\n",
      "Epoch  58|time: 0.03s|train_loss 0.00000639|val_loss 0.00001824\n",
      "Best validation epoch: 58 Mon Aug 15 22:17:54 2022\n",
      "TEST MAE 861.4028 std 754.1707 RMSE 1911.1298 RMSEs 1423.1047 MAPE 0.2029 R2 0.1326 R2s 0.1120\n",
      "Epoch  59|time: 0.03s|train_loss 0.00000623|val_loss 0.00001787\n",
      "Best validation epoch: 59 Mon Aug 15 22:17:54 2022\n",
      "TEST MAE 859.7777 std 750.6766 RMSE 1901.3753 RMSEs 1415.5304 MAPE 0.2029 R2 0.1414 R2s 0.1220\n",
      "Epoch  60|time: 0.03s|train_loss 0.00000616|val_loss 0.00001776\n",
      "Best validation epoch: 60 Mon Aug 15 22:17:54 2022\n",
      "TEST MAE 861.9733 std 750.4684 RMSE 1904.0714 RMSEs 1418.0432 MAPE 0.2028 R2 0.1390 R2s 0.1181\n",
      "Epoch  61|time: 0.03s|train_loss 0.00000606|val_loss 0.00001741\n",
      "Best validation epoch: 61 Mon Aug 15 22:17:54 2022\n",
      "TEST MAE 846.5164 std 738.2702 RMSE 1883.5261 RMSEs 1401.4366 MAPE 0.1963 R2 0.1575 R2s 0.1406\n",
      "Epoch  62|time: 0.03s|train_loss 0.00000597|val_loss 0.00001727\n",
      "Best validation epoch: 62 Mon Aug 15 22:17:54 2022\n",
      "TEST MAE 843.5095 std 738.1075 RMSE 1874.1748 RMSEs 1392.9908 MAPE 0.1989 R2 0.1658 R2s 0.1523\n",
      "Epoch  63|time: 0.03s|train_loss 0.00000585|val_loss 0.00001692\n",
      "Best validation epoch: 63 Mon Aug 15 22:17:54 2022\n",
      "TEST MAE 840.6660 std 737.9692 RMSE 1865.2114 RMSEs 1385.8687 MAPE 0.1940 R2 0.1738 R2s 0.1622\n",
      "Epoch  64|time: 0.03s|train_loss 0.00000568|val_loss 0.00001652\n",
      "Best validation epoch: 64 Mon Aug 15 22:17:54 2022\n",
      "TEST MAE 838.5027 std 732.2728 RMSE 1852.7726 RMSEs 1376.5112 MAPE 0.1984 R2 0.1848 R2s 0.1738\n",
      "Epoch  65|time: 0.03s|train_loss 0.00000567|val_loss 0.00001655\n",
      "Epoch  66|time: 0.03s|train_loss 0.00000560|val_loss 0.00001622\n",
      "Best validation epoch: 66 Mon Aug 15 22:17:54 2022\n",
      "TEST MAE 825.0430 std 726.9399 RMSE 1824.0333 RMSEs 1352.0817 MAPE 0.1976 R2 0.2099 R2s 0.2071\n",
      "Epoch  67|time: 0.03s|train_loss 0.00000536|val_loss 0.00001578\n",
      "Best validation epoch: 67 Mon Aug 15 22:17:54 2022\n",
      "TEST MAE 807.9458 std 718.0958 RMSE 1794.4204 RMSEs 1325.2894 MAPE 0.2029 R2 0.2353 R2s 0.2425\n",
      "Epoch  68|time: 0.03s|train_loss 0.00000538|val_loss 0.00001565\n",
      "Best validation epoch: 68 Mon Aug 15 22:17:54 2022\n",
      "TEST MAE 802.8981 std 709.1732 RMSE 1794.4000 RMSEs 1328.3390 MAPE 0.1980 R2 0.2353 R2s 0.2367\n",
      "Epoch  69|time: 0.03s|train_loss 0.00000523|val_loss 0.00001538\n",
      "Best validation epoch: 69 Mon Aug 15 22:17:54 2022\n",
      "TEST MAE 796.2513 std 708.1506 RMSE 1790.5625 RMSEs 1325.1853 MAPE 0.1899 R2 0.2386 R2s 0.2418\n",
      "Epoch  70|time: 0.03s|train_loss 0.00000513|val_loss 0.00001536\n",
      "Best validation epoch: 70 Mon Aug 15 22:17:54 2022\n",
      "TEST MAE 804.0440 std 707.4549 RMSE 1778.9875 RMSEs 1318.1907 MAPE 0.2068 R2 0.2484 R2s 0.2475\n",
      "Epoch  71|time: 0.03s|train_loss 0.00000501|val_loss 0.00001496\n",
      "Best validation epoch: 71 Mon Aug 15 22:17:54 2022\n",
      "TEST MAE 801.3291 std 707.1608 RMSE 1775.2282 RMSEs 1314.0917 MAPE 0.1958 R2 0.2516 R2s 0.2526\n",
      "Epoch  72|time: 0.03s|train_loss 0.00000492|val_loss 0.00001504\n",
      "Epoch  73|time: 0.03s|train_loss 0.00000497|val_loss 0.00001476\n",
      "Best validation epoch: 73 Mon Aug 15 22:17:54 2022\n",
      "TEST MAE 791.1049 std 698.4567 RMSE 1761.4621 RMSEs 1303.0844 MAPE 0.1926 R2 0.2632 R2s 0.2658\n",
      "Epoch  74|time: 0.03s|train_loss 0.00000486|val_loss 0.00001452\n",
      "Best validation epoch: 74 Mon Aug 15 22:17:54 2022\n",
      "TEST MAE 785.7687 std 698.7175 RMSE 1748.6225 RMSEs 1291.8441 MAPE 0.1804 R2 0.2739 R2s 0.2803\n",
      "Epoch  75|time: 0.03s|train_loss 0.00000482|val_loss 0.00001459\n",
      "Epoch  76|time: 0.03s|train_loss 0.00000474|val_loss 0.00001407\n",
      "Best validation epoch: 76 Mon Aug 15 22:17:54 2022\n",
      "TEST MAE 786.3724 std 697.6191 RMSE 1735.8183 RMSEs 1281.8792 MAPE 0.1887 R2 0.2845 R2s 0.2931\n",
      "Epoch  77|time: 0.03s|train_loss 0.00000467|val_loss 0.00001446\n",
      "Epoch  78|time: 0.03s|train_loss 0.00000462|val_loss 0.00001452\n",
      "Epoch  79|time: 0.03s|train_loss 0.00000455|val_loss 0.00001418\n",
      "Epoch  80|time: 0.03s|train_loss 0.00000460|val_loss 0.00001416\n",
      "Epoch  81|time: 0.03s|train_loss 0.00000453|val_loss 0.00001408\n",
      "Epoch  82|time: 0.03s|train_loss 0.00000447|val_loss 0.00001422\n",
      "Epoch  83|time: 0.03s|train_loss 0.00000442|val_loss 0.00001401\n",
      "Best validation epoch: 83 Mon Aug 15 22:17:55 2022\n",
      "TEST MAE 778.7734 std 682.2426 RMSE 1693.2247 RMSEs 1252.2954 MAPE 0.1782 R2 0.3191 R2s 0.3234\n",
      "Epoch  84|time: 0.03s|train_loss 0.00000445|val_loss 0.00001410\n",
      "Epoch  85|time: 0.03s|train_loss 0.00000431|val_loss 0.00001424\n",
      "Epoch  86|time: 0.03s|train_loss 0.00000425|val_loss 0.00001403\n",
      "Epoch  87|time: 0.03s|train_loss 0.00000432|val_loss 0.00001380\n",
      "Best validation epoch: 87 Mon Aug 15 22:17:55 2022\n",
      "TEST MAE 773.9407 std 675.7041 RMSE 1700.8166 RMSEs 1259.5312 MAPE 0.1677 R2 0.3130 R2s 0.3148\n",
      "Epoch  88|time: 0.03s|train_loss 0.00000420|val_loss 0.00001351\n",
      "Best validation epoch: 88 Mon Aug 15 22:17:55 2022\n",
      "TEST MAE 765.6788 std 677.9764 RMSE 1681.2388 RMSEs 1241.3650 MAPE 0.1638 R2 0.3287 R2s 0.3374\n",
      "Epoch  89|time: 0.03s|train_loss 0.00000421|val_loss 0.00001373\n",
      "Epoch  90|time: 0.03s|train_loss 0.00000416|val_loss 0.00001352\n",
      "Epoch  91|time: 0.03s|train_loss 0.00000409|val_loss 0.00001311\n",
      "Best validation epoch: 91 Mon Aug 15 22:17:55 2022\n",
      "TEST MAE 756.3555 std 666.2980 RMSE 1651.5313 RMSEs 1220.3591 MAPE 0.1587 R2 0.3523 R2s 0.3588\n",
      "Epoch  92|time: 0.03s|train_loss 0.00000407|val_loss 0.00001317\n",
      "Epoch  93|time: 0.03s|train_loss 0.00000405|val_loss 0.00001336\n",
      "Epoch  94|time: 0.03s|train_loss 0.00000401|val_loss 0.00001315\n",
      "Epoch  95|time: 0.03s|train_loss 0.00000391|val_loss 0.00001319\n",
      "Epoch  96|time: 0.03s|train_loss 0.00000400|val_loss 0.00001293\n",
      "Best validation epoch: 96 Mon Aug 15 22:17:55 2022\n",
      "TEST MAE 734.3583 std 638.9661 RMSE 1610.7148 RMSEs 1189.9022 MAPE 0.1650 R2 0.3839 R2s 0.3913\n",
      "Epoch  97|time: 0.03s|train_loss 0.00000387|val_loss 0.00001286\n",
      "Best validation epoch: 97 Mon Aug 15 22:17:55 2022\n",
      "TEST MAE 743.0244 std 649.1636 RMSE 1632.3881 RMSEs 1205.6200 MAPE 0.1588 R2 0.3672 R2s 0.3749\n",
      "Epoch  98|time: 0.03s|train_loss 0.00000387|val_loss 0.00001258\n",
      "Best validation epoch: 98 Mon Aug 15 22:17:55 2022\n",
      "TEST MAE 736.8011 std 644.4228 RMSE 1615.3714 RMSEs 1191.5090 MAPE 0.1634 R2 0.3803 R2s 0.3918\n",
      "Epoch  99|time: 0.04s|train_loss 0.00000388|val_loss 0.00001286\n",
      "Epoch 100|time: 0.03s|train_loss 0.00000386|val_loss 0.00001300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101|time: 0.03s|train_loss 0.00000384|val_loss 0.00001287\n",
      "Epoch 102|time: 0.03s|train_loss 0.00000386|val_loss 0.00001292\n",
      "Epoch 103|time: 0.03s|train_loss 0.00000379|val_loss 0.00001328\n",
      "Epoch 104|time: 0.03s|train_loss 0.00000379|val_loss 0.00001292\n",
      "Epoch 105|time: 0.03s|train_loss 0.00000379|val_loss 0.00001300\n",
      "Epoch 106|time: 0.03s|train_loss 0.00000365|val_loss 0.00001279\n",
      "Epoch 107|time: 0.03s|train_loss 0.00000360|val_loss 0.00001288\n",
      "Epoch 108|time: 0.03s|train_loss 0.00000358|val_loss 0.00001283\n",
      "Epoch 109|time: 0.03s|train_loss 0.00000359|val_loss 0.00001300\n",
      "Epoch 110|time: 0.03s|train_loss 0.00000356|val_loss 0.00001285\n",
      "Epoch 111|time: 0.03s|train_loss 0.00000356|val_loss 0.00001264\n",
      "Epoch 112|time: 0.03s|train_loss 0.00000356|val_loss 0.00001260\n",
      "Epoch 113|time: 0.03s|train_loss 0.00000350|val_loss 0.00001256\n",
      "Best validation epoch: 113 Mon Aug 15 22:17:56 2022\n",
      "TEST MAE 724.3082 std 622.8315 RMSE 1557.3343 RMSEs 1153.2434 MAPE 0.1541 R2 0.4240 R2s 0.4248\n",
      "Epoch 114|time: 0.03s|train_loss 0.00000352|val_loss 0.00001229\n",
      "Best validation epoch: 114 Mon Aug 15 22:17:56 2022\n",
      "TEST MAE 723.4411 std 620.7381 RMSE 1542.8432 RMSEs 1144.4868 MAPE 0.1582 R2 0.4347 R2s 0.4321\n",
      "Epoch 115|time: 0.03s|train_loss 0.00000347|val_loss 0.00001206\n",
      "Best validation epoch: 115 Mon Aug 15 22:17:56 2022\n",
      "TEST MAE 722.8683 std 617.2692 RMSE 1541.3222 RMSEs 1145.9673 MAPE 0.1524 R2 0.4358 R2s 0.4288\n",
      "Epoch 116|time: 0.03s|train_loss 0.00000344|val_loss 0.00001243\n",
      "Epoch 117|time: 0.03s|train_loss 0.00000342|val_loss 0.00001218\n",
      "Epoch 118|time: 0.03s|train_loss 0.00000331|val_loss 0.00001224\n",
      "Epoch 119|time: 0.03s|train_loss 0.00000340|val_loss 0.00001191\n",
      "Best validation epoch: 119 Mon Aug 15 22:17:56 2022\n",
      "TEST MAE 713.7470 std 609.0050 RMSE 1530.4877 RMSEs 1133.4089 MAPE 0.1454 R2 0.4437 R2s 0.4433\n",
      "Epoch 120|time: 0.03s|train_loss 0.00000338|val_loss 0.00001189\n",
      "Best validation epoch: 120 Mon Aug 15 22:17:56 2022\n",
      "TEST MAE 718.6850 std 613.5931 RMSE 1529.2777 RMSEs 1135.4515 MAPE 0.1499 R2 0.4446 R2s 0.4391\n",
      "Epoch 121|time: 0.03s|train_loss 0.00000332|val_loss 0.00001184\n",
      "Best validation epoch: 121 Mon Aug 15 22:17:56 2022\n",
      "TEST MAE 717.7592 std 614.8721 RMSE 1545.8144 RMSEs 1142.9900 MAPE 0.1465 R2 0.4325 R2s 0.4352\n",
      "Epoch 122|time: 0.03s|train_loss 0.00000320|val_loss 0.00001167\n",
      "Best validation epoch: 122 Mon Aug 15 22:17:56 2022\n",
      "TEST MAE 705.4164 std 602.2476 RMSE 1506.6420 RMSEs 1115.9128 MAPE 0.1476 R2 0.4609 R2s 0.4598\n",
      "Epoch 123|time: 0.03s|train_loss 0.00000322|val_loss 0.00001168\n",
      "Epoch 124|time: 0.03s|train_loss 0.00000324|val_loss 0.00001131\n",
      "Best validation epoch: 124 Mon Aug 15 22:17:56 2022\n",
      "TEST MAE 711.2870 std 603.7396 RMSE 1503.7917 RMSEs 1116.5354 MAPE 0.1533 R2 0.4630 R2s 0.4565\n",
      "Epoch 125|time: 0.03s|train_loss 0.00000317|val_loss 0.00001144\n",
      "Epoch 126|time: 0.03s|train_loss 0.00000308|val_loss 0.00001125\n",
      "Best validation epoch: 126 Mon Aug 15 22:17:56 2022\n",
      "TEST MAE 700.1573 std 594.5667 RMSE 1484.2032 RMSEs 1101.1907 MAPE 0.1525 R2 0.4769 R2s 0.4711\n",
      "Epoch 127|time: 0.03s|train_loss 0.00000311|val_loss 0.00001138\n",
      "Epoch 128|time: 0.03s|train_loss 0.00000309|val_loss 0.00001135\n",
      "Epoch 129|time: 0.03s|train_loss 0.00000301|val_loss 0.00001170\n",
      "Epoch 130|time: 0.03s|train_loss 0.00000303|val_loss 0.00001132\n",
      "Epoch 131|time: 0.03s|train_loss 0.00000296|val_loss 0.00001156\n",
      "Epoch 132|time: 0.03s|train_loss 0.00000303|val_loss 0.00001139\n",
      "Epoch 133|time: 0.03s|train_loss 0.00000292|val_loss 0.00001180\n",
      "Epoch 134|time: 0.04s|train_loss 0.00000292|val_loss 0.00001149\n",
      "Epoch 135|time: 0.03s|train_loss 0.00000297|val_loss 0.00001136\n",
      "Epoch 136|time: 0.03s|train_loss 0.00000289|val_loss 0.00001148\n",
      "Epoch 137|time: 0.03s|train_loss 0.00000297|val_loss 0.00001161\n",
      "Epoch 138|time: 0.03s|train_loss 0.00000288|val_loss 0.00001166\n",
      "Epoch 139|time: 0.03s|train_loss 0.00000282|val_loss 0.00001138\n",
      "Epoch 140|time: 0.03s|train_loss 0.00000279|val_loss 0.00001135\n",
      "Epoch 141|time: 0.03s|train_loss 0.00000282|val_loss 0.00001173\n",
      "Epoch 142|time: 0.03s|train_loss 0.00000270|val_loss 0.00001173\n",
      "Epoch 143|time: 0.03s|train_loss 0.00000274|val_loss 0.00001118\n",
      "Best validation epoch: 143 Mon Aug 15 22:17:57 2022\n",
      "TEST MAE 753.9476 std 636.7258 RMSE 1538.0314 RMSEs 1149.0983 MAPE 0.1533 R2 0.4382 R2s 0.4182\n",
      "Epoch 144|time: 0.03s|train_loss 0.00000273|val_loss 0.00001142\n",
      "Epoch 145|time: 0.03s|train_loss 0.00000279|val_loss 0.00001116\n",
      "Best validation epoch: 145 Mon Aug 15 22:17:57 2022\n",
      "TEST MAE 755.7778 std 638.4745 RMSE 1539.0401 RMSEs 1148.2391 MAPE 0.1490 R2 0.4375 R2s 0.4203\n",
      "Epoch 146|time: 0.03s|train_loss 0.00000268|val_loss 0.00001135\n",
      "Epoch 147|time: 0.03s|train_loss 0.00000262|val_loss 0.00001128\n",
      "Epoch 148|time: 0.03s|train_loss 0.00000269|val_loss 0.00001117\n",
      "Epoch 149|time: 0.03s|train_loss 0.00000271|val_loss 0.00001132\n",
      "Epoch 150|time: 0.03s|train_loss 0.00000265|val_loss 0.00001108\n",
      "Best validation epoch: 150 Mon Aug 15 22:17:57 2022\n",
      "TEST MAE 763.3695 std 644.4048 RMSE 1549.6042 RMSEs 1157.6841 MAPE 0.1428 R2 0.4297 R2s 0.4095\n",
      "Epoch 151|time: 0.03s|train_loss 0.00000254|val_loss 0.00001145\n",
      "Epoch 152|time: 0.03s|train_loss 0.00000262|val_loss 0.00001132\n",
      "Epoch 153|time: 0.03s|train_loss 0.00000252|val_loss 0.00001122\n",
      "Epoch 154|time: 0.03s|train_loss 0.00000261|val_loss 0.00001180\n",
      "Epoch 155|time: 0.03s|train_loss 0.00000250|val_loss 0.00001179\n",
      "Epoch 156|time: 0.03s|train_loss 0.00000254|val_loss 0.00001099\n",
      "Best validation epoch: 156 Mon Aug 15 22:17:57 2022\n",
      "TEST MAE 803.0156 std 675.1923 RMSE 1598.8470 RMSEs 1198.3649 MAPE 0.1455 R2 0.3929 R2s 0.3639\n",
      "Epoch 157|time: 0.04s|train_loss 0.00000245|val_loss 0.00001137\n",
      "Epoch 158|time: 0.03s|train_loss 0.00000258|val_loss 0.00001145\n",
      "Epoch 159|time: 0.03s|train_loss 0.00000240|val_loss 0.00001162\n",
      "Epoch 160|time: 0.04s|train_loss 0.00000250|val_loss 0.00001128\n",
      "Epoch 161|time: 0.03s|train_loss 0.00000243|val_loss 0.00001125\n",
      "Epoch 162|time: 0.03s|train_loss 0.00000236|val_loss 0.00001146\n",
      "Epoch 163|time: 0.03s|train_loss 0.00000247|val_loss 0.00001130\n",
      "Epoch 164|time: 0.03s|train_loss 0.00000232|val_loss 0.00001086\n",
      "Best validation epoch: 164 Mon Aug 15 22:17:58 2022\n",
      "TEST MAE 803.1863 std 672.0373 RMSE 1595.0172 RMSEs 1201.1361 MAPE 0.1375 R2 0.3958 R2s 0.3540\n",
      "Epoch 165|time: 0.03s|train_loss 0.00000232|val_loss 0.00001116\n",
      "Epoch 166|time: 0.03s|train_loss 0.00000239|val_loss 0.00001111\n",
      "Epoch 167|time: 0.03s|train_loss 0.00000235|val_loss 0.00001169\n",
      "Epoch 168|time: 0.03s|train_loss 0.00000235|val_loss 0.00001184\n",
      "Epoch 169|time: 0.03s|train_loss 0.00000228|val_loss 0.00001153\n",
      "Epoch 170|time: 0.03s|train_loss 0.00000231|val_loss 0.00001114\n",
      "Epoch 171|time: 0.03s|train_loss 0.00000235|val_loss 0.00001083\n",
      "Best validation epoch: 171 Mon Aug 15 22:17:58 2022\n",
      "TEST MAE 795.2841 std 669.4221 RMSE 1573.6945 RMSEs 1180.4059 MAPE 0.1437 R2 0.4119 R2s 0.3808\n",
      "Epoch 172|time: 0.03s|train_loss 0.00000236|val_loss 0.00001070\n",
      "Best validation epoch: 172 Mon Aug 15 22:17:58 2022\n",
      "TEST MAE 801.6831 std 674.1953 RMSE 1587.1866 RMSEs 1193.7469 MAPE 0.1436 R2 0.4017 R2s 0.3649\n",
      "Epoch 173|time: 0.03s|train_loss 0.00000226|val_loss 0.00001151\n",
      "Epoch 174|time: 0.03s|train_loss 0.00000220|val_loss 0.00001185\n",
      "Epoch 175|time: 0.03s|train_loss 0.00000220|val_loss 0.00001181\n",
      "Epoch 176|time: 0.03s|train_loss 0.00000217|val_loss 0.00001162\n",
      "Epoch 177|time: 0.03s|train_loss 0.00000222|val_loss 0.00001141\n",
      "Epoch 178|time: 0.03s|train_loss 0.00000223|val_loss 0.00001112\n",
      "Epoch 179|time: 0.03s|train_loss 0.00000222|val_loss 0.00001084\n",
      "Epoch 180|time: 0.03s|train_loss 0.00000217|val_loss 0.00001040\n",
      "Best validation epoch: 180 Mon Aug 15 22:17:58 2022\n",
      "TEST MAE 803.3043 std 677.6408 RMSE 1597.2653 RMSEs 1198.7297 MAPE 0.1430 R2 0.3941 R2s 0.3615\n",
      "Epoch 181|time: 0.03s|train_loss 0.00000216|val_loss 0.00001118\n",
      "Epoch 182|time: 0.03s|train_loss 0.00000225|val_loss 0.00001118\n",
      "Epoch 183|time: 0.03s|train_loss 0.00000222|val_loss 0.00001139\n",
      "Epoch 184|time: 0.03s|train_loss 0.00000220|val_loss 0.00001108\n",
      "Epoch 185|time: 0.03s|train_loss 0.00000220|val_loss 0.00001092\n",
      "Epoch 186|time: 0.03s|train_loss 0.00000216|val_loss 0.00001115\n",
      "Epoch 187|time: 0.03s|train_loss 0.00000216|val_loss 0.00001088\n",
      "Epoch 188|time: 0.03s|train_loss 0.00000212|val_loss 0.00001130\n",
      "Epoch 189|time: 0.03s|train_loss 0.00000212|val_loss 0.00001127\n",
      "Epoch 190|time: 0.03s|train_loss 0.00000217|val_loss 0.00001090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191|time: 0.03s|train_loss 0.00000219|val_loss 0.00001113\n",
      "Epoch 192|time: 0.03s|train_loss 0.00000215|val_loss 0.00001123\n",
      "Epoch 193|time: 0.03s|train_loss 0.00000204|val_loss 0.00001115\n",
      "Epoch 194|time: 0.04s|train_loss 0.00000206|val_loss 0.00001087\n",
      "Epoch 195|time: 0.04s|train_loss 0.00000208|val_loss 0.00001036\n",
      "Best validation epoch: 195 Mon Aug 15 22:17:59 2022\n",
      "TEST MAE 807.6915 std 680.8306 RMSE 1597.8985 RMSEs 1203.0796 MAPE 0.1397 R2 0.3936 R2s 0.3527\n",
      "Epoch 196|time: 0.03s|train_loss 0.00000212|val_loss 0.00001078\n",
      "Epoch 197|time: 0.04s|train_loss 0.00000213|val_loss 0.00001079\n",
      "Epoch 198|time: 0.03s|train_loss 0.00000209|val_loss 0.00001047\n",
      "Epoch 199|time: 0.04s|train_loss 0.00000213|val_loss 0.00001086\n",
      "Epoch 200|time: 0.03s|train_loss 0.00000205|val_loss 0.00001099\n",
      "Epoch 201|time: 0.03s|train_loss 0.00000197|val_loss 0.00001057\n",
      "Epoch 202|time: 0.03s|train_loss 0.00000205|val_loss 0.00001064\n",
      "Epoch 203|time: 0.03s|train_loss 0.00000197|val_loss 0.00001052\n",
      "Epoch 204|time: 0.03s|train_loss 0.00000199|val_loss 0.00001103\n",
      "Epoch 205|time: 0.03s|train_loss 0.00000194|val_loss 0.00001057\n",
      "Epoch 206|time: 0.03s|train_loss 0.00000219|val_loss 0.00001048\n",
      "Epoch 207|time: 0.03s|train_loss 0.00000208|val_loss 0.00001063\n",
      "Epoch 208|time: 0.03s|train_loss 0.00000204|val_loss 0.00001058\n",
      "Epoch 209|time: 0.03s|train_loss 0.00000201|val_loss 0.00001026\n",
      "Best validation epoch: 209 Mon Aug 15 22:17:59 2022\n",
      "TEST MAE 812.3380 std 682.2229 RMSE 1604.0782 RMSEs 1209.6984 MAPE 0.1411 R2 0.3889 R2s 0.3430\n",
      "Epoch 210|time: 0.03s|train_loss 0.00000195|val_loss 0.00001072\n",
      "Epoch 211|time: 0.03s|train_loss 0.00000201|val_loss 0.00001081\n",
      "Epoch 212|time: 0.03s|train_loss 0.00000201|val_loss 0.00001036\n",
      "Epoch 213|time: 0.03s|train_loss 0.00000202|val_loss 0.00001041\n",
      "Epoch 214|time: 0.03s|train_loss 0.00000190|val_loss 0.00001033\n",
      "Epoch 215|time: 0.03s|train_loss 0.00000196|val_loss 0.00001010\n",
      "Best validation epoch: 215 Mon Aug 15 22:17:59 2022\n",
      "TEST MAE 787.8151 std 666.0896 RMSE 1573.2747 RMSEs 1181.0502 MAPE 0.1347 R2 0.4122 R2s 0.3799\n",
      "Epoch 216|time: 0.03s|train_loss 0.00000197|val_loss 0.00001008\n",
      "Best validation epoch: 216 Mon Aug 15 22:17:59 2022\n",
      "TEST MAE 778.6516 std 661.2136 RMSE 1556.7646 RMSEs 1169.6542 MAPE 0.1353 R2 0.4245 R2s 0.3890\n",
      "Epoch 217|time: 0.03s|train_loss 0.00000202|val_loss 0.00001037\n",
      "Epoch 218|time: 0.03s|train_loss 0.00000197|val_loss 0.00001016\n",
      "Epoch 219|time: 0.03s|train_loss 0.00000194|val_loss 0.00001002\n",
      "Best validation epoch: 219 Mon Aug 15 22:17:59 2022\n",
      "TEST MAE 781.6525 std 657.2686 RMSE 1561.6016 RMSEs 1175.4335 MAPE 0.1266 R2 0.4209 R2s 0.3820\n",
      "Epoch 220|time: 0.03s|train_loss 0.00000203|val_loss 0.00001035\n",
      "Epoch 221|time: 0.03s|train_loss 0.00000194|val_loss 0.00001035\n",
      "Epoch 222|time: 0.03s|train_loss 0.00000200|val_loss 0.00001013\n",
      "Epoch 223|time: 0.03s|train_loss 0.00000199|val_loss 0.00001042\n",
      "Epoch 224|time: 0.03s|train_loss 0.00000194|val_loss 0.00001022\n",
      "Epoch 225|time: 0.03s|train_loss 0.00000190|val_loss 0.00000994\n",
      "Best validation epoch: 225 Mon Aug 15 22:18:00 2022\n",
      "TEST MAE 779.7943 std 660.4075 RMSE 1567.1636 RMSEs 1179.2476 MAPE 0.1221 R2 0.4167 R2s 0.3783\n",
      "Epoch 226|time: 0.03s|train_loss 0.00000191|val_loss 0.00001030\n",
      "Epoch 227|time: 0.03s|train_loss 0.00000196|val_loss 0.00000986\n",
      "Best validation epoch: 227 Mon Aug 15 22:18:00 2022\n",
      "TEST MAE 780.1579 std 657.6356 RMSE 1550.9378 RMSEs 1169.7538 MAPE 0.1303 R2 0.4288 R2s 0.3863\n",
      "Epoch 228|time: 0.03s|train_loss 0.00000194|val_loss 0.00001030\n",
      "Epoch 229|time: 0.03s|train_loss 0.00000195|val_loss 0.00001026\n",
      "Epoch 230|time: 0.03s|train_loss 0.00000192|val_loss 0.00001053\n",
      "Epoch 231|time: 0.03s|train_loss 0.00000192|val_loss 0.00001040\n",
      "Epoch 232|time: 0.03s|train_loss 0.00000194|val_loss 0.00001045\n",
      "Epoch 233|time: 0.03s|train_loss 0.00000197|val_loss 0.00001056\n",
      "Epoch 234|time: 0.03s|train_loss 0.00000186|val_loss 0.00001021\n",
      "Epoch 235|time: 0.03s|train_loss 0.00000188|val_loss 0.00001036\n",
      "Epoch 236|time: 0.03s|train_loss 0.00000199|val_loss 0.00001030\n",
      "Epoch 237|time: 0.03s|train_loss 0.00000190|val_loss 0.00001037\n",
      "Epoch 238|time: 0.03s|train_loss 0.00000195|val_loss 0.00001025\n",
      "Epoch 239|time: 0.03s|train_loss 0.00000186|val_loss 0.00001019\n",
      "Epoch 240|time: 0.03s|train_loss 0.00000180|val_loss 0.00001045\n",
      "Epoch 241|time: 0.03s|train_loss 0.00000183|val_loss 0.00001065\n",
      "Epoch 242|time: 0.03s|train_loss 0.00000190|val_loss 0.00001049\n",
      "Epoch 243|time: 0.03s|train_loss 0.00000191|val_loss 0.00000998\n",
      "Epoch 244|time: 0.03s|train_loss 0.00000193|val_loss 0.00001035\n",
      "Epoch 245|time: 0.03s|train_loss 0.00000189|val_loss 0.00000985\n",
      "Best validation epoch: 245 Mon Aug 15 22:18:00 2022\n",
      "TEST MAE 760.9813 std 646.3867 RMSE 1539.2248 RMSEs 1157.4023 MAPE 0.1233 R2 0.4374 R2s 0.4015\n",
      "Epoch 246|time: 0.03s|train_loss 0.00000197|val_loss 0.00001007\n",
      "Epoch 247|time: 0.03s|train_loss 0.00000185|val_loss 0.00000994\n",
      "Epoch 248|time: 0.03s|train_loss 0.00000196|val_loss 0.00000986\n",
      "Epoch 249|time: 0.03s|train_loss 0.00000187|val_loss 0.00001041\n",
      "Epoch 250|time: 0.03s|train_loss 0.00000181|val_loss 0.00000998\n",
      "Epoch 251|time: 0.03s|train_loss 0.00000192|val_loss 0.00001018\n",
      "Epoch 252|time: 0.03s|train_loss 0.00000185|val_loss 0.00000999\n",
      "Epoch 253|time: 0.03s|train_loss 0.00000191|val_loss 0.00000986\n",
      "Epoch 254|time: 0.03s|train_loss 0.00000190|val_loss 0.00001012\n",
      "Epoch 255|time: 0.03s|train_loss 0.00000178|val_loss 0.00001011\n",
      "Epoch 256|time: 0.03s|train_loss 0.00000186|val_loss 0.00001034\n",
      "Epoch 257|time: 0.03s|train_loss 0.00000187|val_loss 0.00001035\n",
      "Epoch 258|time: 0.03s|train_loss 0.00000179|val_loss 0.00001041\n",
      "Epoch 259|time: 0.03s|train_loss 0.00000183|val_loss 0.00001031\n",
      "Epoch 260|time: 0.03s|train_loss 0.00000188|val_loss 0.00001004\n",
      "Epoch 261|time: 0.03s|train_loss 0.00000194|val_loss 0.00000967\n",
      "Best validation epoch: 261 Mon Aug 15 22:18:01 2022\n",
      "TEST MAE 770.8597 std 654.6683 RMSE 1561.0463 RMSEs 1174.9600 MAPE 0.1166 R2 0.4213 R2s 0.3829\n",
      "Epoch 262|time: 0.03s|train_loss 0.00000190|val_loss 0.00000950\n",
      "Best validation epoch: 262 Mon Aug 15 22:18:01 2022\n",
      "TEST MAE 768.6887 std 650.9538 RMSE 1548.4022 RMSEs 1164.7290 MAPE 0.1186 R2 0.4306 R2s 0.3942\n",
      "Epoch 263|time: 0.03s|train_loss 0.00000181|val_loss 0.00000984\n",
      "Epoch 264|time: 0.03s|train_loss 0.00000192|val_loss 0.00001021\n",
      "Epoch 265|time: 0.03s|train_loss 0.00000185|val_loss 0.00000939\n",
      "Best validation epoch: 265 Mon Aug 15 22:18:01 2022\n",
      "TEST MAE 759.6667 std 646.2589 RMSE 1515.0037 RMSEs 1141.6194 MAPE 0.1298 R2 0.4549 R2s 0.4167\n",
      "Epoch 266|time: 0.03s|train_loss 0.00000175|val_loss 0.00000944\n",
      "Epoch 267|time: 0.03s|train_loss 0.00000181|val_loss 0.00000978\n",
      "Epoch 268|time: 0.03s|train_loss 0.00000188|val_loss 0.00001003\n",
      "Epoch 269|time: 0.03s|train_loss 0.00000178|val_loss 0.00000942\n",
      "Epoch 270|time: 0.03s|train_loss 0.00000184|val_loss 0.00000946\n",
      "Epoch 271|time: 0.03s|train_loss 0.00000185|val_loss 0.00000946\n",
      "Epoch 272|time: 0.03s|train_loss 0.00000181|val_loss 0.00000973\n",
      "Epoch 273|time: 0.03s|train_loss 0.00000185|val_loss 0.00000982\n",
      "Epoch 274|time: 0.03s|train_loss 0.00000174|val_loss 0.00000989\n",
      "Epoch 275|time: 0.03s|train_loss 0.00000188|val_loss 0.00000982\n",
      "Epoch 276|time: 0.03s|train_loss 0.00000187|val_loss 0.00000968\n",
      "Epoch 277|time: 0.03s|train_loss 0.00000172|val_loss 0.00000940\n",
      "Epoch 278|time: 0.03s|train_loss 0.00000174|val_loss 0.00000988\n",
      "Epoch 279|time: 0.03s|train_loss 0.00000179|val_loss 0.00001005\n",
      "Epoch 280|time: 0.03s|train_loss 0.00000175|val_loss 0.00000959\n",
      "Epoch 281|time: 0.03s|train_loss 0.00000179|val_loss 0.00000957\n",
      "Epoch 282|time: 0.03s|train_loss 0.00000176|val_loss 0.00000964\n",
      "Epoch 283|time: 0.03s|train_loss 0.00000189|val_loss 0.00000977\n",
      "Epoch 284|time: 0.03s|train_loss 0.00000171|val_loss 0.00000992\n",
      "Epoch 285|time: 0.03s|train_loss 0.00000178|val_loss 0.00000991\n",
      "Epoch 286|time: 0.03s|train_loss 0.00000188|val_loss 0.00000936\n",
      "Best validation epoch: 286 Mon Aug 15 22:18:02 2022\n",
      "TEST MAE 748.6592 std 637.5879 RMSE 1519.1362 RMSEs 1140.6943 MAPE 0.1292 R2 0.4519 R2s 0.4212\n",
      "Epoch 287|time: 0.03s|train_loss 0.00000172|val_loss 0.00000966\n",
      "Epoch 288|time: 0.03s|train_loss 0.00000181|val_loss 0.00000979\n",
      "Epoch 289|time: 0.03s|train_loss 0.00000181|val_loss 0.00000960\n",
      "Epoch 290|time: 0.03s|train_loss 0.00000177|val_loss 0.00000949\n",
      "Epoch 291|time: 0.03s|train_loss 0.00000180|val_loss 0.00000950\n",
      "Epoch 292|time: 0.03s|train_loss 0.00000175|val_loss 0.00000927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation epoch: 292 Mon Aug 15 22:18:02 2022\n",
      "TEST MAE 738.6489 std 631.1042 RMSE 1504.0779 RMSEs 1128.5024 MAPE 0.1128 R2 0.4628 R2s 0.4333\n",
      "Epoch 293|time: 0.03s|train_loss 0.00000179|val_loss 0.00000949\n",
      "Epoch 294|time: 0.04s|train_loss 0.00000178|val_loss 0.00000937\n",
      "Epoch 295|time: 0.03s|train_loss 0.00000175|val_loss 0.00000964\n",
      "Epoch 296|time: 0.03s|train_loss 0.00000179|val_loss 0.00000946\n",
      "Epoch 297|time: 0.03s|train_loss 0.00000172|val_loss 0.00000957\n",
      "Epoch 298|time: 0.03s|train_loss 0.00000179|val_loss 0.00000970\n",
      "Epoch 299|time: 0.03s|train_loss 0.00000179|val_loss 0.00000966\n",
      "Epoch 300|time: 0.03s|train_loss 0.00000183|val_loss 0.00000912\n",
      "Best validation epoch: 300 Mon Aug 15 22:18:02 2022\n",
      "TEST MAE 748.0098 std 638.6353 RMSE 1515.6972 RMSEs 1138.0139 MAPE 0.1254 R2 0.4544 R2s 0.4239\n",
      "Epoch 301|time: 0.03s|train_loss 0.00000170|val_loss 0.00000950\n",
      "Epoch 302|time: 0.03s|train_loss 0.00000176|val_loss 0.00000931\n",
      "Epoch 303|time: 0.03s|train_loss 0.00000172|val_loss 0.00000973\n",
      "Epoch 304|time: 0.03s|train_loss 0.00000172|val_loss 0.00000979\n",
      "Epoch 305|time: 0.03s|train_loss 0.00000177|val_loss 0.00000987\n",
      "Epoch 306|time: 0.03s|train_loss 0.00000176|val_loss 0.00000970\n",
      "Epoch 307|time: 0.03s|train_loss 0.00000173|val_loss 0.00000946\n",
      "Epoch 308|time: 0.03s|train_loss 0.00000175|val_loss 0.00000961\n",
      "Epoch 309|time: 0.03s|train_loss 0.00000174|val_loss 0.00000915\n",
      "Epoch 310|time: 0.03s|train_loss 0.00000174|val_loss 0.00000969\n",
      "Epoch 311|time: 0.03s|train_loss 0.00000173|val_loss 0.00000925\n",
      "Epoch 312|time: 0.03s|train_loss 0.00000178|val_loss 0.00000922\n",
      "Epoch 313|time: 0.03s|train_loss 0.00000173|val_loss 0.00000924\n",
      "Epoch 314|time: 0.03s|train_loss 0.00000174|val_loss 0.00001026\n",
      "Epoch 315|time: 0.03s|train_loss 0.00000173|val_loss 0.00000995\n",
      "Epoch 316|time: 0.03s|train_loss 0.00000167|val_loss 0.00000928\n",
      "Epoch 317|time: 0.03s|train_loss 0.00000181|val_loss 0.00000894\n",
      "Best validation epoch: 317 Mon Aug 15 22:18:03 2022\n",
      "TEST MAE 739.4773 std 633.4944 RMSE 1493.4972 RMSEs 1120.9210 MAPE 0.1254 R2 0.4703 R2s 0.4402\n",
      "Epoch 318|time: 0.03s|train_loss 0.00000170|val_loss 0.00000935\n",
      "Epoch 319|time: 0.03s|train_loss 0.00000177|val_loss 0.00000915\n",
      "Epoch 320|time: 0.03s|train_loss 0.00000170|val_loss 0.00000921\n",
      "Epoch 321|time: 0.03s|train_loss 0.00000171|val_loss 0.00000934\n",
      "Epoch 322|time: 0.03s|train_loss 0.00000176|val_loss 0.00000960\n",
      "Epoch 323|time: 0.03s|train_loss 0.00000169|val_loss 0.00000906\n",
      "Epoch 324|time: 0.03s|train_loss 0.00000178|val_loss 0.00000920\n",
      "Epoch 325|time: 0.03s|train_loss 0.00000174|val_loss 0.00000949\n",
      "Epoch 326|time: 0.03s|train_loss 0.00000180|val_loss 0.00000964\n",
      "Epoch 327|time: 0.03s|train_loss 0.00000169|val_loss 0.00000929\n",
      "Epoch 328|time: 0.03s|train_loss 0.00000167|val_loss 0.00000908\n",
      "Epoch 329|time: 0.03s|train_loss 0.00000163|val_loss 0.00000993\n",
      "Epoch 330|time: 0.03s|train_loss 0.00000177|val_loss 0.00000966\n",
      "Epoch 331|time: 0.04s|train_loss 0.00000175|val_loss 0.00000922\n",
      "Epoch 332|time: 0.03s|train_loss 0.00000167|val_loss 0.00000948\n",
      "Epoch 333|time: 0.03s|train_loss 0.00000172|val_loss 0.00000888\n",
      "Best validation epoch: 333 Mon Aug 15 22:18:03 2022\n",
      "TEST MAE 735.5526 std 623.7110 RMSE 1496.6773 RMSEs 1125.5962 MAPE 0.1092 R2 0.4680 R2s 0.4349\n",
      "Epoch 334|time: 0.03s|train_loss 0.00000170|val_loss 0.00000926\n",
      "Epoch 335|time: 0.03s|train_loss 0.00000173|val_loss 0.00000897\n",
      "Epoch 336|time: 0.03s|train_loss 0.00000171|val_loss 0.00000920\n",
      "Epoch 337|time: 0.03s|train_loss 0.00000182|val_loss 0.00000905\n",
      "Epoch 338|time: 0.03s|train_loss 0.00000166|val_loss 0.00000941\n",
      "Epoch 339|time: 0.03s|train_loss 0.00000164|val_loss 0.00000941\n",
      "Epoch 340|time: 0.03s|train_loss 0.00000165|val_loss 0.00000929\n",
      "Epoch 341|time: 0.03s|train_loss 0.00000168|val_loss 0.00000920\n",
      "Epoch 342|time: 0.03s|train_loss 0.00000164|val_loss 0.00000920\n",
      "Epoch 343|time: 0.03s|train_loss 0.00000163|val_loss 0.00000925\n",
      "Epoch 344|time: 0.03s|train_loss 0.00000162|val_loss 0.00000962\n",
      "Epoch 345|time: 0.03s|train_loss 0.00000171|val_loss 0.00000955\n",
      "Epoch 346|time: 0.04s|train_loss 0.00000162|val_loss 0.00000930\n",
      "Epoch 347|time: 0.03s|train_loss 0.00000167|val_loss 0.00000939\n",
      "Epoch 348|time: 0.03s|train_loss 0.00000171|val_loss 0.00000960\n",
      "Epoch 349|time: 0.03s|train_loss 0.00000160|val_loss 0.00000932\n",
      "Epoch 350|time: 0.03s|train_loss 0.00000162|val_loss 0.00000891\n",
      "Epoch 351|time: 0.03s|train_loss 0.00000169|val_loss 0.00000884\n",
      "Best validation epoch: 351 Mon Aug 15 22:18:04 2022\n",
      "TEST MAE 747.4635 std 639.9631 RMSE 1503.1440 RMSEs 1127.5566 MAPE 0.1320 R2 0.4634 R2s 0.4350\n",
      "Epoch 352|time: 0.03s|train_loss 0.00000167|val_loss 0.00000925\n",
      "Epoch 353|time: 0.03s|train_loss 0.00000158|val_loss 0.00000886\n",
      "Epoch 354|time: 0.03s|train_loss 0.00000173|val_loss 0.00000927\n",
      "Epoch 355|time: 0.03s|train_loss 0.00000166|val_loss 0.00000940\n",
      "Epoch 356|time: 0.03s|train_loss 0.00000168|val_loss 0.00000877\n",
      "Best validation epoch: 356 Mon Aug 15 22:18:04 2022\n",
      "TEST MAE 725.2582 std 618.8571 RMSE 1471.1618 RMSEs 1105.3390 MAPE 0.1234 R2 0.4860 R2s 0.4568\n",
      "Epoch 357|time: 0.03s|train_loss 0.00000164|val_loss 0.00000864\n",
      "Best validation epoch: 357 Mon Aug 15 22:18:04 2022\n",
      "TEST MAE 741.4209 std 636.4807 RMSE 1500.5122 RMSEs 1124.2008 MAPE 0.1253 R2 0.4653 R2s 0.4407\n",
      "Epoch 358|time: 0.03s|train_loss 0.00000171|val_loss 0.00000933\n",
      "Epoch 359|time: 0.03s|train_loss 0.00000153|val_loss 0.00000939\n",
      "Epoch 360|time: 0.03s|train_loss 0.00000160|val_loss 0.00000908\n",
      "Epoch 361|time: 0.03s|train_loss 0.00000164|val_loss 0.00000893\n",
      "Epoch 362|time: 0.03s|train_loss 0.00000153|val_loss 0.00000939\n",
      "Epoch 363|time: 0.03s|train_loss 0.00000180|val_loss 0.00000930\n",
      "Epoch 364|time: 0.03s|train_loss 0.00000164|val_loss 0.00000935\n",
      "Epoch 365|time: 0.03s|train_loss 0.00000171|val_loss 0.00000902\n",
      "Epoch 366|time: 0.03s|train_loss 0.00000163|val_loss 0.00000910\n",
      "Epoch 367|time: 0.03s|train_loss 0.00000168|val_loss 0.00000922\n",
      "Epoch 368|time: 0.04s|train_loss 0.00000161|val_loss 0.00000919\n",
      "Epoch 369|time: 0.03s|train_loss 0.00000163|val_loss 0.00000918\n",
      "Epoch 370|time: 0.03s|train_loss 0.00000171|val_loss 0.00000897\n",
      "Epoch 371|time: 0.03s|train_loss 0.00000156|val_loss 0.00000882\n",
      "Epoch 372|time: 0.04s|train_loss 0.00000167|val_loss 0.00000867\n",
      "Epoch 373|time: 0.03s|train_loss 0.00000167|val_loss 0.00000908\n",
      "Epoch 374|time: 0.04s|train_loss 0.00000167|val_loss 0.00000885\n",
      "Epoch 375|time: 0.03s|train_loss 0.00000162|val_loss 0.00000904\n",
      "Epoch 376|time: 0.04s|train_loss 0.00000159|val_loss 0.00000908\n",
      "Epoch 377|time: 0.03s|train_loss 0.00000163|val_loss 0.00000888\n",
      "Epoch 378|time: 0.03s|train_loss 0.00000169|val_loss 0.00000938\n",
      "Epoch 379|time: 0.04s|train_loss 0.00000159|val_loss 0.00000860\n",
      "Best validation epoch: 379 Mon Aug 15 22:18:05 2022\n",
      "TEST MAE 727.6132 std 621.6938 RMSE 1480.9296 RMSEs 1110.7467 MAPE 0.1150 R2 0.4792 R2s 0.4521\n",
      "Epoch 380|time: 0.03s|train_loss 0.00000160|val_loss 0.00000852\n",
      "Best validation epoch: 380 Mon Aug 15 22:18:05 2022\n",
      "TEST MAE 723.0046 std 617.7825 RMSE 1470.1695 RMSEs 1103.3048 MAPE 0.1235 R2 0.4867 R2s 0.4603\n",
      "Epoch 381|time: 0.04s|train_loss 0.00000165|val_loss 0.00000843\n",
      "Best validation epoch: 381 Mon Aug 15 22:18:05 2022\n",
      "TEST MAE 736.0803 std 632.6760 RMSE 1488.7549 RMSEs 1117.2402 MAPE 0.1190 R2 0.4736 R2s 0.4452\n",
      "Epoch 382|time: 0.03s|train_loss 0.00000158|val_loss 0.00000867\n",
      "Epoch 383|time: 0.03s|train_loss 0.00000158|val_loss 0.00000871\n",
      "Epoch 384|time: 0.03s|train_loss 0.00000167|val_loss 0.00000839\n",
      "Best validation epoch: 384 Mon Aug 15 22:18:05 2022\n",
      "TEST MAE 735.1505 std 631.5887 RMSE 1491.9284 RMSEs 1118.8669 MAPE 0.1168 R2 0.4714 R2s 0.4447\n",
      "Epoch 385|time: 0.03s|train_loss 0.00000162|val_loss 0.00000852\n",
      "Epoch 386|time: 0.03s|train_loss 0.00000160|val_loss 0.00000888\n",
      "Epoch 387|time: 0.03s|train_loss 0.00000165|val_loss 0.00000900\n",
      "Epoch 388|time: 0.03s|train_loss 0.00000164|val_loss 0.00000912\n",
      "Epoch 389|time: 0.03s|train_loss 0.00000165|val_loss 0.00000861\n",
      "Epoch 390|time: 0.03s|train_loss 0.00000170|val_loss 0.00000851\n",
      "Epoch 391|time: 0.04s|train_loss 0.00000168|val_loss 0.00000889\n",
      "Epoch 392|time: 0.03s|train_loss 0.00000167|val_loss 0.00000852\n",
      "Epoch 393|time: 0.03s|train_loss 0.00000166|val_loss 0.00000883\n",
      "Epoch 394|time: 0.03s|train_loss 0.00000155|val_loss 0.00000853\n",
      "Epoch 395|time: 0.03s|train_loss 0.00000165|val_loss 0.00000862\n",
      "Epoch 396|time: 0.03s|train_loss 0.00000157|val_loss 0.00000867\n",
      "Epoch 397|time: 0.03s|train_loss 0.00000153|val_loss 0.00000843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 398|time: 0.04s|train_loss 0.00000162|val_loss 0.00000875\n",
      "Epoch 399|time: 0.03s|train_loss 0.00000163|val_loss 0.00000878\n",
      "Epoch 400|time: 0.03s|train_loss 0.00000162|val_loss 0.00000841\n",
      "Epoch 401|time: 0.04s|train_loss 0.00000173|val_loss 0.00000856\n",
      "Epoch 402|time: 0.03s|train_loss 0.00000166|val_loss 0.00000883\n",
      "Epoch 403|time: 0.04s|train_loss 0.00000170|val_loss 0.00000892\n",
      "Epoch 404|time: 0.03s|train_loss 0.00000163|val_loss 0.00000903\n",
      "Epoch 405|time: 0.03s|train_loss 0.00000155|val_loss 0.00000859\n",
      "Epoch 406|time: 0.03s|train_loss 0.00000162|val_loss 0.00000865\n",
      "Epoch 407|time: 0.03s|train_loss 0.00000160|val_loss 0.00000907\n",
      "Epoch 408|time: 0.03s|train_loss 0.00000157|val_loss 0.00000878\n",
      "Epoch 409|time: 0.03s|train_loss 0.00000164|val_loss 0.00000865\n",
      "Epoch 410|time: 0.03s|train_loss 0.00000160|val_loss 0.00000827\n",
      "Best validation epoch: 410 Mon Aug 15 22:18:06 2022\n",
      "TEST MAE 715.9236 std 616.5511 RMSE 1469.1965 RMSEs 1099.2722 MAPE 0.1085 R2 0.4874 R2s 0.4658\n",
      "Epoch 411|time: 0.04s|train_loss 0.00000161|val_loss 0.00000905\n",
      "Epoch 412|time: 0.03s|train_loss 0.00000160|val_loss 0.00000925\n",
      "Epoch 413|time: 0.03s|train_loss 0.00000157|val_loss 0.00000845\n",
      "Epoch 414|time: 0.03s|train_loss 0.00000161|val_loss 0.00000827\n",
      "Epoch 415|time: 0.03s|train_loss 0.00000156|val_loss 0.00000859\n",
      "Epoch 416|time: 0.03s|train_loss 0.00000160|val_loss 0.00000847\n",
      "Epoch 417|time: 0.03s|train_loss 0.00000150|val_loss 0.00000913\n",
      "Epoch 418|time: 0.03s|train_loss 0.00000164|val_loss 0.00000875\n",
      "Epoch 419|time: 0.03s|train_loss 0.00000159|val_loss 0.00000895\n",
      "Epoch 420|time: 0.03s|train_loss 0.00000150|val_loss 0.00000882\n",
      "Epoch 421|time: 0.03s|train_loss 0.00000154|val_loss 0.00000856\n",
      "Epoch 422|time: 0.03s|train_loss 0.00000167|val_loss 0.00000876\n",
      "Epoch 423|time: 0.03s|train_loss 0.00000161|val_loss 0.00000859\n",
      "Epoch 424|time: 0.03s|train_loss 0.00000151|val_loss 0.00000830\n",
      "Epoch 425|time: 0.03s|train_loss 0.00000155|val_loss 0.00000853\n",
      "Epoch 426|time: 0.03s|train_loss 0.00000164|val_loss 0.00000828\n",
      "Epoch 427|time: 0.03s|train_loss 0.00000163|val_loss 0.00000861\n",
      "Epoch 428|time: 0.03s|train_loss 0.00000155|val_loss 0.00000821\n",
      "Best validation epoch: 428 Mon Aug 15 22:18:06 2022\n",
      "TEST MAE 726.0772 std 625.2814 RMSE 1469.4045 RMSEs 1102.9020 MAPE 0.1166 R2 0.4872 R2s 0.4587\n",
      "Epoch 429|time: 0.03s|train_loss 0.00000158|val_loss 0.00000842\n",
      "Epoch 430|time: 0.03s|train_loss 0.00000160|val_loss 0.00000853\n",
      "Epoch 431|time: 0.04s|train_loss 0.00000152|val_loss 0.00000890\n",
      "Epoch 432|time: 0.04s|train_loss 0.00000162|val_loss 0.00000923\n",
      "Epoch 433|time: 0.04s|train_loss 0.00000164|val_loss 0.00000904\n",
      "Epoch 434|time: 0.03s|train_loss 0.00000150|val_loss 0.00000872\n",
      "Epoch 435|time: 0.03s|train_loss 0.00000162|val_loss 0.00000881\n",
      "Epoch 436|time: 0.03s|train_loss 0.00000155|val_loss 0.00000830\n",
      "Epoch 437|time: 0.03s|train_loss 0.00000170|val_loss 0.00000822\n",
      "Epoch 438|time: 0.03s|train_loss 0.00000157|val_loss 0.00000898\n",
      "Epoch 439|time: 0.03s|train_loss 0.00000157|val_loss 0.00000884\n",
      "Epoch 440|time: 0.03s|train_loss 0.00000146|val_loss 0.00000835\n",
      "Epoch 441|time: 0.03s|train_loss 0.00000169|val_loss 0.00000840\n",
      "Epoch 442|time: 0.03s|train_loss 0.00000156|val_loss 0.00000893\n",
      "Epoch 443|time: 0.03s|train_loss 0.00000165|val_loss 0.00000898\n",
      "Epoch 444|time: 0.03s|train_loss 0.00000159|val_loss 0.00000812\n",
      "Best validation epoch: 444 Mon Aug 15 22:18:07 2022\n",
      "TEST MAE 722.3256 std 619.8336 RMSE 1448.8347 RMSEs 1086.9509 MAPE 0.1268 R2 0.5015 R2s 0.4738\n",
      "Epoch 445|time: 0.03s|train_loss 0.00000153|val_loss 0.00000795\n",
      "Best validation epoch: 445 Mon Aug 15 22:18:07 2022\n",
      "TEST MAE 744.3555 std 638.2023 RMSE 1495.8852 RMSEs 1121.3923 MAPE 0.1334 R2 0.4686 R2s 0.4421\n",
      "Epoch 446|time: 0.03s|train_loss 0.00000171|val_loss 0.00000873\n",
      "Epoch 447|time: 0.03s|train_loss 0.00000162|val_loss 0.00000817\n",
      "Epoch 448|time: 0.04s|train_loss 0.00000154|val_loss 0.00000842\n",
      "Epoch 449|time: 0.03s|train_loss 0.00000156|val_loss 0.00000864\n",
      "Epoch 450|time: 0.03s|train_loss 0.00000160|val_loss 0.00000849\n",
      "Epoch 451|time: 0.03s|train_loss 0.00000161|val_loss 0.00000817\n",
      "Epoch 452|time: 0.03s|train_loss 0.00000162|val_loss 0.00000851\n",
      "Epoch 453|time: 0.03s|train_loss 0.00000169|val_loss 0.00000850\n",
      "Epoch 454|time: 0.03s|train_loss 0.00000154|val_loss 0.00000826\n",
      "Epoch 455|time: 0.03s|train_loss 0.00000149|val_loss 0.00000877\n",
      "Epoch 456|time: 0.03s|train_loss 0.00000160|val_loss 0.00000827\n",
      "Epoch 457|time: 0.04s|train_loss 0.00000160|val_loss 0.00000847\n",
      "Epoch 458|time: 0.03s|train_loss 0.00000148|val_loss 0.00000859\n",
      "Epoch 459|time: 0.03s|train_loss 0.00000168|val_loss 0.00000824\n",
      "Epoch 460|time: 0.03s|train_loss 0.00000161|val_loss 0.00000809\n",
      "Epoch 461|time: 0.03s|train_loss 0.00000151|val_loss 0.00000846\n",
      "Epoch 462|time: 0.04s|train_loss 0.00000173|val_loss 0.00000845\n",
      "Epoch 463|time: 0.04s|train_loss 0.00000157|val_loss 0.00000797\n",
      "Epoch 464|time: 0.03s|train_loss 0.00000159|val_loss 0.00000785\n",
      "Best validation epoch: 464 Mon Aug 15 22:18:08 2022\n",
      "TEST MAE 716.7770 std 620.8654 RMSE 1472.7331 RMSEs 1100.0413 MAPE 0.1074 R2 0.4849 R2s 0.4674\n",
      "Epoch 465|time: 0.04s|train_loss 0.00000165|val_loss 0.00000875\n",
      "Epoch 466|time: 0.04s|train_loss 0.00000153|val_loss 0.00000855\n",
      "Epoch 467|time: 0.04s|train_loss 0.00000158|val_loss 0.00000853\n",
      "Epoch 468|time: 0.04s|train_loss 0.00000160|val_loss 0.00000810\n",
      "Epoch 469|time: 0.04s|train_loss 0.00000153|val_loss 0.00000833\n",
      "Epoch 470|time: 0.04s|train_loss 0.00000163|val_loss 0.00000845\n",
      "Epoch 471|time: 0.03s|train_loss 0.00000159|val_loss 0.00000852\n",
      "Epoch 472|time: 0.03s|train_loss 0.00000162|val_loss 0.00000834\n",
      "Epoch 473|time: 0.03s|train_loss 0.00000150|val_loss 0.00000885\n",
      "Epoch 474|time: 0.04s|train_loss 0.00000151|val_loss 0.00000852\n",
      "Epoch 475|time: 0.03s|train_loss 0.00000153|val_loss 0.00000802\n",
      "Epoch 476|time: 0.03s|train_loss 0.00000153|val_loss 0.00000825\n",
      "Epoch 477|time: 0.04s|train_loss 0.00000158|val_loss 0.00000865\n",
      "Epoch 478|time: 0.03s|train_loss 0.00000157|val_loss 0.00000871\n",
      "Epoch 479|time: 0.03s|train_loss 0.00000155|val_loss 0.00000846\n",
      "Epoch 480|time: 0.03s|train_loss 0.00000154|val_loss 0.00000831\n",
      "Epoch 481|time: 0.04s|train_loss 0.00000149|val_loss 0.00000804\n",
      "Epoch 482|time: 0.03s|train_loss 0.00000151|val_loss 0.00000800\n",
      "Epoch 483|time: 0.03s|train_loss 0.00000144|val_loss 0.00000852\n",
      "Epoch 484|time: 0.03s|train_loss 0.00000167|val_loss 0.00000865\n",
      "Epoch 485|time: 0.03s|train_loss 0.00000157|val_loss 0.00000892\n",
      "Epoch 486|time: 0.03s|train_loss 0.00000158|val_loss 0.00000837\n",
      "Epoch 487|time: 0.03s|train_loss 0.00000155|val_loss 0.00000815\n",
      "Epoch 488|time: 0.03s|train_loss 0.00000152|val_loss 0.00000847\n",
      "Epoch 489|time: 0.03s|train_loss 0.00000158|val_loss 0.00000857\n",
      "Epoch 490|time: 0.03s|train_loss 0.00000148|val_loss 0.00000858\n",
      "Epoch 491|time: 0.03s|train_loss 0.00000143|val_loss 0.00000863\n",
      "Epoch 492|time: 0.03s|train_loss 0.00000156|val_loss 0.00000845\n",
      "Epoch 493|time: 0.03s|train_loss 0.00000149|val_loss 0.00000855\n",
      "Epoch 494|time: 0.03s|train_loss 0.00000158|val_loss 0.00000831\n",
      "Epoch 495|time: 0.04s|train_loss 0.00000156|val_loss 0.00000808\n",
      "Epoch 496|time: 0.03s|train_loss 0.00000166|val_loss 0.00000852\n",
      "Epoch 497|time: 0.03s|train_loss 0.00000156|val_loss 0.00000854\n",
      "Epoch 498|time: 0.03s|train_loss 0.00000159|val_loss 0.00000880\n",
      "Epoch 499|time: 0.04s|train_loss 0.00000160|val_loss 0.00000872\n",
      "Epoch 500|time: 0.03s|train_loss 0.00000150|val_loss 0.00000825\n",
      "Epoch 501|time: 0.03s|train_loss 0.00000160|val_loss 0.00000786\n",
      "Epoch 502|time: 0.04s|train_loss 0.00000158|val_loss 0.00000850\n",
      "Epoch 503|time: 0.03s|train_loss 0.00000148|val_loss 0.00000868\n",
      "Epoch 504|time: 0.03s|train_loss 0.00000161|val_loss 0.00000871\n",
      "Epoch 505|time: 0.03s|train_loss 0.00000158|val_loss 0.00000859\n",
      "Epoch 506|time: 0.03s|train_loss 0.00000152|val_loss 0.00000855\n",
      "Epoch 507|time: 0.03s|train_loss 0.00000148|val_loss 0.00000886\n",
      "Epoch 508|time: 0.03s|train_loss 0.00000153|val_loss 0.00000808\n",
      "Epoch 509|time: 0.03s|train_loss 0.00000150|val_loss 0.00000876\n",
      "Epoch 510|time: 0.03s|train_loss 0.00000161|val_loss 0.00000834\n",
      "Epoch 511|time: 0.03s|train_loss 0.00000151|val_loss 0.00000791\n",
      "Epoch 512|time: 0.03s|train_loss 0.00000158|val_loss 0.00000808\n",
      "Epoch 513|time: 0.03s|train_loss 0.00000161|val_loss 0.00000820\n",
      "Epoch 514|time: 0.03s|train_loss 0.00000151|val_loss 0.00000853\n",
      "Epoch 515|time: 0.03s|train_loss 0.00000154|val_loss 0.00000777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation epoch: 515 Mon Aug 15 22:18:09 2022\n",
      "TEST MAE 760.8604 std 657.9340 RMSE 1527.5921 RMSEs 1144.6881 MAPE 0.1304 R2 0.4458 R2s 0.4200\n",
      "Epoch 516|time: 0.03s|train_loss 0.00000154|val_loss 0.00000794\n",
      "Epoch 517|time: 0.03s|train_loss 0.00000150|val_loss 0.00000913\n",
      "Epoch 518|time: 0.03s|train_loss 0.00000153|val_loss 0.00000829\n",
      "Epoch 519|time: 0.03s|train_loss 0.00000152|val_loss 0.00000844\n",
      "Epoch 520|time: 0.03s|train_loss 0.00000161|val_loss 0.00000862\n",
      "Epoch 521|time: 0.03s|train_loss 0.00000150|val_loss 0.00000784\n",
      "Epoch 522|time: 0.03s|train_loss 0.00000157|val_loss 0.00000835\n",
      "Epoch 523|time: 0.03s|train_loss 0.00000160|val_loss 0.00000829\n",
      "Epoch 524|time: 0.03s|train_loss 0.00000152|val_loss 0.00000829\n",
      "Epoch 525|time: 0.03s|train_loss 0.00000160|val_loss 0.00000812\n",
      "Epoch 526|time: 0.03s|train_loss 0.00000159|val_loss 0.00000772\n",
      "Best validation epoch: 526 Mon Aug 15 22:18:10 2022\n",
      "TEST MAE 737.7678 std 639.5367 RMSE 1476.3245 RMSEs 1105.4011 MAPE 0.1129 R2 0.4824 R2s 0.4582\n",
      "Epoch 527|time: 0.03s|train_loss 0.00000154|val_loss 0.00000853\n",
      "Epoch 528|time: 0.03s|train_loss 0.00000146|val_loss 0.00000861\n",
      "Epoch 529|time: 0.03s|train_loss 0.00000154|val_loss 0.00000804\n",
      "Epoch 530|time: 0.03s|train_loss 0.00000152|val_loss 0.00000822\n",
      "Epoch 531|time: 0.03s|train_loss 0.00000147|val_loss 0.00000814\n",
      "Epoch 532|time: 0.03s|train_loss 0.00000154|val_loss 0.00000776\n",
      "Epoch 533|time: 0.03s|train_loss 0.00000160|val_loss 0.00000799\n",
      "Epoch 534|time: 0.03s|train_loss 0.00000141|val_loss 0.00000811\n",
      "Epoch 535|time: 0.03s|train_loss 0.00000152|val_loss 0.00000812\n",
      "Epoch 536|time: 0.03s|train_loss 0.00000155|val_loss 0.00000806\n",
      "Epoch 537|time: 0.03s|train_loss 0.00000152|val_loss 0.00000857\n",
      "Epoch 538|time: 0.03s|train_loss 0.00000155|val_loss 0.00000794\n",
      "Epoch 539|time: 0.03s|train_loss 0.00000150|val_loss 0.00000805\n",
      "Epoch 540|time: 0.03s|train_loss 0.00000148|val_loss 0.00000798\n",
      "Epoch 541|time: 0.03s|train_loss 0.00000147|val_loss 0.00000814\n",
      "Epoch 542|time: 0.03s|train_loss 0.00000159|val_loss 0.00000853\n",
      "Epoch 543|time: 0.03s|train_loss 0.00000147|val_loss 0.00000848\n",
      "Epoch 544|time: 0.03s|train_loss 0.00000145|val_loss 0.00000849\n",
      "Epoch 545|time: 0.03s|train_loss 0.00000145|val_loss 0.00000807\n",
      "Epoch 546|time: 0.03s|train_loss 0.00000156|val_loss 0.00000864\n",
      "Epoch 547|time: 0.03s|train_loss 0.00000155|val_loss 0.00000829\n",
      "Epoch 548|time: 0.03s|train_loss 0.00000143|val_loss 0.00000789\n",
      "Epoch 549|time: 0.03s|train_loss 0.00000147|val_loss 0.00000821\n",
      "Epoch 550|time: 0.03s|train_loss 0.00000156|val_loss 0.00000787\n",
      "Epoch 551|time: 0.03s|train_loss 0.00000153|val_loss 0.00000786\n",
      "Epoch 552|time: 0.03s|train_loss 0.00000150|val_loss 0.00000847\n",
      "Epoch 553|time: 0.03s|train_loss 0.00000147|val_loss 0.00000845\n",
      "Epoch 554|time: 0.03s|train_loss 0.00000147|val_loss 0.00000818\n",
      "Epoch 555|time: 0.03s|train_loss 0.00000142|val_loss 0.00000844\n",
      "Epoch 556|time: 0.03s|train_loss 0.00000147|val_loss 0.00000806\n",
      "Epoch 557|time: 0.03s|train_loss 0.00000142|val_loss 0.00000836\n",
      "Epoch 558|time: 0.03s|train_loss 0.00000147|val_loss 0.00000801\n",
      "Epoch 559|time: 0.03s|train_loss 0.00000149|val_loss 0.00000827\n",
      "Epoch 560|time: 0.03s|train_loss 0.00000152|val_loss 0.00000793\n",
      "Epoch 561|time: 0.03s|train_loss 0.00000155|val_loss 0.00000820\n",
      "Epoch 562|time: 0.03s|train_loss 0.00000142|val_loss 0.00000857\n",
      "Epoch 563|time: 0.03s|train_loss 0.00000150|val_loss 0.00000869\n",
      "Epoch 564|time: 0.03s|train_loss 0.00000146|val_loss 0.00000854\n",
      "Epoch 565|time: 0.03s|train_loss 0.00000152|val_loss 0.00000810\n",
      "Epoch 566|time: 0.03s|train_loss 0.00000147|val_loss 0.00000853\n",
      "Epoch 567|time: 0.03s|train_loss 0.00000143|val_loss 0.00000795\n",
      "Epoch 568|time: 0.03s|train_loss 0.00000140|val_loss 0.00000845\n",
      "Epoch 569|time: 0.03s|train_loss 0.00000144|val_loss 0.00000827\n",
      "Epoch 570|time: 0.03s|train_loss 0.00000152|val_loss 0.00000834\n",
      "Epoch 571|time: 0.03s|train_loss 0.00000152|val_loss 0.00000876\n",
      "Epoch 572|time: 0.03s|train_loss 0.00000152|val_loss 0.00000822\n",
      "Epoch 573|time: 0.03s|train_loss 0.00000155|val_loss 0.00000789\n",
      "Epoch 574|time: 0.03s|train_loss 0.00000142|val_loss 0.00000808\n",
      "Epoch 575|time: 0.03s|train_loss 0.00000166|val_loss 0.00000905\n",
      "Epoch 576|time: 0.03s|train_loss 0.00000148|val_loss 0.00000832\n",
      "Epoch 577|time: 0.03s|train_loss 0.00000142|val_loss 0.00000827\n",
      "Epoch 578|time: 0.03s|train_loss 0.00000153|val_loss 0.00000835\n",
      "Epoch 579|time: 0.03s|train_loss 0.00000159|val_loss 0.00000816\n",
      "Epoch 580|time: 0.03s|train_loss 0.00000151|val_loss 0.00000850\n",
      "Epoch 581|time: 0.03s|train_loss 0.00000159|val_loss 0.00000881\n",
      "Epoch 582|time: 0.03s|train_loss 0.00000148|val_loss 0.00000835\n",
      "Epoch 583|time: 0.03s|train_loss 0.00000146|val_loss 0.00000853\n",
      "Epoch 584|time: 0.03s|train_loss 0.00000154|val_loss 0.00000891\n",
      "Epoch 585|time: 0.03s|train_loss 0.00000148|val_loss 0.00000796\n",
      "Epoch 586|time: 0.03s|train_loss 0.00000159|val_loss 0.00000850\n",
      "Epoch 587|time: 0.03s|train_loss 0.00000159|val_loss 0.00000820\n",
      "Epoch 588|time: 0.03s|train_loss 0.00000152|val_loss 0.00000854\n",
      "Epoch 589|time: 0.03s|train_loss 0.00000143|val_loss 0.00000884\n",
      "Epoch 590|time: 0.03s|train_loss 0.00000170|val_loss 0.00000827\n",
      "Epoch 591|time: 0.03s|train_loss 0.00000153|val_loss 0.00000814\n",
      "Epoch 592|time: 0.03s|train_loss 0.00000155|val_loss 0.00000849\n",
      "Epoch 593|time: 0.03s|train_loss 0.00000147|val_loss 0.00000834\n",
      "Epoch 594|time: 0.03s|train_loss 0.00000151|val_loss 0.00000854\n",
      "Epoch 595|time: 0.03s|train_loss 0.00000139|val_loss 0.00000814\n",
      "Epoch 596|time: 0.03s|train_loss 0.00000148|val_loss 0.00000815\n",
      "Epoch 597|time: 0.03s|train_loss 0.00000156|val_loss 0.00000784\n",
      "Epoch 598|time: 0.04s|train_loss 0.00000143|val_loss 0.00000890\n",
      "Epoch 599|time: 0.04s|train_loss 0.00000143|val_loss 0.00000896\n",
      "Epoch 600|time: 0.03s|train_loss 0.00000149|val_loss 0.00000857\n",
      "Epoch 601|time: 0.03s|train_loss 0.00000149|val_loss 0.00000787\n",
      "Epoch 602|time: 0.03s|train_loss 0.00000147|val_loss 0.00000870\n",
      "Epoch 603|time: 0.03s|train_loss 0.00000153|val_loss 0.00000813\n",
      "Epoch 604|time: 0.03s|train_loss 0.00000150|val_loss 0.00000780\n",
      "Epoch 605|time: 0.03s|train_loss 0.00000140|val_loss 0.00000795\n",
      "Epoch 606|time: 0.03s|train_loss 0.00000151|val_loss 0.00000757\n",
      "Best validation epoch: 606 Mon Aug 15 22:18:12 2022\n",
      "TEST MAE 748.0985 std 655.0978 RMSE 1511.2855 RMSEs 1129.1271 MAPE 0.1029 R2 0.4576 R2s 0.4390\n",
      "Epoch 607|time: 0.03s|train_loss 0.00000163|val_loss 0.00000794\n",
      "Epoch 608|time: 0.03s|train_loss 0.00000147|val_loss 0.00000851\n",
      "Epoch 609|time: 0.03s|train_loss 0.00000149|val_loss 0.00000794\n",
      "Epoch 610|time: 0.03s|train_loss 0.00000144|val_loss 0.00000833\n",
      "Epoch 611|time: 0.03s|train_loss 0.00000165|val_loss 0.00000832\n",
      "Epoch 612|time: 0.03s|train_loss 0.00000144|val_loss 0.00000825\n",
      "Epoch 613|time: 0.03s|train_loss 0.00000149|val_loss 0.00000845\n",
      "Epoch 614|time: 0.03s|train_loss 0.00000152|val_loss 0.00000853\n",
      "Epoch 615|time: 0.03s|train_loss 0.00000138|val_loss 0.00000815\n",
      "Epoch 616|time: 0.03s|train_loss 0.00000149|val_loss 0.00000796\n",
      "Epoch 617|time: 0.03s|train_loss 0.00000146|val_loss 0.00000816\n",
      "Epoch 618|time: 0.03s|train_loss 0.00000148|val_loss 0.00000849\n",
      "Epoch 619|time: 0.03s|train_loss 0.00000150|val_loss 0.00000827\n",
      "Epoch 620|time: 0.03s|train_loss 0.00000143|val_loss 0.00000822\n",
      "Epoch 621|time: 0.03s|train_loss 0.00000134|val_loss 0.00000797\n",
      "Epoch 622|time: 0.03s|train_loss 0.00000154|val_loss 0.00000795\n",
      "Epoch 623|time: 0.03s|train_loss 0.00000161|val_loss 0.00000825\n",
      "Epoch 624|time: 0.03s|train_loss 0.00000147|val_loss 0.00000800\n",
      "Epoch 625|time: 0.03s|train_loss 0.00000147|val_loss 0.00000785\n",
      "Epoch 626|time: 0.03s|train_loss 0.00000165|val_loss 0.00000823\n",
      "Epoch 627|time: 0.03s|train_loss 0.00000144|val_loss 0.00000811\n",
      "Epoch 628|time: 0.03s|train_loss 0.00000149|val_loss 0.00000838\n",
      "Epoch 629|time: 0.03s|train_loss 0.00000140|val_loss 0.00000808\n",
      "Epoch 630|time: 0.03s|train_loss 0.00000150|val_loss 0.00000805\n",
      "Epoch 631|time: 0.03s|train_loss 0.00000145|val_loss 0.00000837\n",
      "Epoch 632|time: 0.03s|train_loss 0.00000140|val_loss 0.00000834\n",
      "Epoch 633|time: 0.03s|train_loss 0.00000142|val_loss 0.00000816\n",
      "Epoch 634|time: 0.03s|train_loss 0.00000152|val_loss 0.00000872\n",
      "Epoch 635|time: 0.03s|train_loss 0.00000142|val_loss 0.00000821\n",
      "Epoch 636|time: 0.03s|train_loss 0.00000144|val_loss 0.00000826\n",
      "Epoch 637|time: 0.03s|train_loss 0.00000148|val_loss 0.00000825\n",
      "Epoch 638|time: 0.03s|train_loss 0.00000154|val_loss 0.00000781\n",
      "Epoch 639|time: 0.03s|train_loss 0.00000140|val_loss 0.00000836\n",
      "Epoch 640|time: 0.03s|train_loss 0.00000141|val_loss 0.00000862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 641|time: 0.03s|train_loss 0.00000150|val_loss 0.00000838\n",
      "Epoch 642|time: 0.03s|train_loss 0.00000146|val_loss 0.00000843\n",
      "Epoch 643|time: 0.03s|train_loss 0.00000141|val_loss 0.00000841\n",
      "Epoch 644|time: 0.03s|train_loss 0.00000149|val_loss 0.00000835\n",
      "Epoch 645|time: 0.03s|train_loss 0.00000143|val_loss 0.00000835\n",
      "Epoch 646|time: 0.03s|train_loss 0.00000140|val_loss 0.00000770\n",
      "Epoch 647|time: 0.03s|train_loss 0.00000147|val_loss 0.00000819\n",
      "Epoch 648|time: 0.03s|train_loss 0.00000145|val_loss 0.00000829\n",
      "Epoch 649|time: 0.03s|train_loss 0.00000151|val_loss 0.00000870\n",
      "Epoch 650|time: 0.03s|train_loss 0.00000150|val_loss 0.00000797\n",
      "Epoch 651|time: 0.03s|train_loss 0.00000154|val_loss 0.00000807\n",
      "Epoch 652|time: 0.03s|train_loss 0.00000137|val_loss 0.00000775\n",
      "Epoch 653|time: 0.03s|train_loss 0.00000138|val_loss 0.00000875\n",
      "Epoch 654|time: 0.04s|train_loss 0.00000157|val_loss 0.00000825\n",
      "Epoch 655|time: 0.03s|train_loss 0.00000148|val_loss 0.00000791\n",
      "Epoch 656|time: 0.03s|train_loss 0.00000134|val_loss 0.00000841\n",
      "Epoch 657|time: 0.03s|train_loss 0.00000140|val_loss 0.00000807\n",
      "Epoch 658|time: 0.03s|train_loss 0.00000158|val_loss 0.00000814\n",
      "Epoch 659|time: 0.03s|train_loss 0.00000163|val_loss 0.00000826\n",
      "Epoch 660|time: 0.03s|train_loss 0.00000147|val_loss 0.00000838\n",
      "Epoch 661|time: 0.03s|train_loss 0.00000141|val_loss 0.00000830\n",
      "Epoch 662|time: 0.03s|train_loss 0.00000152|val_loss 0.00000893\n",
      "Epoch 663|time: 0.03s|train_loss 0.00000146|val_loss 0.00000846\n",
      "Epoch 664|time: 0.03s|train_loss 0.00000140|val_loss 0.00000849\n",
      "Epoch 665|time: 0.03s|train_loss 0.00000150|val_loss 0.00000860\n",
      "Epoch 666|time: 0.03s|train_loss 0.00000146|val_loss 0.00000799\n",
      "Epoch 667|time: 0.03s|train_loss 0.00000143|val_loss 0.00000830\n",
      "Epoch 668|time: 0.03s|train_loss 0.00000148|val_loss 0.00000822\n",
      "Epoch 669|time: 0.03s|train_loss 0.00000149|val_loss 0.00000871\n",
      "Epoch 670|time: 0.04s|train_loss 0.00000146|val_loss 0.00000855\n",
      "Epoch 671|time: 0.03s|train_loss 0.00000147|val_loss 0.00000872\n",
      "Epoch 672|time: 0.03s|train_loss 0.00000150|val_loss 0.00000861\n",
      "Epoch 673|time: 0.03s|train_loss 0.00000145|val_loss 0.00000869\n",
      "Epoch 674|time: 0.03s|train_loss 0.00000155|val_loss 0.00000850\n",
      "Epoch 675|time: 0.03s|train_loss 0.00000164|val_loss 0.00000840\n",
      "Epoch 676|time: 0.03s|train_loss 0.00000146|val_loss 0.00000830\n",
      "Epoch 677|time: 0.03s|train_loss 0.00000153|val_loss 0.00000837\n",
      "Epoch 678|time: 0.04s|train_loss 0.00000150|val_loss 0.00000836\n",
      "Epoch 679|time: 0.03s|train_loss 0.00000138|val_loss 0.00000797\n",
      "Epoch 680|time: 0.03s|train_loss 0.00000153|val_loss 0.00000839\n",
      "Epoch 681|time: 0.03s|train_loss 0.00000140|val_loss 0.00000867\n",
      "Epoch 682|time: 0.03s|train_loss 0.00000143|val_loss 0.00000815\n",
      "Epoch 683|time: 0.03s|train_loss 0.00000140|val_loss 0.00000897\n",
      "Epoch 684|time: 0.03s|train_loss 0.00000150|val_loss 0.00000844\n",
      "Epoch 685|time: 0.03s|train_loss 0.00000143|val_loss 0.00000816\n",
      "Epoch 686|time: 0.03s|train_loss 0.00000141|val_loss 0.00000865\n",
      "Epoch 687|time: 0.03s|train_loss 0.00000149|val_loss 0.00000854\n",
      "Epoch 688|time: 0.03s|train_loss 0.00000145|val_loss 0.00000832\n",
      "Epoch 689|time: 0.03s|train_loss 0.00000140|val_loss 0.00000803\n",
      "Epoch 690|time: 0.03s|train_loss 0.00000146|val_loss 0.00000854\n",
      "Epoch 691|time: 0.03s|train_loss 0.00000137|val_loss 0.00000896\n",
      "Epoch 692|time: 0.03s|train_loss 0.00000139|val_loss 0.00000881\n",
      "Epoch 693|time: 0.03s|train_loss 0.00000139|val_loss 0.00000849\n",
      "Epoch 694|time: 0.03s|train_loss 0.00000151|val_loss 0.00000879\n",
      "Epoch 695|time: 0.03s|train_loss 0.00000150|val_loss 0.00000828\n",
      "Epoch 696|time: 0.03s|train_loss 0.00000147|val_loss 0.00000834\n",
      "Epoch 697|time: 0.03s|train_loss 0.00000137|val_loss 0.00000821\n",
      "Epoch 698|time: 0.03s|train_loss 0.00000150|val_loss 0.00000794\n",
      "Epoch 699|time: 0.03s|train_loss 0.00000149|val_loss 0.00000801\n",
      "Epoch 700|time: 0.03s|train_loss 0.00000144|val_loss 0.00000872\n",
      "Epoch 701|time: 0.03s|train_loss 0.00000154|val_loss 0.00000855\n",
      "Epoch 702|time: 0.04s|train_loss 0.00000147|val_loss 0.00000838\n",
      "Epoch 703|time: 0.03s|train_loss 0.00000140|val_loss 0.00000826\n",
      "Epoch 704|time: 0.04s|train_loss 0.00000126|val_loss 0.00000862\n",
      "Epoch 705|time: 0.04s|train_loss 0.00000153|val_loss 0.00000925\n",
      "Epoch 706|time: 0.03s|train_loss 0.00000151|val_loss 0.00000812\n",
      "Epoch 707|time: 0.03s|train_loss 0.00000141|val_loss 0.00000892\n",
      "Epoch 708|time: 0.03s|train_loss 0.00000140|val_loss 0.00000885\n",
      "Epoch 709|time: 0.04s|train_loss 0.00000152|val_loss 0.00000875\n",
      "Epoch 710|time: 0.03s|train_loss 0.00000144|val_loss 0.00000823\n",
      "Epoch 711|time: 0.04s|train_loss 0.00000169|val_loss 0.00000784\n",
      "Epoch 712|time: 0.03s|train_loss 0.00000142|val_loss 0.00000848\n",
      "Epoch 713|time: 0.03s|train_loss 0.00000160|val_loss 0.00000860\n",
      "Epoch 714|time: 0.03s|train_loss 0.00000144|val_loss 0.00000798\n",
      "Epoch 715|time: 0.03s|train_loss 0.00000149|val_loss 0.00000815\n",
      "Epoch 716|time: 0.03s|train_loss 0.00000140|val_loss 0.00000833\n",
      "Epoch 717|time: 0.03s|train_loss 0.00000132|val_loss 0.00000845\n",
      "Epoch 718|time: 0.03s|train_loss 0.00000149|val_loss 0.00000879\n",
      "Epoch 719|time: 0.03s|train_loss 0.00000145|val_loss 0.00000857\n",
      "Epoch 720|time: 0.03s|train_loss 0.00000161|val_loss 0.00000793\n",
      "Epoch 721|time: 0.03s|train_loss 0.00000143|val_loss 0.00000868\n",
      "Epoch 722|time: 0.03s|train_loss 0.00000142|val_loss 0.00000876\n",
      "Epoch 723|time: 0.03s|train_loss 0.00000138|val_loss 0.00000806\n",
      "Epoch 724|time: 0.03s|train_loss 0.00000137|val_loss 0.00000795\n",
      "Epoch 725|time: 0.03s|train_loss 0.00000147|val_loss 0.00000863\n",
      "Epoch 726|time: 0.03s|train_loss 0.00000148|val_loss 0.00000842\n",
      "Epoch 727|time: 0.03s|train_loss 0.00000137|val_loss 0.00000927\n",
      "Epoch 728|time: 0.03s|train_loss 0.00000152|val_loss 0.00000864\n",
      "Epoch 729|time: 0.03s|train_loss 0.00000145|val_loss 0.00000858\n",
      "Epoch 730|time: 0.03s|train_loss 0.00000141|val_loss 0.00000834\n",
      "Epoch 731|time: 0.03s|train_loss 0.00000140|val_loss 0.00000820\n",
      "Epoch 732|time: 0.03s|train_loss 0.00000145|val_loss 0.00000879\n",
      "Epoch 733|time: 0.03s|train_loss 0.00000150|val_loss 0.00000916\n",
      "Epoch 734|time: 0.03s|train_loss 0.00000131|val_loss 0.00000820\n",
      "Epoch 735|time: 0.03s|train_loss 0.00000150|val_loss 0.00000823\n",
      "Epoch 736|time: 0.03s|train_loss 0.00000144|val_loss 0.00000776\n",
      "Epoch 737|time: 0.03s|train_loss 0.00000150|val_loss 0.00000890\n",
      "Epoch 738|time: 0.03s|train_loss 0.00000147|val_loss 0.00000843\n",
      "Epoch 739|time: 0.03s|train_loss 0.00000143|val_loss 0.00000802\n",
      "Epoch 740|time: 0.03s|train_loss 0.00000150|val_loss 0.00000842\n",
      "Epoch 741|time: 0.03s|train_loss 0.00000138|val_loss 0.00000847\n",
      "Epoch 742|time: 0.03s|train_loss 0.00000132|val_loss 0.00000870\n",
      "Epoch 743|time: 0.03s|train_loss 0.00000148|val_loss 0.00000840\n",
      "Epoch 744|time: 0.03s|train_loss 0.00000136|val_loss 0.00000807\n",
      "Epoch 745|time: 0.03s|train_loss 0.00000141|val_loss 0.00000835\n",
      "Epoch 746|time: 0.03s|train_loss 0.00000143|val_loss 0.00000838\n",
      "Epoch 747|time: 0.03s|train_loss 0.00000148|val_loss 0.00000859\n",
      "Epoch 748|time: 0.03s|train_loss 0.00000148|val_loss 0.00000858\n",
      "Epoch 749|time: 0.03s|train_loss 0.00000140|val_loss 0.00000838\n",
      "Epoch 750|time: 0.03s|train_loss 0.00000137|val_loss 0.00000851\n",
      "Epoch 751|time: 0.03s|train_loss 0.00000147|val_loss 0.00000838\n",
      "Epoch 752|time: 0.03s|train_loss 0.00000141|val_loss 0.00000791\n",
      "Epoch 753|time: 0.03s|train_loss 0.00000141|val_loss 0.00000892\n",
      "Epoch 754|time: 0.03s|train_loss 0.00000142|val_loss 0.00000834\n",
      "Epoch 755|time: 0.03s|train_loss 0.00000141|val_loss 0.00000901\n",
      "Epoch 756|time: 0.03s|train_loss 0.00000143|val_loss 0.00000818\n",
      "Epoch 757|time: 0.03s|train_loss 0.00000135|val_loss 0.00000828\n",
      "Epoch 758|time: 0.03s|train_loss 0.00000152|val_loss 0.00000798\n",
      "Epoch 759|time: 0.03s|train_loss 0.00000139|val_loss 0.00000802\n",
      "Epoch 760|time: 0.03s|train_loss 0.00000134|val_loss 0.00000808\n",
      "Epoch 761|time: 0.03s|train_loss 0.00000150|val_loss 0.00000892\n",
      "Epoch 762|time: 0.03s|train_loss 0.00000134|val_loss 0.00000890\n",
      "Epoch 763|time: 0.03s|train_loss 0.00000146|val_loss 0.00000883\n",
      "Epoch 764|time: 0.03s|train_loss 0.00000146|val_loss 0.00000812\n",
      "Epoch 765|time: 0.03s|train_loss 0.00000172|val_loss 0.00000819\n",
      "Epoch 766|time: 0.03s|train_loss 0.00000137|val_loss 0.00000851\n",
      "Epoch 767|time: 0.03s|train_loss 0.00000143|val_loss 0.00000809\n",
      "Epoch 768|time: 0.03s|train_loss 0.00000139|val_loss 0.00000828\n",
      "Epoch 769|time: 0.03s|train_loss 0.00000139|val_loss 0.00000888\n",
      "Epoch 770|time: 0.03s|train_loss 0.00000138|val_loss 0.00000789\n",
      "Epoch 771|time: 0.03s|train_loss 0.00000144|val_loss 0.00000841\n",
      "Epoch 772|time: 0.03s|train_loss 0.00000147|val_loss 0.00000807\n",
      "Epoch 773|time: 0.03s|train_loss 0.00000143|val_loss 0.00000911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 774|time: 0.03s|train_loss 0.00000136|val_loss 0.00000816\n",
      "Epoch 775|time: 0.03s|train_loss 0.00000139|val_loss 0.00000801\n",
      "Epoch 776|time: 0.03s|train_loss 0.00000148|val_loss 0.00000729\n",
      "Best validation epoch: 776 Mon Aug 15 22:18:18 2022\n",
      "TEST MAE 800.8420 std 699.4887 RMSE 1570.6881 RMSEs 1175.4286 MAPE 0.1198 R2 0.4141 R2s 0.3877\n",
      "Epoch 777|time: 0.03s|train_loss 0.00000139|val_loss 0.00000785\n",
      "Epoch 778|time: 0.03s|train_loss 0.00000149|val_loss 0.00000882\n",
      "Epoch 779|time: 0.03s|train_loss 0.00000148|val_loss 0.00000767\n",
      "Epoch 780|time: 0.03s|train_loss 0.00000145|val_loss 0.00000754\n",
      "Epoch 781|time: 0.03s|train_loss 0.00000140|val_loss 0.00000797\n",
      "Epoch 782|time: 0.03s|train_loss 0.00000145|val_loss 0.00000806\n",
      "Epoch 783|time: 0.03s|train_loss 0.00000136|val_loss 0.00000855\n",
      "Epoch 784|time: 0.04s|train_loss 0.00000144|val_loss 0.00000831\n",
      "Epoch 785|time: 0.04s|train_loss 0.00000144|val_loss 0.00000832\n",
      "Epoch 786|time: 0.03s|train_loss 0.00000156|val_loss 0.00000887\n",
      "Epoch 787|time: 0.04s|train_loss 0.00000142|val_loss 0.00000957\n",
      "Epoch 788|time: 0.04s|train_loss 0.00000137|val_loss 0.00000857\n",
      "Epoch 789|time: 0.03s|train_loss 0.00000144|val_loss 0.00000848\n",
      "Epoch 790|time: 0.03s|train_loss 0.00000138|val_loss 0.00000868\n",
      "Epoch 791|time: 0.03s|train_loss 0.00000145|val_loss 0.00000917\n",
      "Epoch 792|time: 0.03s|train_loss 0.00000152|val_loss 0.00000910\n",
      "Epoch 793|time: 0.04s|train_loss 0.00000145|val_loss 0.00000888\n",
      "Epoch 794|time: 0.04s|train_loss 0.00000137|val_loss 0.00000814\n",
      "Epoch 795|time: 0.03s|train_loss 0.00000141|val_loss 0.00000837\n",
      "Epoch 796|time: 0.04s|train_loss 0.00000131|val_loss 0.00000865\n",
      "Epoch 797|time: 0.04s|train_loss 0.00000149|val_loss 0.00000858\n",
      "Epoch 798|time: 0.04s|train_loss 0.00000130|val_loss 0.00000806\n",
      "Epoch 799|time: 0.04s|train_loss 0.00000138|val_loss 0.00000874\n",
      "Epoch 800|time: 0.04s|train_loss 0.00000142|val_loss 0.00000849\n",
      "Epoch 801|time: 0.04s|train_loss 0.00000143|val_loss 0.00000786\n",
      "Epoch 802|time: 0.04s|train_loss 0.00000132|val_loss 0.00000827\n",
      "Epoch 803|time: 0.04s|train_loss 0.00000140|val_loss 0.00000794\n",
      "Epoch 804|time: 0.04s|train_loss 0.00000142|val_loss 0.00000870\n",
      "Epoch 805|time: 0.04s|train_loss 0.00000150|val_loss 0.00000850\n",
      "Epoch 806|time: 0.03s|train_loss 0.00000137|val_loss 0.00000857\n",
      "Epoch 807|time: 0.04s|train_loss 0.00000142|val_loss 0.00000809\n",
      "Epoch 808|time: 0.03s|train_loss 0.00000136|val_loss 0.00000786\n",
      "Epoch 809|time: 0.03s|train_loss 0.00000135|val_loss 0.00000871\n",
      "Epoch 810|time: 0.03s|train_loss 0.00000147|val_loss 0.00000878\n",
      "Epoch 811|time: 0.03s|train_loss 0.00000142|val_loss 0.00000783\n",
      "Epoch 812|time: 0.03s|train_loss 0.00000137|val_loss 0.00000823\n",
      "Epoch 813|time: 0.03s|train_loss 0.00000137|val_loss 0.00000839\n",
      "Epoch 814|time: 0.03s|train_loss 0.00000130|val_loss 0.00000828\n",
      "Epoch 815|time: 0.03s|train_loss 0.00000147|val_loss 0.00000843\n",
      "Epoch 816|time: 0.03s|train_loss 0.00000143|val_loss 0.00000860\n",
      "Epoch 817|time: 0.03s|train_loss 0.00000136|val_loss 0.00000797\n",
      "Epoch 818|time: 0.03s|train_loss 0.00000153|val_loss 0.00000814\n",
      "Epoch 819|time: 0.03s|train_loss 0.00000132|val_loss 0.00000829\n",
      "Epoch 820|time: 0.03s|train_loss 0.00000134|val_loss 0.00000821\n",
      "Epoch 821|time: 0.03s|train_loss 0.00000139|val_loss 0.00000834\n",
      "Epoch 822|time: 0.03s|train_loss 0.00000135|val_loss 0.00000815\n",
      "Epoch 823|time: 0.03s|train_loss 0.00000153|val_loss 0.00000820\n",
      "Epoch 824|time: 0.03s|train_loss 0.00000151|val_loss 0.00000761\n",
      "Epoch 825|time: 0.03s|train_loss 0.00000143|val_loss 0.00000860\n",
      "Epoch 826|time: 0.03s|train_loss 0.00000146|val_loss 0.00000926\n",
      "Epoch 827|time: 0.03s|train_loss 0.00000144|val_loss 0.00000833\n",
      "Epoch 828|time: 0.03s|train_loss 0.00000139|val_loss 0.00000902\n",
      "Epoch 829|time: 0.03s|train_loss 0.00000157|val_loss 0.00000892\n",
      "Epoch 830|time: 0.03s|train_loss 0.00000143|val_loss 0.00000860\n",
      "Epoch 831|time: 0.03s|train_loss 0.00000135|val_loss 0.00000858\n",
      "Epoch 832|time: 0.03s|train_loss 0.00000137|val_loss 0.00000841\n",
      "Epoch 833|time: 0.03s|train_loss 0.00000137|val_loss 0.00000849\n",
      "Epoch 834|time: 0.03s|train_loss 0.00000144|val_loss 0.00000906\n",
      "Epoch 835|time: 0.03s|train_loss 0.00000159|val_loss 0.00000868\n",
      "Epoch 836|time: 0.03s|train_loss 0.00000143|val_loss 0.00000834\n",
      "Epoch 837|time: 0.03s|train_loss 0.00000142|val_loss 0.00000807\n",
      "Epoch 838|time: 0.03s|train_loss 0.00000145|val_loss 0.00000840\n",
      "Epoch 839|time: 0.03s|train_loss 0.00000141|val_loss 0.00000795\n",
      "Epoch 840|time: 0.03s|train_loss 0.00000142|val_loss 0.00000858\n",
      "Epoch 841|time: 0.04s|train_loss 0.00000134|val_loss 0.00000828\n",
      "Epoch 842|time: 0.04s|train_loss 0.00000140|val_loss 0.00000867\n",
      "Epoch 843|time: 0.03s|train_loss 0.00000143|val_loss 0.00000839\n",
      "Epoch 844|time: 0.03s|train_loss 0.00000141|val_loss 0.00000804\n",
      "Epoch 845|time: 0.03s|train_loss 0.00000149|val_loss 0.00000845\n",
      "Epoch 846|time: 0.03s|train_loss 0.00000148|val_loss 0.00000876\n",
      "Epoch 847|time: 0.03s|train_loss 0.00000145|val_loss 0.00000829\n",
      "Epoch 848|time: 0.03s|train_loss 0.00000141|val_loss 0.00000857\n",
      "Epoch 849|time: 0.03s|train_loss 0.00000136|val_loss 0.00000813\n",
      "Epoch 850|time: 0.03s|train_loss 0.00000145|val_loss 0.00000816\n",
      "Epoch 851|time: 0.03s|train_loss 0.00000142|val_loss 0.00000844\n",
      "Epoch 852|time: 0.03s|train_loss 0.00000135|val_loss 0.00000822\n",
      "Epoch 853|time: 0.04s|train_loss 0.00000155|val_loss 0.00000899\n",
      "Epoch 854|time: 0.03s|train_loss 0.00000143|val_loss 0.00000797\n",
      "Epoch 855|time: 0.03s|train_loss 0.00000141|val_loss 0.00000842\n",
      "Epoch 856|time: 0.03s|train_loss 0.00000140|val_loss 0.00000862\n",
      "Epoch 857|time: 0.03s|train_loss 0.00000139|val_loss 0.00000820\n",
      "Epoch 858|time: 0.03s|train_loss 0.00000141|val_loss 0.00000877\n",
      "Epoch 859|time: 0.03s|train_loss 0.00000146|val_loss 0.00000803\n",
      "Epoch 860|time: 0.03s|train_loss 0.00000147|val_loss 0.00000866\n",
      "Epoch 861|time: 0.04s|train_loss 0.00000142|val_loss 0.00000857\n",
      "Epoch 862|time: 0.03s|train_loss 0.00000138|val_loss 0.00000813\n",
      "Epoch 863|time: 0.04s|train_loss 0.00000144|val_loss 0.00000862\n",
      "Epoch 864|time: 0.03s|train_loss 0.00000143|val_loss 0.00000844\n",
      "Epoch 865|time: 0.03s|train_loss 0.00000148|val_loss 0.00000836\n",
      "Epoch 866|time: 0.03s|train_loss 0.00000147|val_loss 0.00000821\n",
      "Epoch 867|time: 0.03s|train_loss 0.00000142|val_loss 0.00000846\n",
      "Epoch 868|time: 0.03s|train_loss 0.00000142|val_loss 0.00000825\n",
      "Epoch 869|time: 0.03s|train_loss 0.00000147|val_loss 0.00000811\n",
      "Epoch 870|time: 0.03s|train_loss 0.00000141|val_loss 0.00000809\n",
      "Epoch 871|time: 0.03s|train_loss 0.00000136|val_loss 0.00000864\n",
      "Epoch 872|time: 0.03s|train_loss 0.00000132|val_loss 0.00000968\n",
      "Epoch 873|time: 0.03s|train_loss 0.00000137|val_loss 0.00000880\n",
      "Epoch 874|time: 0.03s|train_loss 0.00000150|val_loss 0.00000859\n",
      "Epoch 875|time: 0.03s|train_loss 0.00000146|val_loss 0.00000756\n",
      "Epoch 876|time: 0.03s|train_loss 0.00000144|val_loss 0.00000819\n",
      "Epoch 877|time: 0.03s|train_loss 0.00000126|val_loss 0.00000804\n",
      "Epoch 878|time: 0.03s|train_loss 0.00000142|val_loss 0.00000837\n",
      "Epoch 879|time: 0.03s|train_loss 0.00000146|val_loss 0.00000854\n",
      "Epoch 880|time: 0.03s|train_loss 0.00000137|val_loss 0.00000849\n",
      "Epoch 881|time: 0.03s|train_loss 0.00000147|val_loss 0.00000818\n",
      "Epoch 882|time: 0.03s|train_loss 0.00000147|val_loss 0.00000838\n",
      "Epoch 883|time: 0.03s|train_loss 0.00000145|val_loss 0.00000854\n",
      "Epoch 884|time: 0.03s|train_loss 0.00000139|val_loss 0.00000833\n",
      "Epoch 885|time: 0.03s|train_loss 0.00000143|val_loss 0.00000814\n",
      "Epoch 886|time: 0.03s|train_loss 0.00000147|val_loss 0.00000811\n",
      "Epoch 887|time: 0.03s|train_loss 0.00000141|val_loss 0.00000831\n",
      "Epoch 888|time: 0.03s|train_loss 0.00000145|val_loss 0.00000834\n",
      "Epoch 889|time: 0.03s|train_loss 0.00000135|val_loss 0.00000829\n",
      "Epoch 890|time: 0.03s|train_loss 0.00000144|val_loss 0.00000836\n",
      "Epoch 891|time: 0.03s|train_loss 0.00000137|val_loss 0.00000867\n",
      "Epoch 892|time: 0.03s|train_loss 0.00000132|val_loss 0.00000841\n",
      "Epoch 893|time: 0.03s|train_loss 0.00000142|val_loss 0.00000830\n",
      "Epoch 894|time: 0.03s|train_loss 0.00000131|val_loss 0.00000806\n",
      "Epoch 895|time: 0.03s|train_loss 0.00000138|val_loss 0.00000778\n",
      "Epoch 896|time: 0.03s|train_loss 0.00000130|val_loss 0.00000825\n",
      "Epoch 897|time: 0.03s|train_loss 0.00000143|val_loss 0.00000851\n",
      "Epoch 898|time: 0.03s|train_loss 0.00000142|val_loss 0.00000875\n",
      "Epoch 899|time: 0.03s|train_loss 0.00000152|val_loss 0.00000860\n",
      "Epoch 900|time: 0.03s|train_loss 0.00000140|val_loss 0.00000830\n",
      "Epoch 901|time: 0.03s|train_loss 0.00000130|val_loss 0.00000825\n",
      "Epoch 902|time: 0.03s|train_loss 0.00000135|val_loss 0.00000813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 903|time: 0.03s|train_loss 0.00000129|val_loss 0.00000893\n",
      "Epoch 904|time: 0.03s|train_loss 0.00000139|val_loss 0.00000870\n",
      "Epoch 905|time: 0.03s|train_loss 0.00000142|val_loss 0.00000845\n",
      "Epoch 906|time: 0.03s|train_loss 0.00000152|val_loss 0.00000832\n",
      "Epoch 907|time: 0.03s|train_loss 0.00000160|val_loss 0.00000851\n",
      "Epoch 908|time: 0.03s|train_loss 0.00000142|val_loss 0.00000856\n",
      "Epoch 909|time: 0.03s|train_loss 0.00000148|val_loss 0.00000874\n",
      "Epoch 910|time: 0.03s|train_loss 0.00000148|val_loss 0.00000895\n",
      "Epoch 911|time: 0.03s|train_loss 0.00000141|val_loss 0.00000824\n",
      "Epoch 912|time: 0.04s|train_loss 0.00000138|val_loss 0.00000770\n",
      "Epoch 913|time: 0.03s|train_loss 0.00000135|val_loss 0.00000803\n",
      "Epoch 914|time: 0.03s|train_loss 0.00000147|val_loss 0.00000835\n",
      "Epoch 915|time: 0.03s|train_loss 0.00000131|val_loss 0.00000833\n",
      "Epoch 916|time: 0.03s|train_loss 0.00000136|val_loss 0.00000824\n",
      "Epoch 917|time: 0.04s|train_loss 0.00000133|val_loss 0.00000776\n",
      "Epoch 918|time: 0.03s|train_loss 0.00000144|val_loss 0.00000808\n",
      "Epoch 919|time: 0.03s|train_loss 0.00000142|val_loss 0.00000898\n",
      "Epoch 920|time: 0.03s|train_loss 0.00000147|val_loss 0.00000788\n",
      "Epoch 921|time: 0.03s|train_loss 0.00000145|val_loss 0.00000765\n",
      "Epoch 922|time: 0.04s|train_loss 0.00000137|val_loss 0.00000807\n",
      "Epoch 923|time: 0.03s|train_loss 0.00000140|val_loss 0.00000871\n",
      "Epoch 924|time: 0.03s|train_loss 0.00000138|val_loss 0.00000773\n",
      "Epoch 925|time: 0.03s|train_loss 0.00000145|val_loss 0.00000836\n",
      "Epoch 926|time: 0.03s|train_loss 0.00000137|val_loss 0.00000869\n",
      "Epoch 927|time: 0.03s|train_loss 0.00000143|val_loss 0.00000812\n",
      "Epoch 928|time: 0.03s|train_loss 0.00000135|val_loss 0.00000829\n",
      "Epoch 929|time: 0.03s|train_loss 0.00000134|val_loss 0.00000749\n",
      "Epoch 930|time: 0.03s|train_loss 0.00000150|val_loss 0.00000865\n",
      "Epoch 931|time: 0.03s|train_loss 0.00000135|val_loss 0.00000884\n",
      "Epoch 932|time: 0.03s|train_loss 0.00000141|val_loss 0.00000855\n",
      "Epoch 933|time: 0.03s|train_loss 0.00000132|val_loss 0.00000879\n",
      "Epoch 934|time: 0.03s|train_loss 0.00000137|val_loss 0.00000829\n",
      "Epoch 935|time: 0.03s|train_loss 0.00000142|val_loss 0.00000874\n",
      "Epoch 936|time: 0.03s|train_loss 0.00000149|val_loss 0.00000793\n",
      "Epoch 937|time: 0.03s|train_loss 0.00000134|val_loss 0.00000851\n",
      "Epoch 938|time: 0.03s|train_loss 0.00000134|val_loss 0.00000759\n",
      "Epoch 939|time: 0.03s|train_loss 0.00000138|val_loss 0.00000838\n",
      "Epoch 940|time: 0.03s|train_loss 0.00000132|val_loss 0.00000875\n",
      "Epoch 941|time: 0.03s|train_loss 0.00000143|val_loss 0.00000868\n",
      "Epoch 942|time: 0.03s|train_loss 0.00000142|val_loss 0.00000931\n",
      "Epoch 943|time: 0.03s|train_loss 0.00000138|val_loss 0.00000864\n",
      "Epoch 944|time: 0.03s|train_loss 0.00000142|val_loss 0.00000789\n",
      "Epoch 945|time: 0.03s|train_loss 0.00000142|val_loss 0.00000814\n",
      "Epoch 946|time: 0.03s|train_loss 0.00000137|val_loss 0.00000898\n",
      "Epoch 947|time: 0.03s|train_loss 0.00000138|val_loss 0.00000767\n",
      "Epoch 948|time: 0.03s|train_loss 0.00000141|val_loss 0.00000854\n",
      "Epoch 949|time: 0.03s|train_loss 0.00000137|val_loss 0.00000819\n",
      "Epoch 950|time: 0.03s|train_loss 0.00000139|val_loss 0.00000817\n",
      "Epoch 951|time: 0.03s|train_loss 0.00000132|val_loss 0.00000785\n",
      "Epoch 952|time: 0.03s|train_loss 0.00000150|val_loss 0.00000807\n",
      "Epoch 953|time: 0.03s|train_loss 0.00000145|val_loss 0.00000865\n",
      "Epoch 954|time: 0.03s|train_loss 0.00000151|val_loss 0.00000857\n",
      "Epoch 955|time: 0.03s|train_loss 0.00000132|val_loss 0.00000831\n",
      "Epoch 956|time: 0.03s|train_loss 0.00000158|val_loss 0.00000819\n",
      "Epoch 957|time: 0.03s|train_loss 0.00000137|val_loss 0.00000869\n",
      "Epoch 958|time: 0.03s|train_loss 0.00000144|val_loss 0.00000794\n",
      "Epoch 959|time: 0.03s|train_loss 0.00000142|val_loss 0.00000820\n",
      "Epoch 960|time: 0.03s|train_loss 0.00000133|val_loss 0.00000841\n",
      "Epoch 961|time: 0.03s|train_loss 0.00000145|val_loss 0.00000857\n",
      "Epoch 962|time: 0.03s|train_loss 0.00000134|val_loss 0.00000802\n",
      "Epoch 963|time: 0.03s|train_loss 0.00000137|val_loss 0.00000853\n",
      "Epoch 964|time: 0.03s|train_loss 0.00000139|val_loss 0.00000805\n",
      "Epoch 965|time: 0.03s|train_loss 0.00000141|val_loss 0.00000892\n",
      "Epoch 966|time: 0.03s|train_loss 0.00000136|val_loss 0.00000861\n",
      "Epoch 967|time: 0.03s|train_loss 0.00000133|val_loss 0.00000852\n",
      "Epoch 968|time: 0.03s|train_loss 0.00000145|val_loss 0.00000837\n",
      "Epoch 969|time: 0.03s|train_loss 0.00000137|val_loss 0.00000857\n",
      "Epoch 970|time: 0.03s|train_loss 0.00000138|val_loss 0.00000787\n",
      "Epoch 971|time: 0.03s|train_loss 0.00000128|val_loss 0.00000876\n",
      "Epoch 972|time: 0.03s|train_loss 0.00000144|val_loss 0.00000867\n",
      "Epoch 973|time: 0.03s|train_loss 0.00000138|val_loss 0.00000820\n",
      "Epoch 974|time: 0.03s|train_loss 0.00000138|val_loss 0.00000824\n",
      "Epoch 975|time: 0.03s|train_loss 0.00000149|val_loss 0.00000811\n",
      "Epoch 976|time: 0.03s|train_loss 0.00000139|val_loss 0.00000841\n"
     ]
    }
   ],
   "source": [
    "bad_counter = 0\n",
    "best_epoch = 0\n",
    "best_val = 1e+20;\n",
    "try:\n",
    "    print('begin training');\n",
    "    if not os.path.exists(args.save_dir):\n",
    "        os.makedirs(args.save_dir)\n",
    "    \n",
    "    for epoch in range(1, args.epochs+1):\n",
    "        epoch_start_time = time.time()\n",
    "        train_loss = train(data_loader, data_loader.train)\n",
    "        val_loss, mae,std_mae, rmse, rmse_states, mape, r2, r2_states = evaluate(data_loader, data_loader.val, history_average=True)\n",
    "        print('Epoch {:3d}|time:{:5.2f}s|train_loss {:5.8f}|val_loss {:5.8f}'.format(epoch, (time.time() - epoch_start_time), train_loss, val_loss))\n",
    "\n",
    "        # Save the model if the validation loss is the best we've seen so far.\n",
    "        if val_loss < best_val:\n",
    "            best_val = val_loss\n",
    "            best_epoch = epoch\n",
    "            bad_counter = 0\n",
    "            model_path = '%s/%s.pt' % (args.save_dir, log_token)\n",
    "            with open(model_path, 'wb') as f:\n",
    "                torch.save(model.state_dict(), f)\n",
    "            print('Best validation epoch:',epoch, time.ctime());\n",
    "            test_loss, mae,std_mae, rmse, rmse_states, mape, r2, r2_states  = evaluate(data_loader, data_loader.test,tag='test')\n",
    "            print('TEST MAE {:5.4f} std {:5.4f} RMSE {:5.4f} RMSEs {:5.4f} MAPE {:5.4f} R2 {:5.4f} R2s {:5.4f}'.format( mae, std_mae, rmse, rmse_states, mape, r2, r2_states))\n",
    "        else:\n",
    "            bad_counter += 1\n",
    "\n",
    "        if bad_counter == args.patience:\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('-' * 89)\n",
    "    print('Exiting from training early, epoch',epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "97aa8355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final evaluation\n",
      "TEST MAE 774.2249 std 674.7603 RMSE 1529.8939 RMSEs 1145.4900 MAPE 0.1174 R2 0.4442 R2s 0.4182\n"
     ]
    }
   ],
   "source": [
    "# Load the best saved model.\n",
    "model_path = '%s/%s.pt' % (args.save_dir, log_token)\n",
    "with open(model_path, 'rb') as f:\n",
    "    model.load_state_dict(torch.load(f));\n",
    "test_loss, mae,std_mae, rmse, rmse_states, mape, r2, r2_states  = evaluate(data_loader, data_loader.test,tag='test',history_average=True)\n",
    "print('Final evaluation')\n",
    "print('TEST MAE {:5.4f} std {:5.4f} RMSE {:5.4f} RMSEs {:5.4f} MAPE {:5.4f} R2 {:5.4f} R2s {:5.4f}'.format( mae, std_mae, rmse, rmse_states, mape, r2, r2_states))\n",
    "           \n",
    "# test model\n",
    "if args.eval != '':\n",
    "    testdata = np.loadtxt(open(\"data/{}.txt\".format(args.eval)), delimiter=',')\n",
    "    testdata = (testdata - data_loader.min) / (data_loader.max - data_loader.min)\n",
    "    testdata = torch.Tensor(testdata)\n",
    "    testdata = testdata.unsqueeze(0)\n",
    "    testdata = Variable(testdata)\n",
    "    if args.cuda:\n",
    "        testdata = testdata.cuda()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out_data, attn = model(testdata, None)\n",
    "        out_data = out_data.cpu().numpy() * (data_loader.max - data_loader.min ) * 1.0 + data_loader.min\n",
    "        at = attn[0]\n",
    "        attn = attn[1].squeeze(0)\n",
    "        #print(out_data.shape) #1, numregion\n",
    "        #out_data = out_data.squeeze(0)\n",
    "\n",
    "    # record\n",
    "    out_data = out_data.tolist()\n",
    "    with open(\"save/{}.txt\".format(args.eval+\"result\"), \"a\") as f:\n",
    "        f.write(\"\\n\" + \"window\" + str(args.window) + \", horizon\" + str(args.horizon) + \"\\n\")\n",
    "        f.write(str(at))\n",
    "        f.write(str(attn))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "17cb9e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 모델 저장\n",
    "torch.save(model.state_dict(), 'SEFNet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "46d4f5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 저장한 모델 불러오기\n",
    "    # class를 먼저 정의한 뒤에 저장한 매개변수를 불러와준다.\n",
    "model = Model(args, data_loader)  \n",
    "model.load_state_dict(torch.load('SEFNet.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bc7a78",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd07ff9",
   "metadata": {},
   "source": [
    "# 데이터 차원 수 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d58e7b",
   "metadata": {},
   "source": [
    "## get_batches 풀어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e89c7f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_loader, data):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    n_samples = 0.\n",
    "    batch_size = args.batch\n",
    "\n",
    "    for inputs in data_loader.get_batches(data, batch_size, False):\n",
    "        X, Y = inputs[0], inputs[1]\n",
    "        optimizer.zero_grad()\n",
    "        output,_  = model(X) \n",
    "        if Y.size(0) == 1:\n",
    "            Y = Y.view(-1)\n",
    "        loss_train = F.mse_loss(output, Y) # mse_loss\n",
    "        total_loss += loss_train.item()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        n_samples += (output.size(0) * data_loader.m)\n",
    "    return float(total_loss / n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8be0efda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TPA_LSTM과 같음\"\"\"\n",
    "def get_batches(self, data, batch_size, shuffle=True):\n",
    "    inputs = data[0] # data = data_loader.train\n",
    "    targets = data[1]\n",
    "    length = len(inputs)\n",
    "    if shuffle:\n",
    "        index = torch.randperm(length)\n",
    "    else:\n",
    "        index = torch.LongTensor(range(length))\n",
    "    start_idx = 0\n",
    "    while (start_idx < length):\n",
    "        end_idx = min(length, start_idx + batch_size)\n",
    "        excerpt = index[start_idx:end_idx]\n",
    "        X = inputs[excerpt,:]\n",
    "        Y = targets[excerpt,:]\n",
    "        if (self.cuda):\n",
    "            X = X.cuda()\n",
    "            Y = Y.cuda()\n",
    "        model_inputs = Variable(X)\n",
    "\n",
    "        data = [model_inputs, Variable(Y)]\n",
    "        yield data\n",
    "        start_idx += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41a07f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################ self.rawdat.shape ################\n",
      "rawdat.shape (348, 47)\n",
      "\n",
      "################ self.dat.shape ################\n",
      "관측치 수 : 348 변수 개수 : 47\n",
      "\n",
      "################ _pre_train ################\n",
      "self.tmp_train X: torch.Size([150, 20, 47])\n",
      "self.tmp_train Y: torch.Size([150, 47])\n",
      "train_mx (trainset의 shape) : (170, 47)\n",
      "self.train_set : range(24, 174)\n",
      "self.valid_set : range(174, 243)\n",
      "self.test_set : range(243, 348)\n",
      "_pre_train (정규화된 데이터 dat의 shape) : (348, 47)\n",
      "\n",
      "################ [train, valid, test] shape ################\n",
      "size of train/val/test sets 150 69 105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataBasicLoader(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc6c6721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 전체 train X 데이터셋 : torch.Size([150, 20, 47])\n",
      "# 단일 train X 데이터셋 : torch.Size([20, 47])\n",
      "\n",
      "# 전체 train Y 데이터셋 : torch.Size([150, 47])\n",
      "# 단일 train Y 데이터셋 : torch.Size([47])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Train X data\"\"\"\n",
    "print('# 전체 train X 데이터셋 :', data_loader.train[0].shape) # [batch_size, window_size, n_features]\n",
    "print('# 단일 train X 데이터셋 :', data_loader.train[0][0].shape) # [window_size, n_features] -> 하나의 window만 존재한다.\n",
    "print()\n",
    "\n",
    "\"\"\"Train Y data\"\"\"\n",
    "print('# 전체 train Y 데이터셋 :', data_loader.train[1].shape) # [batch_size, n_features]\n",
    "print('# 단일 train Y 데이터셋 :', data_loader.train[1][0].shape) # [n_features] -> 하나의 window에 대한 정답으로 47개의 feature별로 한 개의 값만 존재한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c987edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 20, 47])\n",
      "torch.Size([128, 47])\n",
      "\n",
      "torch.Size([22, 20, 47])\n",
      "torch.Size([22, 47])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 두 개의 batch만 나옴\n",
    "idx = 0\n",
    "for inputs in data_loader.get_batches(data_loader.train, 128, False):\n",
    "    X, Y = inputs[0], inputs[1]\n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "    print()\n",
    "    idx+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2912ac",
   "metadata": {},
   "source": [
    "### get_batches 하나씩 자세하게 풀기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "553fed88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## inputs ##\n",
      "torch.Size([150, 20, 47])\n",
      "torch.Size([20, 47])\n",
      "\n",
      "## targets ##\n",
      "torch.Size([150, 47])\n",
      "torch.Size([47])\n",
      "\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "inputs = data_loader.train[0] # data = data_loader.train\n",
    "targets = data_loader.train[1]\n",
    "length = len(inputs)\n",
    "print('## inputs ##')\n",
    "print(inputs.shape)\n",
    "print(inputs[0].shape)\n",
    "print()\n",
    "print('## targets ##')\n",
    "print(targets.shape)\n",
    "print(targets[0].shape)\n",
    "print()\n",
    "\n",
    "print(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d17ef6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
       "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
       "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
       "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
       "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
       "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
       "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
       "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
       "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
       "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = torch.LongTensor(range(length))\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9dc8194d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end_idx : 128\n",
      "excerpt : tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n"
     ]
    }
   ],
   "source": [
    "start_idx = 0\n",
    "batch_size = 128\n",
    "end_idx = min(length, start_idx + batch_size) # min(150, 0+128) -> 128\n",
    "print('end_idx :', end_idx)\n",
    "excerpt = index[start_idx:end_idx] # 0:128\n",
    "print('excerpt :', excerpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cf67fa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# excerpt 값의 index들을 X와 Y에 할당\n",
    "X = inputs[excerpt,:]\n",
    "Y = targets[excerpt,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "db61d1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 cuda 설정\n",
    "X = X.cuda()\n",
    "Y = Y.cuda()\n",
    "# model의 input값에 설정\n",
    "model_inputs = Variable(X)\n",
    "\n",
    "data = [model_inputs, Variable(Y)]\n",
    "start_idx += batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab88ccc",
   "metadata": {},
   "source": [
    "## intra series embedding module에 input되는 값 확인\n",
    "- 확인을 위해 _split()의 useraw를 True로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "deab79cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 348\n",
    "m = 47\n",
    "P = 20\n",
    "h = 1\n",
    "train = int(args.train*n)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ef6f9f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(20, 174)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\"\"\"원본 데이터\"\"\"\n",
    "rawdat = pd.DataFrame(np.loadtxt(open(\"data/{}.txt\".format(args.dataset)), delimiter=',')) # 데이터 불러오기\n",
    "col_list = [f'region_{i}' for i in range(1, rawdat.shape[1]+1)]\n",
    "rawdat.columns = col_list\n",
    "train_set = range(20+1-1, train)\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd04484b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>region_3</th>\n",
       "      <th>region_4</th>\n",
       "      <th>region_5</th>\n",
       "      <th>region_6</th>\n",
       "      <th>region_7</th>\n",
       "      <th>region_8</th>\n",
       "      <th>region_9</th>\n",
       "      <th>region_10</th>\n",
       "      <th>...</th>\n",
       "      <th>region_38</th>\n",
       "      <th>region_39</th>\n",
       "      <th>region_40</th>\n",
       "      <th>region_41</th>\n",
       "      <th>region_42</th>\n",
       "      <th>region_43</th>\n",
       "      <th>region_44</th>\n",
       "      <th>region_45</th>\n",
       "      <th>region_46</th>\n",
       "      <th>region_47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   region_1  region_2  region_3  region_4  region_5  region_6  region_7  \\\n",
       "0       0.0       0.0       7.0       0.0       0.0       0.0       0.0   \n",
       "1       1.0       0.0      21.0       0.0       3.0       0.0       0.0   \n",
       "2       1.0       0.0       2.0       0.0       2.0       1.0       0.0   \n",
       "3       0.0       0.0       4.0       0.0       0.0       0.0       1.0   \n",
       "4       0.0       0.0      13.0       0.0       6.0       0.0       0.0   \n",
       "\n",
       "   region_8  region_9  region_10  ...  region_38  region_39  region_40  \\\n",
       "0       0.0       4.0        3.0  ...        1.0        1.0        0.0   \n",
       "1       0.0       3.0       17.0  ...        2.0        0.0        0.0   \n",
       "2       6.0       3.0        3.0  ...        4.0        0.0        0.0   \n",
       "3       0.0       5.0        5.0  ...        6.0        3.0        1.0   \n",
       "4       0.0      13.0        2.0  ...        1.0        1.0        0.0   \n",
       "\n",
       "   region_41  region_42  region_43  region_44  region_45  region_46  region_47  \n",
       "0        4.0        1.0        0.0        1.0       14.0        0.0        0.0  \n",
       "1        5.0        0.0        1.0        1.0       16.0        2.0        0.0  \n",
       "2        9.0        1.0        0.0        7.0       42.0        0.0        0.0  \n",
       "3        3.0        2.0        0.0        2.0       75.0        0.0        0.0  \n",
       "4        4.0        0.0        1.0        6.0      100.0        0.0        2.0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a30c8d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 20, 47])\n",
      "torch.Size([128, 47])\n"
     ]
    }
   ],
   "source": [
    "## 두 개의 batch만 나옴\n",
    "idx = 0\n",
    "for inputs in data_loader.get_batches(data_loader.train, 128, False):\n",
    "    X, Y = inputs[0], inputs[1]\n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239e4c07",
   "metadata": {},
   "source": [
    "### 원본"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf2793ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 20, 47])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3823ca98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 47])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 헹이 window size이고, 열이 columns이다.\n",
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9800869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000e+00, 0.0000e+00, 4.3314e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 3.5619e-04, 2.5229e-04, 0.0000e+00, 2.4783e-04,\n",
       "        0.0000e+00, 4.2141e-04, 2.6998e-04, 2.6976e-04, 0.0000e+00, 7.0093e-04,\n",
       "        2.3178e-04, 2.0981e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        7.4857e-04, 1.7021e-04, 8.0939e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1737e-03, 4.9358e-04, 4.0404e-04,\n",
       "        1.9294e-04, 8.2068e-05, 3.6617e-04, 0.0000e+00, 1.9382e-04, 2.0105e-04,\n",
       "        0.0000e+00, 2.8977e-04, 1.9154e-03, 0.0000e+00, 0.0000e+00],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dec1391",
   "metadata": {},
   "source": [
    "### permute 이후\n",
    "- 원래는 행이 window이고, 열이 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e3343e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 47, 20])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 행이 columns이고 열이 window size이다.\n",
    "X.permute(0,2,1).contiguous().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9426c628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([47, 20])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.permute(0,2,1).contiguous()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ac49f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0006, 0.0006, 0.0000, 0.0000, 0.0000, 0.0000, 0.0006, 0.0006,\n",
       "        0.0006, 0.0000, 0.0000, 0.0000, 0.0000, 0.0018, 0.0024, 0.0018, 0.0041,\n",
       "        0.0012, 0.0030], device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫 번째 변수의 window length 만큼의 값\n",
    "X.permute(0,2,1).contiguous()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "53f16447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 4.0, 3.0, 7.0, 2.0, 5.0]\n"
     ]
    }
   ],
   "source": [
    "# 첫 번째 변수의 window length 만큼의 값\n",
    "print(rawdat.loc[:19, 'region_1'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3901e00a",
   "metadata": {},
   "source": [
    "### permute().view() 이후\n",
    "- torch.Size([6016, 20, 1])를 가짐\n",
    "- 여기서 size(0)인 6016은 128*47로 batch_size*n_features를 의미한다.\n",
    "- X.permute(0,2,1).contiguous().view(-1, X.size(1), 1)[0]은 첫 번째 변수의 window_size만큼의 값을 의미한다.\n",
    "- X.permute(0,2,1).contiguous().view(-1, X.size(1), 1)[1]은 두 번째 변수의 window_size만큼의 값을 의미한다.\n",
    "- X.permute(0,2,1).contiguous().view(-1, X.size(1), 1)[47]은 다시 첫 번째 변수의 window_size만큼의 값을 의미한다.\n",
    "- `즉 모든 변수의 window size만큼의 값들을 1차원으로 펼친 것을 의미한다.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "307951df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6016, 20, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.permute(0,2,1).contiguous().view(-1, X.size(1), 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b1d56704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.permute(0,2,1).contiguous().view(-1, X.size(1), 1)[48].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "86a4c81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0006],\n",
       "        [0.0006],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0018],\n",
       "        [0.0024],\n",
       "        [0.0018],\n",
       "        [0.0041],\n",
       "        [0.0012],\n",
       "        [0.0030],\n",
       "        [0.0118]], device='cuda:0')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.permute(0,2,1).contiguous().view(-1, X.size(1), 1)[47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e2371e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 4.0, 3.0, 7.0, 2.0, 5.0, 20.0]\n"
     ]
    }
   ],
   "source": [
    "# 첫 번째 변수의 window length 만큼의 값\n",
    "print(rawdat['region_1'][1:21].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b028b997",
   "metadata": {},
   "source": [
    "### LSTM 적용해보기\n",
    "- window_size * 변수 길이만큼 1열로 늘어선 값들이 LSTM에 들어간다.\n",
    "- LSTM을 통해 나온 마지막 hidden_out 값은 hidR(64) 만큼의 size를 가지고 있다.\n",
    "- 이는 47개 지역(변수)들을 64 size로 늘린 값으로 각 지역의 정보를 가지고 있다고 보면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "6d9c5876",
   "metadata": {},
   "outputs": [],
   "source": [
    "## r은 X.permute(0, 2, 1).contiguous().view(-1, X.size(1), 1)을 의미\n",
    "# r_out, hc = self.lstm(r, None)\n",
    "# last_hid = self.dropout(r_out[:, -1, :])\n",
    "# intra_ = last_hid.view(-1, self.m, self.hidR) # t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "337e75a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 원본 데이터의 shape :             torch.Size([128, 20, 47])\n",
      "## permute한 데이터의 shape :        torch.Size([128, 47, 20])\n",
      "## permute + view한 데이터의 shape : torch.Size([6016, 20, 1])\n"
     ]
    }
   ],
   "source": [
    "## 20은 window size\n",
    "## 47은 변수의 개수\n",
    "## 6016은 batch_size*n_features\n",
    "print('## 원본 데이터의 shape :            ', X.shape)\n",
    "print('## permute한 데이터의 shape :       ', X.permute(0, 2, 1).shape)\n",
    "print('## permute + view한 데이터의 shape :', X.permute(0, 2, 1).contiguous().view(-1, X.size(1), 1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a553ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6016, 20, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intra-Region embedding\n",
    "r = X.permute(0, 2, 1).contiguous().view(-1, X.size(1), 1) # LSTM에 입력될 수 있게 변형\n",
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "11e1f47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LSTM layer 확인\n",
    "self_hidR = 64\n",
    "self_num_layers = 1\n",
    "self_lstm = nn.LSTM(1, self_hidR, bidirectional=False, batch_first=True, num_layers=self_num_layers).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9c851c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## output.shape : torch.Size([6016, 20, 64])\n",
      "## hc.shape : torch.Size([1, 6016, 64])\n"
     ]
    }
   ],
   "source": [
    "# hc는 hidden state와 cell state를 모두 가지고 있음\n",
    "r_out, hc = self_lstm(r, None)\n",
    "print('## output.shape :', r_out.shape)\n",
    "print('## hc.shape :', hc[0].shape) # hidden state의 경우 [최종 lstm layer, 길이, hidden_state_feature와 같이 나온다.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9cd89e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6016, 64])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 변수별 각 window의 마지막 값\n",
    "    # [6016, 20, 64]는 20X64행렬이 6016개 있다는 것\n",
    "    # [6016, 64]으로의 변환은 20X64에서 20개의 행 중에 마지막 하나의 행들만 가져오는 것\n",
    "r_out[:, -1, :].shape\n",
    "# 위 값의 첫 행은 r_out[0, -1, :]과 같다.\n",
    "    # 6016개 중 1번째의 20X64 중에서 마지막 64개 (1x64)만 가져온 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fa256bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## last hidden state의 shape : torch.Size([6016, 64])\n"
     ]
    }
   ],
   "source": [
    "# last_hid = nn.Dropout(0.2)(r_out[:, -1, :])\n",
    "last_hid = r_out[:, -1, :]\n",
    "print('## last hidden state의 shape :', last_hid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "019a6ae2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 47, 64])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_m = 47 # 변수 개수\n",
    "self_hidR = 64 # LSTM hidden state size\n",
    "# batch마다 지역별 hidden state가 나온다.\n",
    "intra_ = last_hid.view(-1, self_m, self_hidR) # [128, 47, 64]과 같이 바뀜 = [batch_size, n_features, hidR]\n",
    "intra_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8cc1d6",
   "metadata": {},
   "source": [
    "## inter series embedding module에 input 되는 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "818ea61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Inter-Region embedding\n",
    "# rac = self.rac(x) # RegionAwareConv\n",
    "# q = self.q_linear(rac) # rac의 결과가 attention에 입력\n",
    "# k = self.k_linear(rac)\n",
    "# v = self.v_linear(rac)\n",
    "# q = nn.Dropout(p=0.2)(q)\n",
    "# k = nn.Dropout(p=0.2)(k)\n",
    "# v = nn.Dropout(p=0.2)(v)\n",
    "# inter_ = self.attn_layer(q, k, v) # i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a266cf7f",
   "metadata": {},
   "source": [
    "### 원본"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "421133d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 20, 47])\n",
      "torch.Size([128, 47])\n"
     ]
    }
   ],
   "source": [
    "## 두 개의 batch만 나옴\n",
    "idx = 0\n",
    "for inputs in data_loader.get_batches(data_loader.train, 128, False):\n",
    "    X, Y = inputs[0], inputs[1]\n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8e31482b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 20, 47])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## [batch_size, window size, n_features]로 이루어진 원본이 그대로 들어감\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1263f8",
   "metadata": {},
   "source": [
    "### self.rac()에 원본 X input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0a5afa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "## self.rac() = RegionAwareConv(P=self.w, m=self.m, k=self.k, hidP=self.hidP)을 의미\n",
    "sef_w = 20 # window_size\n",
    "self_m = 47 # 변수 개수\n",
    "self_k = 16 # kernel 개수\n",
    "self_hidP = 1 # RegionAwareConv의 hidden size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0321cdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegionAwareConv(nn.Module):\n",
    "    def __init__(self, P, m, k, hidP, dilation_factor=2):\n",
    "        super(RegionAwareConv, self).__init__()\n",
    "        self.P = P\n",
    "        self.m = m\n",
    "        self.k = k\n",
    "        self.hidP = hidP\n",
    "        # local convolution의 경우 dilation은 1로 설정\n",
    "            # conv_l1과 conv_l2는 kernel_size가 다름\n",
    "        self.conv_l1 = ConvBranch(m = self.m, in_channels=1, out_channels=self.k, kernel_size=3, dilation_factor=1, hidP = self.hidP)\n",
    "        self.conv_l2 = ConvBranch(m = self.m, in_channels=1, out_channels=self.k, kernel_size=5, dilation_factor=1, hidP = self.hidP)\n",
    "        # periodic convolution의 경우 dilation은 2로 설정\n",
    "        self.conv_p1 = ConvBranch(m = self.m, in_channels=1, out_channels=self.k, kernel_size=3, dilation_factor=dilation_factor, hidP=self.hidP)\n",
    "        self.conv_p2 = ConvBranch(m = self.m, in_channels=1, out_channels=self.k, kernel_size=5, dilation_factor=dilation_factor, hidP=self.hidP)\n",
    "        # global_pattern의 경우 전체 window가 input됨 -> kernel_size가 self.P\n",
    "        self.conv_g = ConvBranch(m=self.m, in_channels=1, out_channels=self.k, kernel_size=self.P, dilation_factor=1, hidP=None, isPool=False)\n",
    "        self.activate = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, self.P, self.m)\n",
    "        batch_size = x.shape[0]\n",
    "        # local pattern\n",
    "        x_l1 = self.conv_l1(x)\n",
    "        x_l2 = self.conv_l2(x)\n",
    "        x_local = torch.cat([x_l1, x_l2], dim=1)\n",
    "        # periodic pattern\n",
    "        x_p1 = self.conv_p1(x)\n",
    "        x_p2 = self.conv_p2(x)\n",
    "        x_period = torch.cat([x_l1, x_l2], dim=1)\n",
    "        # global\n",
    "        x_global = self.conv_g(x)\n",
    "        # concat and activate\n",
    "        x = torch.cat([x_local, x_period, x_global], dim=1).permute(0, 2, 1) # 3가지 pattern을 concat함\n",
    "        x = self.activate(x) # nn.tanh()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "23e09cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBranch(nn.Module):\n",
    "    def __init__(self, m, in_channels, out_channels, kernel_size, dilation_factor, hidP = 1, isPool=True):\n",
    "        super().__init__()\n",
    "        self.m = m\n",
    "        self.isPool = isPool\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=(kernel_size, 1), dilation = (dilation_factor, 1), bias=False)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        if self.isPool:\n",
    "            self.pooling = nn.AdaptiveMaxPool2d((hidP, m))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = F.relu(self.conv(x))\n",
    "        x = self.batchnorm(x)\n",
    "        if self.isPool:\n",
    "            x = self.pooling(x)\n",
    "        x = x.view(batch_size, -1, self.m)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f252ae5f",
   "metadata": {},
   "source": [
    "### self.rac 입력 초기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "758adb37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 20, 47])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_m = 47 # 변수 개수\n",
    "self_P = 20 # window\n",
    "\n",
    "\"\"\"inter-series embedding module에 input 되기 위해 차원 변경\"\"\"\n",
    "## nn.Conv2d()의 입력은 (batch_size, in_channels, H(height), W(width))-> 본 데이터의 경우 (128, 1, window_size, n_features)\n",
    "    # (self.P, self.m)이 이미지의 사각형과 같은 역할을 한다.\n",
    "rac_X = X.view(-1, 1, self_P, self_m)\n",
    "rac_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f9965c",
   "metadata": {},
   "source": [
    "### self.conv_ (ConvBranch) 입력\n",
    "- 원본 X를 nn.Conv2d()에 입력될 수 있게 channels수에 맞춰 차원 변경\n",
    "- 이후 batchnorm과 pooling을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1004ccbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## batch_size : 128\n",
      "## self.rac()에 input되는 x의 shape torch.Size([128, 1, 20, 47])\n"
     ]
    }
   ],
   "source": [
    "batch_size = X.shape[0]\n",
    "print('## batch_size :', batch_size)\n",
    "print('## self.rac()에 input되는 x의 shape', rac_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79200372",
   "metadata": {},
   "source": [
    "#### nn.Conv2d() 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0f6cc890",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"convolution\"\"\"\n",
    "# 변수들 각각에 kernel이 적용되야 하기에 kernel_size가 행이 길도록 설정되어 있음\n",
    "# 디폴트로 padding은 0이 설정되어 있음\n",
    "normal_conv = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(3, 1), dilation = (1, 1), bias=False).cuda()\n",
    "normal_conv2 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(5, 1), dilation = (1, 1), bias=False).cuda()\n",
    "conv_l1 = ConvBranch(m = self_m, in_channels=1, out_channels=self_k, kernel_size=3, dilation_factor=1, hidP = self_hidP).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "20210b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 16, 20, 47])\n"
     ]
    }
   ],
   "source": [
    "# 임시\n",
    "임시_conv = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(1, 1), dilation = (1, 1), bias=False).cuda()\n",
    "임시_output = 임시_conv(rac_X)\n",
    "print(임시_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "41b30283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## conv_l1_output.shape : torch.Size([128, 16, 18, 47])\n",
      "## conv_l2_output.shape : torch.Size([128, 16, 16, 47])\n"
     ]
    }
   ],
   "source": [
    "# kernel이 (3,1)이어서 H만 20에서 18로 줄어듦\n",
    "conv_l1_output = normal_conv(rac_X)\n",
    "conv_l2_output = normal_conv2(rac_X)\n",
    "print('## conv_l1_output.shape :', conv_l1_output.shape)\n",
    "print('## conv_l2_output.shape :', conv_l2_output.shape) # kernel size가 5이기에 H가 더 줄어듦"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35421a06",
   "metadata": {},
   "source": [
    "#### Max pooling 적용\n",
    "- max pooling을 먹이면 kernel size에 상관없이 모두 1로 압축됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6bded3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"max pooling\"\"\"\n",
    "## max pooling\n",
    "    # 47개 변수별 window size에서의 의미를 max pooling을 통해 하나로 줄임\n",
    "hidP = 1\n",
    "self_pooling = nn.AdaptiveMaxPool2d((hidP, self_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "acc70c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Local1에서 pooling 이후의 shape : torch.Size([128, 16, 1, 47])\n",
      "## Local2에서 pooling 이후의 shape : torch.Size([128, 16, 1, 47])\n"
     ]
    }
   ],
   "source": [
    "## max pooling을 먹이면 kernel size에 상관없이 모두 1로 압축됨\n",
    "conv_l1_pooling_output = self_pooling(conv_l1_output)\n",
    "conv_l2_pooling_output = self_pooling(conv_l2_output)\n",
    "print('## Local1에서 pooling 이후의 shape :', conv_l1_pooling_output.shape)\n",
    "print('## Local2에서 pooling 이후의 shape :', conv_l2_pooling_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08effeb7",
   "metadata": {},
   "source": [
    "#### view() 적용\n",
    "- nn.Conv2d()를 통해 나온 out_channel 별 변수로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "af5ea244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## view() 전의 conv_l1_pooling_output : torch.Size([128, 16, 1, 47])\n",
      "## view() 전의 conv_l2_pooling_output : torch.Size([128, 16, 1, 47])\n",
      "## view() 후의 conv_l1_pooling_output : torch.Size([128, 16, 47])\n",
      "## view() 후의 conv_l2_pooling_output : torch.Size([128, 16, 47])\n"
     ]
    }
   ],
   "source": [
    "print('## view() 전의 conv_l1_pooling_output :', conv_l1_pooling_output.shape)\n",
    "print('## view() 전의 conv_l2_pooling_output :', conv_l2_pooling_output.shape)\n",
    "\n",
    "## torch.squeeze(conv_l1_pooling_output,2)와 같음\n",
    "conv_l1_pooling_output = conv_l1_pooling_output.view(batch_size, -1, self_m)\n",
    "conv_l2_pooling_output = conv_l2_pooling_output.view(batch_size, -1, self_m)\n",
    "print('## view() 후의 conv_l1_pooling_output :', conv_l1_pooling_output.shape)\n",
    "print('## view() 후의 conv_l2_pooling_output :', conv_l2_pooling_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49af1a6",
   "metadata": {},
   "source": [
    "#### Local pattern concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bfca8e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## x_local : torch.Size([128, 32, 47])\n"
     ]
    }
   ],
   "source": [
    "## kernel_size를 3으로 해서 뽑은 값과 5로 해서 뽑은 값을 concat\n",
    "x_local = torch.cat([conv_l1_pooling_output, conv_l2_pooling_output], dim=1)\n",
    "print('## x_local :', x_local.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b727173",
   "metadata": {},
   "source": [
    "##### periodic과 global 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0b39b40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"convolution\"\"\"\n",
    "## periodic\n",
    "normal_conv_p1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(3, 1), dilation = (2, 1), bias=False).cuda()\n",
    "normal_conv_p2 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(5, 1), dilation = (2, 1), bias=False).cuda()\n",
    "\n",
    "## global\n",
    "self_P = 20 # window size를 의미\n",
    "# global pattern의 kernel size는 window size\n",
    "normal_conv_g = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(self_P,1), dilation = 1, bias=False).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "83a4c3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## conv_p1_output.shape : torch.Size([128, 16, 16, 47])\n",
      "## conv_p2_output.shape : torch.Size([128, 16, 12, 47])\n",
      "## conv_g_output.shape : torch.Size([128, 16, 1, 47])\n"
     ]
    }
   ],
   "source": [
    "# kernel이 (3,1)이어서 H만 20에서 18로 줄어듦\n",
    "conv_p1_output = normal_conv_p1(rac_X)\n",
    "conv_p2_output = normal_conv_p2(rac_X)\n",
    "conv_g_output = normal_conv_g(rac_X)\n",
    "\n",
    "print('## conv_p1_output.shape :', conv_p1_output.shape)\n",
    "print('## conv_p2_output.shape :', conv_p2_output.shape) # kernel size가 5이기에 H가 더 줄어듦\n",
    "print('## conv_g_output.shape :', conv_g_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ad28b6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## periodic1에서 pooling 이후의 shape : torch.Size([128, 16, 1, 47])\n",
      "## periodic2에서 pooling 이후의 shape : torch.Size([128, 16, 1, 47])\n",
      "## global shape : torch.Size([128, 16, 1, 47])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"max pooling\"\"\"\n",
    "## max pooling을 먹이면 kernel size에 상관없이 모두 1로 압축됨\n",
    "conv_p1_pooling_output = self_pooling(conv_p1_output)\n",
    "conv_p2_pooling_output = self_pooling(conv_p2_output)\n",
    "\n",
    "## global pattern은 pooling 안 함\n",
    "conv_g_output = conv_g_output\n",
    "\n",
    "print('## periodic1에서 pooling 이후의 shape :', conv_p1_pooling_output.shape)\n",
    "print('## periodic2에서 pooling 이후의 shape :', conv_p2_pooling_output.shape)\n",
    "print('## global shape :', conv_g_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "544f9aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## view() 전의 conv_p1_pooling_output : torch.Size([128, 16, 1, 47])\n",
      "## view() 전의 conv_p2_pooling_output : torch.Size([128, 16, 1, 47])\n",
      "## view() 전의 conv_g_pooling_output : torch.Size([128, 16, 1, 47])\n",
      "\n",
      "## view() 후의 conv_p1_pooling_output : torch.Size([128, 16, 47])\n",
      "## view() 후의 conv_p2_pooling_output : torch.Size([128, 16, 47])\n",
      "## view() 후의 conv_g_output : torch.Size([128, 16, 47])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\"\"\n",
    "print('## view() 전의 conv_p1_pooling_output :', conv_p1_pooling_output.shape)\n",
    "print('## view() 전의 conv_p2_pooling_output :', conv_p2_pooling_output.shape)\n",
    "print('## view() 전의 conv_g_pooling_output :', conv_g_output.shape, end='\\n\\n')\n",
    "\n",
    "## torch.squeeze(conv_l1_pooling_output,2)와 같음\n",
    "conv_p1_pooling_output = conv_p1_pooling_output.view(batch_size, -1, self_m)\n",
    "conv_p2_pooling_output = conv_p2_pooling_output.view(batch_size, -1, self_m)\n",
    "conv_g_output = conv_g_output.view(batch_size, -1, self_m)\n",
    "print('## view() 후의 conv_p1_pooling_output :', conv_p1_pooling_output.shape)\n",
    "print('## view() 후의 conv_p2_pooling_output :', conv_p2_pooling_output.shape)\n",
    "print('## view() 후의 conv_g_output :', conv_g_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0798b929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## x_period : torch.Size([128, 32, 47])\n"
     ]
    }
   ],
   "source": [
    "## kernel_size를 3으로 해서 뽑은 값과 5로 해서 뽑은 값을 concat\n",
    "x_period = torch.cat([conv_p1_pooling_output, conv_p2_pooling_output], dim=1)\n",
    "print('## x_period :', x_period.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0f75d80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## x_global : torch.Size([128, 16, 47])\n"
     ]
    }
   ],
   "source": [
    "## kernel_size를 3으로 해서 뽑은 값과 5로 해서 뽑은 값을 concat\n",
    "x_global = conv_g_output\n",
    "print('## x_global :', x_global.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77c1e71",
   "metadata": {},
   "source": [
    "#### local과 periodic과 global concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f9b7abb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 80, 47])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## permute 전 (attention에 넣기 전)의 shape\n",
    "torch.cat([x_local, x_period, x_global], dim=1).shape # 3가지 pattern을 concat함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "ae0fd91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## self.rac의 최종 output : torch.Size([128, 47, 80])\n"
     ]
    }
   ],
   "source": [
    "## local과 periodic과 global을 모두 1차원 상에서 concat한 다음 permute \n",
    "    # [batch_size, n_features, convolution_channels]\n",
    "rac_output = torch.cat([x_local, x_period, x_global], dim=1).permute(0, 2, 1) # 3가지 pattern을 concat함\n",
    "print('## self.rac의 최종 output :', rac_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "eb36b6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tanh 사용\n",
    "self_activate = nn.Tanh()\n",
    "rac_output = self_activate(rac_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4c2b10",
   "metadata": {},
   "source": [
    "### attention 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "9c78b5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_k = 16 # number of kernels\n",
    "self_hidP = 1 # the output hidden dim of adaptive pooling\n",
    "self_hidA = 64 # attention Q, K, V의 linear layer의 hidden size\n",
    "self_regionconvhid = self_k * 4*self_hidP + self_k\n",
    "self_regionconvhid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "f71e3eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q, K, V 계산\"\"\"\n",
    "## Linear layer의 outsize를 intra series embedding module의 LSTM output size와 일치시킨다.\n",
    "self_q_linear = nn.Linear(self_regionconvhid, self_hidA, bias = True).cuda() # 80 -> 64\n",
    "self_k_linear = nn.Linear(self_regionconvhid, self_hidA, bias = True).cuda() # 80 -> 64\n",
    "self_v_linear = nn.Linear(self_regionconvhid, self_hidA, bias = True).cuda() # 80 -> 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "68323955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 기존의 shape : torch.Size([128, 47, 80])\n",
      "\n",
      "## Query의 shape : torch.Size([128, 47, 64])\n",
      "## Key의 shape : torch.Size([128, 47, 64])\n",
      "## Value의 shape : torch.Size([128, 47, 64])\n"
     ]
    }
   ],
   "source": [
    "print('## 기존의 shape :', rac_output.shape)\n",
    "print()\n",
    "q = self_q_linear(rac_output)\n",
    "k = self_k_linear(rac_output)\n",
    "v = self_v_linear(rac_output)\n",
    "print('## Query의 shape :', q.shape)\n",
    "print('## Key의 shape :', k.shape)\n",
    "print('## Value의 shape :', v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "d8305588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## k.transpose(1,2) : torch.Size([128, 64, 47])\n",
      "\n",
      "## attn shape : torch.Size([128, 47, 47])\n",
      "\n",
      "## attention이 적용된 output : torch.Size([128, 47, 64])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"attention을 하기 위한 class Dott 구현\"\"\"\n",
    "print('## k.transpose(1,2) :', k.transpose(1,2).shape, end='\\n\\n')\n",
    "\n",
    "## batch일 때 matrix multiplication을 할 수 있는 bmm을 사용한다.\n",
    "attn = torch.bmm(q,k.transpose(1,2)) # (47*64)*(64*47) ->(47,47)\n",
    "print('## attn shape :', attn.shape, end='\\n\\n')\n",
    "self_softmax = nn.Softmax(dim=-1) # dim=-1은 dim=1과 같음 -> 행별 softmax\n",
    "attn = self_softmax(attn) # softmax 적용\n",
    "output = torch.bmm(attn, v) # Value와 attention weight을 곱하여 attention value를 만들어 냄\n",
    "print('## attention이 적용된 output :', output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "f24f0d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_  = output.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c78f56",
   "metadata": {},
   "source": [
    "## parametric matrix fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "77324b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intra_ shape torch.Size([128, 47, 64])\n",
      "inter_ shape torch.Size([128, 47, 64])\n"
     ]
    }
   ],
   "source": [
    "print('intra_ shape', intra_.shape)\n",
    "print('inter_ shape', inter_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "8eede486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## self_inter shape : torch.Size([47, 64])\n",
      "## self_intra shape : torch.Size([47, 64])\n"
     ]
    }
   ],
   "source": [
    "self_inter = nn.Parameter(torch.FloatTensor(self_m, self_hidA), requires_grad=True).cuda()\n",
    "self_intra = nn.Parameter(torch.FloatTensor(self_m, self_hidR), requires_grad=True).cuda()\n",
    "print('## self_inter shape :', self_inter.shape)\n",
    "print('## self_intra shape :', self_intra.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "bc5701cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## intra shape :  torch.Size([128, 47, 64])\n",
      "## inter shape :  torch.Size([128, 47, 64])\n"
     ]
    }
   ],
   "source": [
    "## element wise하게 곱함\n",
    "intra_ = torch.mul(self_intra, intra_)\n",
    "inter_ = torch.mul(self_inter, inter_)\n",
    "print('## intra shape : ', intra_.shape)\n",
    "print('## inter shape : ', inter_.shape)\n",
    "\n",
    "## 최종적인 output\n",
    "res = torch.cat([intra_, inter_], dim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e4d485",
   "metadata": {},
   "source": [
    "## final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "69092588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=128, out_features=1, bias=True)"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 최종 output layer\n",
    "self_output = nn.Linear(self_hidA+self_hidR, 1).cuda()\n",
    "self_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "6f1fdd7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res shape : torch.Size([128, 47, 1])\n"
     ]
    }
   ],
   "source": [
    "## intra와 inter concat\n",
    "res = self_output(res)\n",
    "print('res shape :', res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "01da1bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 47])"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## batch의 모든 window마다 정답이 나옴\n",
    "res = res.squeeze(2)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d72d059",
   "metadata": {},
   "source": [
    "## AR module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "02492c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=20, out_features=1, bias=True)"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_hw = 20 # window_size\n",
    "self_highway = nn.Linear(self_hw, 1).cuda()\n",
    "self_highway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "c05d0248",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## z shape : torch.Size([6016, 20])\n"
     ]
    }
   ],
   "source": [
    "z = X[:,-self_hw:,:]\n",
    "z = z.permute(0, 2, 1).contiguous().view(-1, 20)\n",
    "print('## z shape :', z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "0389898c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6016, 1])"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AR_output = self_highway(z)\n",
    "AR_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "08da01aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 47])"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## batch의 모든 window마다 정답이 나옴\n",
    "AR_output = AR_output.view(-1, self_m)\n",
    "AR_output.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "torch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "297.542px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
